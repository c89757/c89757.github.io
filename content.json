{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://c89757.gitee.io/colinstar","root":"/colinstar/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-12-16T13:28:00.710Z","updated":"2021-12-16T13:28:00.710Z","comments":false,"path":"/404.html","permalink":"http://c89757.gitee.io/colinstar/404.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-12-16T13:28:00.713Z","updated":"2021-12-16T13:28:00.713Z","comments":true,"path":"links/index.html","permalink":"http://c89757.gitee.io/colinstar/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-12-16T13:28:00.713Z","updated":"2021-12-16T13:28:00.713Z","comments":false,"path":"categories/index.html","permalink":"http://c89757.gitee.io/colinstar/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-12-16T13:28:00.714Z","updated":"2021-12-16T13:28:00.714Z","comments":false,"path":"repository/index.html","permalink":"http://c89757.gitee.io/colinstar/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-12-16T13:28:00.715Z","updated":"2021-12-16T13:28:00.715Z","comments":false,"path":"tags/index.html","permalink":"http://c89757.gitee.io/colinstar/tags/index.html","excerpt":"","text":""},{"title":"书单","date":"2021-12-16T13:28:00.712Z","updated":"2021-12-16T13:28:00.712Z","comments":false,"path":"books/index.html","permalink":"http://c89757.gitee.io/colinstar/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2021-12-16T13:28:00.712Z","updated":"2021-12-16T13:28:00.712Z","comments":false,"path":"about/index.html","permalink":"http://c89757.gitee.io/colinstar/about/index.html","excerpt":"","text":"个人详细介绍"}],"posts":[{"title":"科学上网-自建梯子","slug":"科学上网-自建梯子","date":"2024-05-11T12:12:58.000Z","updated":"2024-05-11T14:14:29.680Z","comments":true,"path":"2024/05/11/科学上网-自建梯子/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/05/11/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-%E8%87%AA%E5%BB%BA%E6%A2%AF%E5%AD%90/","excerpt":"","text":"购买VPS vultr：截至2024-05-10，基本已死。服务器ip大多都ping不通 hostease：美国主机商，在香港有机房，香港服务器不需要备案，且支持支付宝付款 以下操作基于centos7，建议镜像选用centos 服务器配置 用xshell或其他客户端，远程连接上服务器 shadowsocks依次执行以下命令 如果没有wget，先安装：yum install -y wget 12345wget --no-check-certificate -O shadowsocks.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 根据提示，输入密码、端口、加密方式，等待安装即可。 上述安装完成之后，一般速度较慢，所以我们需要配置加速（类似于一种算法，能加速网络传输） 安装Google BBR： 12345wget — no-check-certificate https://github.com/teddysun/across/raw/master/bbr.shchmod +x bbr.sh./bbr.sh 显示 “Press any key to start…” 按回车确认。 提示重启VPS，输入Y确认，等待重启即可 补充 1234/etc/init.d/shadowsocks start # 启动/etc/init.d/shadowsocks stop # 停止/etc/init.d/shadowsocks restart # 重启/etc/init.d/shadowsocks status # 状态 原文链接 安装客户端shadowsocks官网下载客户端： https://github.com/shadowsocks/shadowsocks-windows/releases 下载完成安装之后，打开客户端，配置ip、密码、加速方式即可 其他godaddy美国域名服务器，不需要备案 官网链接 官网被墙了，需要梯子才可访问。而且其官网本身会检测VPN，一般市场上的机场用的人多，都会被检测出来，通过自建的VPN可以访问","categories":[{"name":"网络","slug":"网络","permalink":"http://c89757.gitee.io/colinstar/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"other","slug":"other","permalink":"http://c89757.gitee.io/colinstar/tags/other/"}]},{"title":"InnoDB-FullTextIndex","slug":"InnoDB-FullTextIndex","date":"2024-04-24T11:24:50.000Z","updated":"2024-04-24T16:02:56.866Z","comments":true,"path":"2024/04/24/InnoDB-FullTextIndex/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/04/24/InnoDB-FullTextIndex/","excerpt":"","text":"InnoDB全文检索索引，是基于文本的列(CHAR、VARCHAR或TEXT列)上创建的，以加快对这些列中包含的数据的查询和DML操作。 InnoDB全文索引采用了倒排索引设计。倒排索引存储一个单词列表，对于每个单词，存储该单词出现在其中的文档列表。为了支持邻近搜索，每个字的位置信息也以字节偏移量的形式存储 MySql5.7.6之前，全文检索只支持英文索引，不支持中文全文索引。 MySql5.7.6之后，内置了ngram全文解析器，用来支持中文、日文、韩文分词 概述 全文搜索使用MATCH() AGAINST()语法执行。MATCH()接受一个逗号分隔的列表，该列表指定要搜索的列。AGAINST接受一个要搜索的字符串和一个可选的修饰符，该修饰符指示要执行的搜索类型。 全文检索支持三种搜索方式 自然语言搜索 将搜索字符串解释为自然人类语言中的短语(自由文本中的短语)。 如果给出了IN natural language MODE修饰符，或者没有给出修饰符，全文搜索就是自然语言搜索。 boolean搜索 使用特殊查询语言的规则解释搜索字符串。 字符串包含要搜索的单词。例如某个单词必须在匹配行中出现或不存在 查询扩展搜索 是对自然语言搜索的修改。 搜索字符串用于执行自然语言搜索。然后将搜索返回的最相关行的单词添加到搜索字符串中，并再次进行搜索。该查询返回第二次搜索的行。 自然语言搜索 默认情况下或使用IN NATURAL LANGUAGE MODE修饰符时，MATCH()函数针对文本集合执行字符串的自然语言搜索。集合是包含在FULLTEXT索引中的一个或多个列的集合。搜索字符串作为参数提供给AGAINST()。对于表中的每一行，MATCH()返回一个相关性值;也就是说，搜索字符串与MATCH()列表中指定的列中该行中的文本之间的相似性度量。 12345678910111213141516171819202122232425262728mysql&gt; CREATE TABLE articles ( -&gt; id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY, -&gt; title VARCHAR(200), -&gt; body TEXT, -&gt; FULLTEXT (title,body) -&gt; ) ENGINE=InnoDB;Query OK, 0 rows affected (0.08 sec)mysql&gt; INSERT INTO articles (title,body) VALUES -&gt; (&#x27;MySQL Tutorial&#x27;,&#x27;DBMS stands for DataBase ...&#x27;), -&gt; (&#x27;How To Use MySQL Well&#x27;,&#x27;After you went through a ...&#x27;), -&gt; (&#x27;Optimizing MySQL&#x27;,&#x27;In this tutorial, we show ...&#x27;), -&gt; (&#x27;1001 MySQL Tricks&#x27;,&#x27;1. Never run mysqld as root. 2. ...&#x27;), -&gt; (&#x27;MySQL vs. YourSQL&#x27;,&#x27;In the following database comparison ...&#x27;), -&gt; (&#x27;MySQL Security&#x27;,&#x27;When configured properly, MySQL ...&#x27;);Query OK, 6 rows affected (0.01 sec)Records: 6 Duplicates: 0 Warnings: 0mysql&gt; SELECT * FROM articles -&gt; WHERE MATCH (title,body) -&gt; AGAINST (&#x27;database&#x27; IN NATURAL LANGUAGE MODE);+----+-------------------+------------------------------------------+| id | title | body |+----+-------------------+------------------------------------------+| 1 | MySQL Tutorial | DBMS stands for DataBase ... || 5 | MySQL vs. YourSQL | In the following database comparison ... |+----+-------------------+------------------------------------------+2 rows in set (0.00 sec) 默认情况下，以不区分大小写的方式执行搜索。若要执行区分大小写的全文搜索，请对索引列使用二进制排序。例如，可以为使用的latin1字符集的列分配latin1_bin排序规则，使其对全文搜索区分大小写。 当在WHERE子句中使用MATCH()时，如前面所示的示例，只要满足以下条件，返回的行将自动按照最高相关性优先排序： 必须没有显式的ORDER BY子句。 必须使用全文索引扫描而不是表扫描来执行搜索。 如果查询连接表，则全文索引扫描必须是连接中最左边的非常量表。 要计算count值，你可以这么写 123SELECT COUNT(*) FROM articles WHERE MATCH (title,body) AGAINST (&#x27;database&#x27; IN NATURAL LANGUAGE MODE); 有时候这样写可能会更快 1234SELECT COUNT(IF(MATCH (title,body) AGAINST (&#x27;database&#x27; IN NATURAL LANGUAGE MODE), 1, NULL)) AS count FROM articles; 第一个查询做了一些额外的工作(根据相关性对结果排序)，但也可以使用基于WHERE子句的索引查找。如果搜索匹配的行很少，索引查找可能会使第一个查询更快。第二个查询执行全表扫描，如果搜索词出现在大多数行中，则可能比索引查找快。 对于自然语言全文搜索，MATCH()函数中命名的列必须与表中某些FULLTEXT索引中包含的列相同。 对于前面的查询，MATCH()函数中指定的列(title和body)与文章表FULLTEXT索引定义中指定的列相同。 要分别搜索标题或正文，需要为每列创建单独的FULLTEXT索引。 使用索引的全文搜索只能在MATCH()子句中命名单个表中的列，因为索引不能跨多个表。 全文索引表创建InnoDB全文索引时，会创建一组索引表 1SELECT table_id, name, space from INFORMATION_SCHEMA.INNODB_SYS_TABLES; 辅助索引表名的前缀是FTS_，后缀是index_#。每个辅助索引表通过与被索引表的table_id匹配的辅助索引表名中的十六进制值与被索引表相关联。 全文检索缓存当文本被插入时，将对其进行标记，并将单个单词和相关数据插入全文索引中。 这个过程，即使对于文本比较小，也可能导致对索引表进行大量小的插入，从而使对这些表的并发访问成为争用点。 为了避免这个问题，InnoDB使用全文索引缓存来临时缓存索引表中最近插入的行。 插入时先保存到这个内存缓存结构，直到缓存满，然后将它们批量刷新到磁盘(到辅助索引表) 可以通过如下语句，查询最近插入的行的标记化数据。 1SELECT * FROM INFORMATION_SCHEMA.INNODB_FT_INDEX_CACHE; 缓存和批处理刷新行为避免了对辅助索引表的频繁更新，还避免了对同一个单词的多次插入，并最大限度地减少了重复条目。不是逐个刷新每个单词，而是将相同单词的插入合并并作为单个条目刷新到磁盘，从而提高了插入效率，同时使辅助索引表尽可能小。 全文索引缓存，仅仅为最近插入的行 缓存标记化的数据，查询时，已经刷新到磁盘的数据不会被带回到全文检索缓存中。直接查询辅助索引表中的数据，并且在返回之前，将辅助索引表中的结果与全文索引缓存中的结果合并。","categories":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/categories/MySql/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/tags/MySql/"}]},{"title":"XA事务与两阶段提交","slug":"XA事务与两阶段提交","date":"2024-04-22T16:15:30.000Z","updated":"2024-04-23T16:22:42.575Z","comments":true,"path":"2024/04/23/XA事务与两阶段提交/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/04/23/XA%E4%BA%8B%E5%8A%A1%E4%B8%8E%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/","excerpt":"","text":"MySQL分为server层和存储引擎层，而事务具体是在存储引擎层实现的。 在书写包含在一个事务中的语句时，不同语句可能会涉及不同存储引擎的表，这时如果我们想保持整个事务要么全部执行，要么全部不执行的话，本质上就需要保证各个存储引擎的事务全部提交，或者全部回滚。 我们有一个大的事务，我们可以称其为全局事务，这个全局事务由若干的小的事务组成。要实现这个大的事务，就必须让它对应的若干个小的事务全部完成，或者全部回滚。我们也可以把这个大的全局事务称作分布式事务。 XA规范XA规范提出了2个角色 一个全局事务由多个小的事务组成，所以需要一个事务协调器（Transaction Coordinator）或资源管理器（Resource Manager） 管理一个小事务的角色被称为事务管理器（Transaction Manager） 要提交一个全局事务，那么属于该全局事务的若干个小事务就应该全部提交，只要有任何一个小事务无法提交，那么整个全局事务就应该全部回滚。 XA规范中指出，要提交一个全局事务，必须分为2步 Prepare阶段 当事务协调器准备提交一个全局事务时，会依次通知各个事务管理器，进行提交，如果事务管理器觉得没有问题，就把执行过程中所产生的redo日志都刷新到磁盘，然后应答事务协调器；如果事务协调器不能正确提交事务，则也需要通知事务协调器 Commit阶段 如果在Prepare阶段各个事务管理器给事务协调器的应答都是OK，没有问题，那么事务协调器就要真正通知各个事务管理器，去提交事务。 如果Prepare阶段有事务管理器给事务协调器的应答是，不能提交事务，于是事务协调器就通知各个事务管理器，进行事务回滚。 不过在事务协调器在统一提交和回滚之前，都需要在某个地方记录一下这个全局事务已提交，以及各个子事务的状态信息。 XA规范把上述全局事务提交时所经历的两个阶段称作两阶段提交。 MySql中的XA事务MySQL中的XA事务分为外部XA和内部XA 外部XA在MySql的外部XA实现中，MySql服务器充当事务管理器，而连接服务器的客户端程序充当事务协调器。 想在MySQL中使用XA事务，需要一些特殊的语句： XA &#123;START|BEGIN&#125; xid ：该语句用于开启一个XA事务，此时该XA事务处于ACTIVE状态。 在一台MySql服务器上，每个XA事务都必须有一个唯一的id，被称作xid。这个xid是由发其XA事务的应用程序（客户端）自己指定的，只要我们自己保证它唯一就好了。 这个xid其实是由gtrid、bqual、formatID三个部分组成的： 1xid: gtrid [, bqual [, formatID ]] 其中gtrid（global transaction id）是指全局事务id，是一个字符串，bqual是指分支限定符，formatID是指gtrid和bqual所使用的格式。bqual和formatID省略。 XA END xid：在使用XA START xid开启了一个XA事务后，客户端就可以接着发送属于这个XA事务的各条语句，等所有语句都发送完毕后，就可以接着发送XA END xid来告知服务器由xid标识的XA事务的所有语句都输入完了。此时该XA事务处于IDLE状态。 XA PREPARE xid：对于处于IDLE状态的XA事务，应用程序就可以询问MySQL服务器是否准备好提交这个XA事务了，此时就可以给服务器发送XA PREPARE xid语句。当MySQL服务器收到此语句后，就需要做准备提交前的工作了，比如把该事务执行过程中所产生的redo日志刷新到磁盘等。此时XA事务处于PREPARE状态。 XA ROLLBACK xid：应用程序通过发送此语句来让MySQL服务器回滚xid所标识的事务。此时XA事务处于ABORT状态。 XA RECOVER：应用程序想看一下当前MySQL服务器上已经处于Prepare状态的XA事务有哪些，就可以发送该语句。 现在各个公司由于表中数据太多，这些数据会被分散在不通服务器中存储。由应用程序员分别和不同的MySQL服务器打交道实在费劲，所以有一种称作数据库中间件的东西开始问世。即应用程序只将SQL语句发送给数据库中间件，中间件分析一下该SQL访问的数据都在哪些不同的服务器中存储着，并且计算出不通服务器应该执行哪些SQL语句。然后就可以对不同的服务器分别开启XA事务，并且让把不同服务器需要执行的语句分别发送到不同的服务器中。等应用程序员告知中间件准备提交事务时，中间件先给各个服务器发送XA PREPARE语句，如果各个服务器都返回OK的话，接着就给各个服务器发送XA COMMIT语句来提交XA事务，等各个服务器把提交成功的消息返回给中间件，中间件就可以通知应用程序事务提交成功了。 内部XA对于一台服务器来说，即使客户端使用BEGIN/START TRANSACTION语句开启的普通事务，事务所包含的语句也有可能涉及多个存储引擎。此时MySQL内部采用XA规范来保证所有支持事务的存储引擎要么全部提交，要么全部回滚，这也被称作MySQL的内部XA。 在MySQL内部执行一个事务时，存储引擎会修改相应的数据，server层会记录语句对应的binlog。这是一个原子性的行为，要么都完成，要么都不完成 那我们需要保证：如果存储引擎提交了事务，server层的binlog日志必须也被写入到硬盘上；如果存储引擎回滚了事务，server层的binlog日志必须不能被写入到硬盘上。 那我们需要保证：如果存储引擎提交了事务，server层的binlog日志必须也被写入到硬盘上；如果存储引擎回滚了事务，server层的binlog日志必须不能被写入到硬盘上。 有binlog参与的内部XA事务 当客户端执行COMMIT语句或者在自动提交的情况下，MySQL内部开启一个XA事务，分两阶段来完成XA事务的提交： Prepare阶段：存储引擎将该事务执行过程中产生的redo日志刷盘，并且将本事务的状态设定为PREPARE。binlog啥也不干，下面看一下具体的代码 首先我们知道事务执行过程中需要写undo日志，这些undo日志被写到若干个页面中，这些页面也被称作Undo页面，这些页面会串成一个链表，称作Undo页面链表。在一个事务对应的Undo页面链表的首个页面中，记录了一些关于这个事务的一些属性。 Undo Log Segment Header部分 其中的TRX_UNDO_STATE字段就表明该事务目前处于什么状态。当处于Prepare阶段时，会将TRX_UNDO_STATE字段的值设置为TRX_UNDO_PREPARED（整数5），表明当前事务处在Prepare阶段。 Undo Log Header部分： 包括了各种信息，其中有两个属性 TRX_UNDO_XID_EXISTS：表示有没有xid信息 XID信息：表示具体的xid是什么 当处于Prepare阶段时，调用innobase_xa_prepare函数会将TRX_UNDO_XID_EXISTS设置为TRUE，并将本次内部XA事务的xid（这个xid是mysql自己生成的）写入XID信息处。 Commit阶段：先将事务执行过程中产生的binlog刷新到硬盘，再执行存储引擎的提交工作。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"MySql的锁","slug":"MySql的锁","date":"2024-04-21T07:23:11.000Z","updated":"2024-04-22T16:09:47.791Z","comments":true,"path":"2024/04/21/MySql的锁/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/04/21/MySql%E7%9A%84%E9%94%81/","excerpt":"","text":"行级锁 一致性读：事务利用MVVC进行读取操作称为一致性读（或者称为快照读），一致性读不会对表中任何记录加锁锁定读：通过加锁的方式 共享锁（S锁） 多个事务可以同时拥有共享锁，但是会排斥独占锁 1select ...... LOCK IN SHARE MODE; 如： 事务1拥有数据行的共享锁，此时事务2可以获取到该数据行的共享锁，但是如果事务2想要获取独占锁的话，会被阻塞，直到事务1释放共享锁后，才能获取到独占锁 独占锁（X锁） 只有一个事务可以获取到独占锁，会排斥其他共享锁、独占锁 1select ...... FOR UPDATE 如：事务1拥有数据行的独占锁后，此时事务2无论是想获取该数据行的共享锁还是独占锁都将被阻塞，直到事务1释放独占锁为止 表级锁 表级S锁 如果一个事务给表加了S（共享）锁，那么： 其他事务可以继续获得该表的S锁 其他事务可以继续获得表中数据行的S锁 其他事务不能获得继续获得该表的X锁 其他事务不能获得继续获得该表中数据行的X锁 1LOCK TABLES `table_name` READ; 表级X锁 如果一个事务给表加了X（独占）锁，那么： 其他事务不能继续获得该表的S锁 其他事务不能继续获得表中数据行的S锁 其他事务不能获得继续获得该表的X锁 其他事务不能获得继续获得该表中数据行的X锁 1LOCK TABLES `table_name` WRITE; 意向锁在对表加表级独占锁时，如何知道表中的数据行是否已经被加了行锁呢？ 意向共享锁（Intention Shared Lock）：IS锁，当事务准备在某条记录上加S锁时，需要先在表级别加一个IS锁 意向独占锁（Intention Exclusive Lock）：IX锁，当事务准备在某条记录上加X锁时，需要现在表级别加一个IX锁 IS锁、IX锁是表级锁，他们的作用仅仅是为了在之后加表级别的S锁和X锁时，可以快速判断表中的记录是否被上锁 元数据锁 MySQL使用元数据锁来管理对数据库对象的并发访问，并确保数据的一致性。元数据锁不仅适用于表，还适用于库、存储过程、函数、触发器等 官方文档解释 在对表执行DDL语句时，其实是通过Metadata Lock（MDL）来实现的。一般情况下，也不会使用Innodb引擎的表级锁。 比如：在对某个表执行ALTER TABLE等DDL语句时，其他事务对该表的SELECT、INSERT、DELETE、UPDATE等语句时，会发生阻塞。 不是所有的都会阻塞，某些情况下，MySql支持online ddl，提供了并发DML的支持，不会对其他事务的读写数据产生阻塞 AUTO_INC锁我们可以给表的某个列加上AUTO_INCREMENT属性，让其自增 系统在给该列递增赋值时，有两种方式，由系统变量innodb_autoinc_lock_mode控制，他有三个可选值 0：采用AUTO_INC锁，也就是在执行插入语句时，加一个表级别的AUTO_INC锁，然后为每条待插入记录的AUTO_INCREMENT列分配递增的值。在该语句执行结束之后（不是提交事务后），就会把AUTO_INC锁释放掉。 2：采用轻量级锁，在插入数据，生成AUTO_INCREMENT列的值时，获取这个轻量级锁，然后在生成本次插入语句需要的AUTO_INCREMENT值之后，就把这个锁释放掉，而不需要等到整个插入语句执行完成之后才释放锁 1：二者混用。当插入条数确定时，采用轻量级锁；当插入条数不确定时，采用轻量级锁采用AUTO_INC锁，如INSERT INTO ... SELECT 、REPLACE...SELECT等语句。 INNODB中的行级锁INNDODB中，有几种不同类型的行锁 LOCK_REC_NOT_GAP 就是最’’普通’的行锁。这种行锁有S锁和X锁的区分的 LOCK_GAP 间隙锁，顾名思义，会对数据行之间的间隙加锁 给一个数据行加上间隙锁之后，会锁住其前面的间隙，不允许其他事务在这个区间执行插入操作。给一条记录加gap锁，并不会影响其他事务对该条记录加行锁或者继续加gap锁 当我们给Supremum加上gap锁之后，表示从数据最大行 ~ +∞ 这区间，不允许插入数据 LOCK_ORDINARY 这种类型的锁，既可以锁住某条记录，也可以给它加gap锁，即可以阻止其他事务在该记录的前面的间隙插入新记录。 LOCK_INSERT_INTENTION 插入意向锁 一个事务在插入一条记录时，需要判断插入位置是否已被别的事务加了gap锁。如果有的话，插入操作需要等待，直到拥有gap锁的那个事务提交为止。在这个等待的过程中，也需要在内存中生成一个锁结构，表明有事务想在某个间隙中插入新记录，但是现在处于等待状态。 这种类型的锁命名为Insert Intention Lock。 隐式锁 一般情况下，执行INSERT语句是不需要在内存中生成锁结构的（如果当前插入的间隙已经被加了gap锁，那么本次insert操作会阻塞，并且当前事务会在该间隙上加入一个插入意向锁。） 如果当前插入的间隙没有加gap锁，那么当前事务不会为INSERT生成锁结构，但是如果有其他记录，想要获取这个数据，那该怎么办？ 情景1：对于聚簇索引记录来说，有一个trx_id隐藏列，该隐藏列记录着最后改动该记录的事务的事务id。 在当前事务中新插入一条聚簇索引记录后，该记录的trx_id隐藏列代表的就是当前事务的事务id。如果其他十五次是相对该记录添加S锁和X锁，首先会看一下该记录的trx_id隐藏列代表的事务是否是当前活跃事务。如果不是的话就可以正常读取。如果是的话，会帮当前事务创建一个X锁的锁结构，该锁结构的is_waiting属性为false；然后为自己也创建一个锁结构，该锁结构的is_waiting属性为true，之后自己进入等待状态。 情景2：对于二级聚簇索引来说，本身并没有trx_id隐藏列，但是在二级索引页面的Page Header部分有一个PAGE_MAX_TRX_ID属性，该属性代表对该页面做改动的最大的事务id。如果PAGE_MAX_TRX_ID属性值小于当前最小的活动事务id，那就说明对该页面做修改的事务都已经提交了，否则就需要在页面中定位到对应的二级索引记录，然后通过回表找到对应聚簇索引记录，然后再重复情景1的做法。 INNODB锁的内存结构对一条记录加锁的本质就是在内存中创建一个锁结构与之关联。 如果符合以下条件，这些记录的锁就可以放到一个锁结构中： 在同一个事务中进行加锁操作 被加锁的记录在同一个页面中 加锁的类型是一样 等待状态的是一样的 锁结构大致如下所示： 锁所在的事务信息：无论是表级锁还是行级锁，一个锁属于一个事务，这里记载着该锁对应的事务信息 锁所在的事务信息在内存结构中只有一个指针，所以不会占用多大内存空间。通过指针可以找到内存中关于该事务的更多信息 索引信息：对于行级锁来说，需要记录以下加锁的记录属于哪个索引 表级/行锁信息：表级锁结构和行级锁结构在这个位置内容是不同的 type_mode：锁的类型 语句加锁分析普通的select READ UNCOMMITTED：不加锁，直接读取记录的最新版本；可能出现脏读、不可重复读和幻读现象 READ COMMITTED：不加锁，在每次执行普通的select语句时，都会生成一个ReadView，这样避免了脏读现象，能避免脏读，但是不能避免不可重复读和幻读现象 REPEATABLE READ ：不加锁，只有在第一次执行select时，会生成ReadView SERIALIZABLE： autocommit = 0 时，普通的select语句会自动加上共享锁，也就是select ... lock in share mode。 autocommit = 1 时，即启用自动提交，不会加锁，利用MVVC生成ReadView来读取记录。（启用自动提交后，意味着一个事务中只包含一条语句，而一条语句不会出现可重复读、幻读的现象） 锁定读 SELECT … LOCK IN SHARE MODE SELECT … FOR UPDATE UPDATE … DELETE … update 和 delete 在执行过程中，需要首先定位到被改动的记录并给记录加锁，因此也能被认定为是一种锁定读 匹配模式（match mode） 在使用索引进行扫描时，查询优化器首先会生成若干个扫描区间。如果对于联合索引 [a，b]，有下面几种情况 精确匹配：如果形成扫描区间匹配时只有一个值，是一个单点扫描区间。比如where a = 1，扫描区间就是[1,1]。或者where a = 1 and b = 1，也属于精确扫描 不精确匹配：如果形成的扫描区间有多个值，比如 where a = 1 and b &gt; 1，扫描区间是 [(1,1), (1, +∞)]，这种就不算是单点扫描区间，这种匹配模式就是不精确匹配 唯一性搜索（unique search） 如果在扫描某个区间的记录前，就能事先确定该扫描区间内最多只包含一条记录的话，那么就把这种情况称作唯一性搜索 匹配模式为精确匹配 使用的索引是主键或唯一二级索引 如果使用的索引是唯一二级索引，并且搜索条件不能为”索引列IS NULL”的形式（因为唯一二级索引来说，可以存储多个值为NULL 的记录） 如果索引中包含多个列，那么在生成扫描区间时，每一个列都得被用到、 也就是说，搜索条件能够确定结果只有唯一一条 SELECT ... LOCK IN SHARE MODE加锁过程 隔离级别**不大于READ COMMITED**时，一般情况下，读取某个扫描区间中记录的过程如下： 首先快速在B+树叶子节点中定位到该扫描区间中的第一条记录，把该记录作为当前记录 为当前记录加S型行锁 判断索引条件下推的条件是否成立 索引下推：（index condition pushdown,ICP）把一些搜索条件下推到存储引擎中判断，而不是返回到Server层再判断。ICP只适用于二级索引，不适用于聚簇索引。仅适用于select语句，不适用update、delete 执行回表操作 如果扫描的是二级索引记录，则可能需要回表获取聚簇索引记录，并且给该聚簇索引记录加S型行锁 判断边界条件是否成立 server层判断条件是否成立 对于上述的查询过程来说，如果走的二级索引，会先将二级索引加行锁，并且回表后，还需要给聚簇索引记录加行锁 在隔离级别不大于READ COMMITED时，在扫描区间时，先给记录加锁，如果记录不满足条件时，则释放锁，如果记录满足条件，则不会释放锁 隔离级别**不小于REPETATABLE READ**时，对一个select语句来说 如果扫描的是聚簇索引，则： 在对区间扫描时，加的是S型的LOCK_ORDINARY，也就是行锁+gap锁。 如果扫到的记录符合条件，则不会释放锁；如果扫到的记录不符合条件，也不会释放锁。 如果先扫描二级索引，再回表扫描聚簇索引，则： 在对二级索引的区间扫描时，先对二级索引记录加上S型的LOCK_ORDINARY，也就是行锁+gap锁，然后回表找到聚簇索引对应行，对该聚簇索引记录加一个S型行锁。 存储引擎将查询到的聚簇索引记录返回给Server层，Server层判断记录是否符合条件，如果符合，则不会释放加在该记录上的锁 如果Server层判断记录不符合条件，则丢弃这条结果数据，并且也不会释放加在该记录上的锁 SELECT … FOR UPDATE语句加锁过程与上述的SELECT … LOCK IN SHARE MODE语句类似，只不过加的都是X锁 如果匹配模式是精确模式 隔离级别不大于READ_COMMITTED时，不会为扫描区间后面的下一条记录加锁 隔离级别不小于REPEATABLE_READ时，则会为扫描区间后面的下一条记录加gap锁 当隔离级别不小于REPEATABLE READ时，如果匹配模式不是精确匹配，并且没有找到精确匹配的记录，则会为该扫描区间后面的下一条记录加LOCK_ORDINARY（行锁+gap锁） 无论是哪个隔离级别，只要是唯一型搜索，并且读到的记录没有标记为’已删除’（记录头信息中的delete_flag = 1），就为读取到的记录加行锁 查看事务加锁情况1select * from information_schema.INNODB_TRX; trx_tables_locked：表级锁 trx_rwos_locked：加了多少个行级锁（不包含隐式锁） trx_lock_structs：表示该事务生成了多少个内存中的锁结构 系统中发生了某个事务因为想要获取锁而被阻塞的情况时，会在这个表中记录 tips：已过时，在MySql8.0中已经被移除 1select * from information_schema.INNODB_LOCKS; 1SHOW ENGINE INNODB STATUS;","categories":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/categories/MySql/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/tags/MySql/"}]},{"title":"MySql增加varchar长度","slug":"MySql增加varchar长度","date":"2024-04-17T11:29:10.000Z","updated":"2024-04-17T16:15:53.224Z","comments":true,"path":"2024/04/17/MySql增加varchar长度/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/04/17/MySql%E5%A2%9E%E5%8A%A0varchar%E9%95%BF%E5%BA%A6/","excerpt":"","text":"背景最近需要增加某个varchar字段的长度，由varchar(50)扩展为varchar(100)，但是表中数据很大，担心锁表，想到了MySql的online-DDL，于是测试了一下，发现了一些有趣的事情，记录一下。 varchar 先从varchar字段的存储方式说起，人们通常拿char和varchar对比，此处也一起探讨下。 官网文档对二者的说明 ​ char类型的字段长度固定，在建表时的申明就已经确定，长度范围在0 ~ 255，数据的真实长度不足时，会用空格填充。如果数据本身就带有空格，在检索时，会删除尾随的空格，除非开启sql_mode：PAD_CHAR_TO_FULL_LENGTH S ​ varchar是可变长字段，长度范围在0 ~ 65535。在数据行中的格式中，一般还会有个可变长字段长度列表，来记录变长字段存储的真实长度。 （针对某些行格式来说，如compact，如果采用的是不定长的编码字符集的话，比如gbk表示一个字符要1~2字节，mysql的utf8表示一个字符要1~3字符，此时char类型的字段的长度 也会被加到可变长字段长度列表中） 行格式 compact 如果表采用的是compact行格式，那每个数据行的格式如下 其中我们重点关注一下 变长字段长度列表 这个结构，需要注意的是，这个结构并不是在所有数据行都有，它只存储值不为空的列的长度。 也就是说，如果一行数据中，没有变长字段，或者所有的变长字段都为空，就不需要有这个结构 针对某一行的某一个varchar字段来说，如果他不为空的话，则在变长字段长度列表中，需要1~2个字节来存储其数据的长度，具体是一个字节还是两个字节，规则如下： 如果变长字段允许的最大长度不超过255，则使用一个字节存储 如果变长字段允许的最大长度超过了255，并且实际的长度超过了127字节时，需要两个字节去存储其长度 列为溢出列（下面解释何为溢出列） 比如针对 utf8mb4编码的行来说，varchar(30)，最多可以存储的字节为：4 * 30 = 120字节，此时在变长字段长度列表中，只需要一个字节存储其长度即可。 MySql对数据行的大小都有一定限制，如果变长字段存储的值很长，超过一定长度怎么办？ 针对这种很长、占用字节数很多的列，在记录真实数据处只会存储改列的一部分数据，而把剩余的数据存放在外部页中，然后用20字节指针指向外部页。这种列称为溢出列 针对compcat行格式来说，如果一列数据特别多，则只会存储前768字节的数据，然后将剩余数据记录在其他页中，数据格式如下： 需要注意的是，此时变长列表中记录的长度，是内部存储部分的长度 + 20字节指针。这里就是 768 + 20 所以不论数据多长，占用多少字节，都只需要两个字节存储其长度 dynamic dynamic行格式是compcat的变种，具有相同的存储特性。 在处理溢出页上，dynamic不会在记录的真实数据处存储该溢出列真实数据的前768字节，而是把所有真实数据都存储到溢出页中，只在记录的真实数据处存储20字节大小的指针。 online-ddl MySql 在线DDL功能，提供了一些特性，如： 更少的磁盘空间和I/O开销，尽可能少地加锁 官网地址 Extending VARCHAR column size 1ALTER TABLE *tbl_name* CHANGE COLUMN c1 c1 VARCHAR(255), ALGORITHM=INPLACE, LOCK=NONE; 值的注意的是：就地ALTER TABLE只支持将VARCHAR列的大小从0增加到255字节，或者从256字节增加到更大的大小。 原因就是上面所说的行格式。255字节时，只需要更改字段限制就好了。 如果我们把VARCHAR(50)更改VARCHAR(63)，假设行编码为utf8mb4，原长度为 50 * 4 &lt; 255，所以变长字段列表中只需要一个字节记录。修改后允许的最大长度为63字符，即最大字节为 63 * 4 = 252 &lt; 255。也只需要一个字节去记录长度，所以此时扩展其大小速度很快。 如果我们将大小修改为VARCHAR(100)，修改后允许的最大长度为100，即最大字节为 100 * 4 = 400 &gt; 255，此处是就需要两个字节去记录长度，所以此时扩展其大小速度比较慢，因为还需要调整每行的长度。 执行DDL语句时，可以通过以下语句查看锁情况 12345678910111213SELECT r.trx_id waiting_trx_id, r.trx_mysql_thread_id waiting_thread, r.trx_query waiting_query, b.trx_id blocking_trx_id, b.trx_mysql_thread_id blocking_thread, b.trx_query blocking_queryFROM information_schema.innodb_lock_waits w INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;","categories":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/categories/MySql/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/tags/MySql/"}]},{"title":"MySql的日志","slug":"MySql的日志","date":"2024-04-14T10:06:02.000Z","updated":"2024-04-21T07:23:27.958Z","comments":true,"path":"2024/04/14/MySql的日志/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/04/14/MySql%E7%9A%84%E6%97%A5%E5%BF%97/","excerpt":"","text":"binlog 二进制日志，记录了数据库发生的变化。如新建了一个数据库或者表、表结构发生改变、表中的数据发生了变化时都会记录相应的binlog日志。 主要作用 用于复制 MySql主从复制就依赖binlog，主服务器将数据同步给各个从服务器 用于恢复 数据误删后可以通过binlog恢复 配置可以通过如下命令查看是否当前服务器是否开启了binlog 1show variables like &#x27;log_bin&#x27;; binlog日志并不是仅写到一个文件中，而是写入一组文件中，这组文件的命名如下： 12345basename.000001basename.000002basename.000003basename.000004... 启动选项log-bin[=base_name]中的base_name就是这组binlog日志文件名称都包含的部分。 如果不配置basename，MySQL服务器会默认将主机名-bin作为binlog日志文件的basename。 除了这些真正存储的binlog日志文件以外，MySql服务器还会在相同的路径下生成一个关于binlog的索引文件。 文件名为.index结尾，同时他是他是一个文本文件，里面存储的是各个binlog文件的路径 查看binlogbinlog中记录数据库发生更改的各种事件（events），这些事件的种类非常多，我们熟悉的有： WRITE_ROWS_EVENT：插入记录。 UPDATE_ROWS_EVENT：更新记录。 DELETE_ROWS_EVENT：删除记录。 1234SHOW BINLOG EVENTS [IN &#x27;log_name&#x27;] [FROM pos] [LIMIT [offset,] row_count] [IN &#39;log_name&#39;]：log_name表示我们要查看哪个binlog日志文件的内容。 [FROM pos]：pos表示我们要查看binlog文件的起始偏移量（通过指定这个值可以直接去查看某个偏移量处的事件）。 offset表示我们要从哪个事件开始查看，row_count表示我们要查看多少个事件。 mysqlbinlog 由于binlog是二进制格式的，我们不能直接以文本的形式查看。使用SHOW BINLOG EVENTS又只能看到粗略的信息，如果我们想查看binlog日志文件的详细信息的话，就需要使用MySQL给我们提供的实用工具——mysqlbinlog。 1mysqlbinlog ./basename.000001 redolog 事务已经提交，但是还没有刷到磁盘，但是如果此时服务宕机，可能会造成数据丢失。 比如：数据刚提交，或者只更改了buffer pool中的数据，但是还没有刷新到磁盘，服务宕机，内存中的数据就没了。 redolog记录的就是，对数据的更改操作。如把某个页的地址偏移量为1000的数据更改为2。这样即使服务宕机，重启后，只需要按照redolog记录的步骤重新更新数据页即可。 为了让已经提交的事务对数据的更改能永久生效，即使服务器崩溃，也能通过redolog恢复 redolog是顺序写入磁盘的。 日志格式redolog本质上只是记录了一下事务对数据库进行了哪些修改。 MySql针对不同的修改场景，定义了多种类型的redo日志，但大部分类型的redo日志都有以下这种通用格式 type：这条redo日志的类型 space ID：表空间ID page number：页号 data：这条redo日志的具体内容 简单的日志类型有些极其简单的修改，只需要记录一些某个页面的某个偏移量处修改了几个字节、修改后的内容，这种极其简单的redolog称为物理日志，并且根据在页面中写入数据的多少划分为几种不同类型的redo日志类型. MLOG_1BYTE（type字段对应的十进制数字为1）：表示在某个页面偏移量处写了1字节的redo日志类型 MLOG_2BYTE（type字段对应的十进制数字为2）：表示在某个页面偏移量处写了2字节的redo日志类型 MLOG_4BYTE（type字段对应的十进制数字为4）：表示在某个页面偏移量处写了4字节的redo日志类型 MLOG_8BYTE（type字段对应的十进制数字为8）：表示在某个页面偏移量处写了8字节的redo日志类型 MLOG_WRITE_STRING（type字段对应的十进制数字为30）：表示在某个页面偏移量处写入1个 字节序列 的redo日志类型 对于MLOG_ n BYTE格式的日志，他们的通用日志格式如下： 对于``MLOG_WRITE_STRING`类型的日志来说，格式都差不多，只不过具体数据中包含的字节数量不同。格式如下： MLOG_WRITE_STRING类型的redolog因为不确定写入的具体数据占用多少字节，所以需要在日志结构中添加一个len字段。 复杂的日志类型对于一个INSERT语句来说，他对B+树的影响如下 表中有几个索引，一条INSERT语句就有可能更新多少棵B+树 针对一棵B+树来说，有可能只更新叶子节点，也有可能需要更新内节点页面，还可能新增内节点页面（比如新增后的页面不够了，需要页分类，此时就需要在内节点新增目录记录） 其实需要更新的东西很多，比如Page Director中的槽信息，Page Header中的各种统计信息，数据会按照索引列的大小排成一个单向链表，所以还需要更新上一条记录的记录头中的指针，也就是next record属性 针对这种比较复杂的更改，需要记录的东西太多，我们又不能把整个页面记录下来，太浪费了，于是就有了新的redolog日志类型 MLOG_REC_INSERT（type字段对应的十进制数字为9）：表示在插入一条使用非紧凑行格式（redundant）的记录时，redo日志的类型 MLOG_COMP_REC_INSERT（type字段对应的十进制数字为38）：表示在插入一条使用紧凑行格式（compact、dynamic、compressed）的记录时，redo日志的类型 MLOG_COMP_PAGE_CREATE（type字段对应的十进制数字为58）：表示在创建一个存储紧凑行格式记录的页面时，redo日志的类型 …… MLOG_COMP_REC_INSERT类型的redolog格式如下： Mini-Transication 以组的形式写入redolog 比如INSERT语句，再插入时，可能会产生很多条redolog；例如：再插入时，叶子节点空间不足，就需要页分裂，同时向父节点加一个目录项，如果此时父节点的页面空间也不足，就需要再次分裂。如果我们再插入的过程中，只记录了一部分的redolog，此时系统崩溃，待系统重启恢复后，按照redolog的记录去恢复，就会形成一条不正确的 B+ 树。 所以MySql为了保证这个操作的原子性，记录redolog时，都是以组的形式来记录。在进行恢复时，对于一个组内的redolog，要么全部恢复，要么一条都不会恢复。 如何区分日志属于哪一组呢？ MySql会在每个组的日志结尾处，插入一条特殊类型的redolog，叫做MLOG_MUTIL_REC_END，以这个日志结尾的就属于一组redolog redo log block一个MTR（Mini-Transication）生成的redo日志都放在了大小为512字节的页中，称为block。 redo block的格式示意图： LOG_BLOCK_HDR_NO：每一个block都有一个大于0的唯一编号，该属性就表示该编号值 LOG_BLOCK_HDR_DATA_LEN：表示block中已经使用了多少字节；初始值12（因为log block body从第12个字节处开始）。随着往block中写入的redo日志越来越多，该属性也跟着增长。 LOG_BLOCK_FIRST_REC_GROUP：一个redo日志也可以称为一条redo日志记录（redo log record）。一个MTR会生成多条redo日志记录，这个MTR生成的这些redo日志记录被称为一个redo日志记录组（redo log record group）。LOG_BLOCK_FIRST_REC_GROUP就代表该block中第一个MTR生成的redo日志记录组的偏移量，其实也就是这个block中第一个MTR生成的第一条redo日志记录的偏移量。 LOG_BLOCK_CHECKPOINT_NO：表示checkpoint的序列 LOG_BLOCK_CHECKSUM：表示该block的校验值，用于正确性校验。 log buffer​ 写入redo日志时，其实也是写在redo log buffer日志缓冲区的。 ​ MySql服务器在启动时就向操作系统申请了一大片连续的内存空间，称为redo log buffer日志缓冲区。这片连续的内存空间被划分若干连续的redo log block。 ​ 向log buffer中写入undo日志的过程中是顺序写入的，也就是先往前面的block中写，当该block的空闲空间用完之后再往下一个block中写。MySql维护了一个全局变量buf_free，记录偏移量，指明后续写入的redo日志应该写到log buffer中的哪个位置。 ​ 一个MTR执行过程中可能产生若干条redo日志，这些redo是一个不可分割的组，所以并不是每生成一条redo日志就该将其插入到log buffer中，而是将每个MTR运行过程中产生的日志暂存到一个地方；当该MTR结束时，再将过程中产生的一组redo日志全部复制到log buffer中。 redo日志刷盘时机 log buffer 空间不足时 log buffer的大小是有限的，通过系统变量innodb_log_buffer指定，当写入log buffer的redo日志超过log buffer总容量的50%时，就需要把这些日志刷新到磁盘中 事务提交时 为了持久性，也为了保证系统崩溃后，能够恢复事务对页面的更改 当某个脏页刷新到磁盘前，会保证先将该脏页对应的redo日志刷新磁盘中 因为redo日志是顺序写入的，所以将某个脏页对应的redo日志从redo log buffer刷新到磁盘时，也会保证在其之前产生的redo日志也刷新到磁盘 后台线程，定时刷新 大约以每秒1次的频率将log buffer中的redo日志刷新到磁盘 正常关闭服务器时 redo日志文件组使用命令 1show variables like &#x27;datadir&#x27;; 可以查看redo日志的保存文件位置。 默认在数据目录下的ib_logfile()和ib_logfile1()两个文件中 下面是关于redo log的一些参数 innodb_log_group_home_dir：指定了redo日志文件所在的目录，默认就是当前的数据目录 innodb_log_file_size：指定了每个redo日志文件的大小，在MySql5.7版本中的默认值就是48MB innodb_log_files_in_group：指定了redo日志文件的个数，默认值为2，最大值100 redo日志是循环写入日志文件的，也就是先写入第一个文件，第一个文件满了，再写入第二个文件，以此类推，当最后一个文件写满了时，再写入第一个文件。 所以可能会有覆盖的风险。（如何解决：checkpoint) checkpointredo日志文件格式log buffer本质上一片连续的内存空间，被划分为若干个512字节大小的block。将log buffer中的redo日志刷新到磁盘的本值就是把block镜像写入日志文件中，所以redo日志文件其实也是由若干个512字节大小的block组成。 在redo日志文件组中，每个文件格式大小都一样，都是由下面两部分组成： 前2048个字节（前4个block）用来存储一些管理信息 从第2048字节往后的字节用来存储log buffer中block镜像 前4个block的结构如下： log file header LOG_HEADER_FORMAT：4字节，redo日志的版本，在MySql5.7中基本都为1 LOG_HEADER_PAD1：4字节，用于字节填充，无实在意义 LOG_HEDAER_START_LSN：8字节，标记本redo日志文件偏移量为2048字节处对应的lsn值 LOG_HEADER_CRETOR：32字节 ，一个字节串，标记本redo日志文件的创建者是谁，正常运行时该值为MySql的版本号；在使用mysqlbackup命令创建redo日志文件时，该值为ibbackup和创建时间 LOG_BLOCK_CHECKSUM：4字节，本block的校验值；所有的block都有该值， checkpoint1 LOG_CHECKPOINT_NO：8字节，服务器执行checkpoint编号，每执行一次checkpoint，该值就加1 LOG_CHECKPOINT_LSN：8字节，服务器在结束checkpoint时对应的lsn值；系统崩溃后恢复将从该值开始 LOG_CHECKPOINT_OFFSET：8字节，上个属性中的lsn值在redo日志文件组中的偏移量 LOG_CHECKPOINT_LOG_BUF_SIZE：8字节，服务器在执行checkpoint操作时对应的log buffer的大小 LOG_BLOCK_CHECKSUM：4字节，本block的校验值；所有block都有该值 checkpoint2结构与checkpoint1一样 log sequence numberINNODB设计了一个为lsn(log sequence number)的全局变量，用来记录当前总共已经写入的redo日志量。 lsn的值为8704，也就是一条redo日志也没写入时，lsn的值就是8704 向log buffer中不断写入日志，其实是以MTR生成的一组redo日志为单位写入的，而且实际上是把日志写在了log buffe body处。但是在统计lsn的增长值时，是按照实际写入的日志量加上占用的log buffer header和log buffer trailer来计算的。 如下图：buf_free用来标记下一条redo日志应该写到log buffer中的哪个位置。 MTR1写完以后，对于MTR2，一个页面装不下，跨页了，此时，lsn的偏移量应该加上第一个block的 log block trailer和第二个block的log block header。 每一组由MTR生成的redo日志都有一个唯一的lsn值与其对应；lsn值越小，说明redo日志产生得越早。 flushed_to_disk_lsn全局变量flushed_to_disk_lsn，用来表示刷新到磁盘的redo日志的总量 lsn是用来记录redo日志在log buffer中的日志量 在系统第一次启动时，flushed_to_disk_lsn的值与lsn的值是相同的，都是8704。 随着系统的运行，flushed_to_disk_lsn的值，会逐渐被lsn甩开。因为先写log buffer，再刷新磁盘，毕竟磁盘的刷新没那么快，也没那么及时 他们的关系如下图： buf_next_to_write表示下一段将要刷新到磁盘的偏移量 个人理解：flushed_to_disk_lsn是全局累加的，记录系统总共刷新了多少日志量。 但是buf_next_to_write是一个指针，用于记录当前刷新到了哪里，随着log buffer清空，这个值也会被复位，指向log buffer开头 如果lsn的值和flushed_to_disk_lsn的值相同，则表示所有的redo日志都刷新到了磁盘。 flush链表中的lsn 当第一次修改buffer pool中的某页面时，会把该页面对应的控制块加入到flush链表的头部。（之后再次修改时，由于已经存在flush链表中，所以不再插入了）。也就是说，flush链表中的脏页按照页面的第一次修改时间进行排序的，。 在flush链表的控制块中，记录着两个关于页面何时修改的属性。 oldest_modification：第一次修改buffer pool中某个缓冲页时，就将修改该页面的MTR开始时的lsn值写入这个属性 newest_modification：每修改一次页面，都会将 修改该页面的MTR结束时对应的lsn值写入这个属性。也就是说，该属性表示页面最近一次需修改后对应的lsn值 checkpointredo日志文件是有限的，循环写入时，可能新的内容会覆盖旧的内容 redo日志只是为了在系统崩溃后恢复脏页用的，如果对应的脏页已经被刷盘了，那么即使现在系统崩溃后，重启后也没必要使用redo日志恢复该页面了。也就是说该段redo日志就没用的了。 所以判断某个redo日志占用的磁盘空间是否可以被覆盖，就是看对应脏页是否已经被刷新到磁盘 MySql维护一个全部变量checkpoint_lsn，用来表示当前系统中可以被覆盖的redo日志总量是多少。当某个MTR生成的redo日志，被刷新到磁盘中，那么就可以执行一个增加checkpoint_lsn操作，这个操作称为执行一个checkpoint 执行一个checkpoint可以分为两个步骤 计算当前系统中可以被覆盖的redo日志对应的lsn值最大是多少 将checkpoint_lsn与对应的redo日志文件组偏移量以及此次checkpoint的编号写到日志文件的管理信息（checkpoint1或者checkpoint2）中 MySql维护了一个checkpoint_no变量，用来统计目前系统执行了多少次checkpoint；每执行一次checkpoint，该变量的值就加1。 当checkpoint_no的值是偶数时，就写到checkpoint1中，是奇数时，就写到checkpoint2中 查看系统中的各种lsn值1show innodb engine status; -–LOG-–Log sequence number 78434369Log flushed up to 78434369Pages flushed up to 78434369Last checkpoint at 784343600 pending log flushes, 0 pending chkp writes98 log i/o’s done, 0.00 log i/o’s/second-——————— Log sequence number：表示系统中的lsn值，也就是当前系统已经写入的redo日志量，包括写入到log buffer中的redo日志 Log flushed up to：表示flused_to_disk_lsn值，也就是当前系统已经写入磁盘的redo日志量 Pages flushed up to：表示flush链表中最早被修改的那个页面对应的old_nodification属性值 Last checkpoint at：表示当前系统的checkpoint_lsn值 innodb_flush_log_at_trx_commit该系统变量innodb_flush_log_at_trx_commit的系统变量的值 0：表示在事务提交时，不立即向磁盘同步redo日志，这个任务交给后台线程来处理。 1：表示在事务提交时需要将redo日志同步到磁盘。默认值就是1 2：当该系统变量的值为2时，表示在事务提交时，需要将redo日志写到操作系统的缓冲区中，但并不需要保证将日志真正地刷新磁盘。 undolog 用于事务回滚后的数据恢复 比如： 对于insert语句，我们把这条记录的主键值记下来，回滚时只需要把这条记录删掉即可 对于delete语句，我们把这条记录的内容都记下来，回滚时再把这些内容组成的记录插入到表里就好了 对于update语句，需要把更新前的旧值记下来，回滚时把这些列更新为旧值即可 select语句并不会修改任何记录，所以也不会产生undolog 事务id 只读事务：START TRANSCATION READ ONLY开启只读事务，在只读事务中，不允许对普通的表进行增删改操作，但是可以对用户临时表进行增删改操作。（这里说的用户临时表是指 create temporary table创建的表，不是语句执行过程中的那个using temporary，那个是系统临时表） 读写事务：START TRANSCATION READ WRITE开启读写事务，BEGIN和START TRANSCATION语句开启的也是读写事务。在读写事务中可以对表进行增删改操作。 如果某个事务，在执行过程中，对某个表执行了写操作，也就是增删改，那么InnoDB存储引擎就会给它分配一个第一无二的事务id。 对于只读事务来说，只有第一次对用户临时表进行增删改时，才会对其分配一个事务id。如果没有更改，则不会分配 对于读写事务来说，只有它第一次对某个表执行增删改操作时，才会为这个事务分配一个事务id，否则不分配事务id 日志格式insert操作对应的undo日志 insert语句导致的结果就是插入了一条记录，回滚操作就是把这条记录删除就好了。所以我们只要把这条记录的主键信息记录上就好了 MySql类型为TRX_UNDO_INSERT_REC的undo日志，其完整结构如下 undo no：在一个事务是从0开始递增的。事务没提交时，每生成一条undo日志，那么该条日志的undo no就加1 table id：每个表都会分配一个唯一的table id，可以通过infomation_schema的innodb_sys_tables表来查看对应的table id 如果记录中主键只包含一列，那么在类型为TRX_UNDO_INSERT_REC的undo日志中，只需要把该列占用的存储空间大小和真实值记录下来。如果记录中的逐渐包含多个列，那么每个列占用的存储空间大小和对应的真实值都需要记录下来。（真实值就是指 对应的主键id） 在向表中插入一条记录时，其实聚簇索引和二级索引都需要插入记录。不过在记录undo日志时，只需要根据聚簇索引记录一条undo日志就好了。 by the way：innodb行格式 聚簇索引的记录除了会记录完整的用户数据以外，还会记录几个隐藏列： row_id就是隐藏id，不是必须的 这个roll_pointer，其实本质就是一个指向记录对应的undo日志指针。 当我们在一次事务中，插入了两条记录后，假如分配的事务id为100，其对应的关系如下图 delete操作对应的undo日志数据页中的数据会根据记录头中的next_record属性组成一个单向链表。 被删除的记录也会根据记录头中的next_record属性组成一个链表，不过这个链表中的记录占用的存储空间可以被重新利用，所以这个链表也被称为垃圾链表 Page Header部分中有一个名为PAGE FREE的属性，它指向垃圾链表的头节点 数据行中的记录头信息中，有一个delete_flag标识，用来标记数据是否被删除。 假如现在数据状态如下： 我们要把正常记录的最后一条记录删掉，这个删除过程需要经历两个过程 阶段1：仅仅将该记录的delete_flag标识位设置为1。这个过程称为delete mark 其实也会修改trx_id、roll_pointer这些隐藏列的值 阶段2：当该删除语句提交事务后，会有专门的线程来真正地把记录删除掉（也就是将记录移到垃圾链表）。这个过程阶段称为purge 被删除的记录，以头插法加到垃圾链表的头节点 在阶段2执行完成之后，这条记录就算是被真正删除了，占用的存储空间也就可以被重新利用了。 事务一旦提交，也就不需要考虑回滚的事了，所以只需要针对第一阶段delete mark进行回滚就好了 MySql设计了一种名为TRX_UNDO_DEL_MARK_REC类型的undo日志 在对一条记录进行delete mark操作之前，需要把该记录的trx_id和roll_pointer隐藏列的旧值都记录到对应的undo日志中的 trx_id 和 roll_pointer属性中。 这样可以通过undo日志的roll pointer属性找到上一次对该记录进行改动时产生的undo日志 比如：现在有两个事务，一个对其更新，一个对其删除，更新在前，删除在后，删除后如果要回滚，应该回滚到更新后的状态，这个东西其实就是版本链 索引各列信息：如果某个列，加到了索引列中，就会把索引的相关信息记录到这里。 &lt;pos，len, value&gt;：pos表示该列在记录中的位置，len该列占用的存储空间大小，value表示该列实际值 update操作对应的undo日志 不更新主键 就地更新（in-place update) 在更新时，对于被更新的列来说，如果更新前后 占用的存储空间一样大，那么就可以直接在原记录的基础上修改对应列的值（必须一样大，更新后存储空间变大或变小，都不能就地更新） 先删除旧记录，再插入新记录 如果更新前后占用的存储空间大小不一致，就需要先把这条旧记录删除，再根据更新后的值插入一条新记录 这里说的删除不是delete mark，而是真正的删除，也就是加入到垃圾链表。这里执行删除操作的也并不是delete语句中进行purge操作时使用的后台线程，而是用户线程执行的同步删除 如果新创建的记录占用的存储空间不超过旧记录占用的存储空间，那么可以直接重用旧记录的存储空间；否则需要在页面中新申请一块记录供新记录使用 针对这种不更新主键的情况（包括上面两种情况），MySql设计了一种类型为TRX_UNDO_UPD_EXIST_REC类型的undo日志 如果update语句中更新的列包含了索引列，那么就会添加”索引列各列信息”这个部分，否则不会添加这个部分 更新主键 在聚簇索引中，记录按照主键值的大小连成一个单向链表。如果更新了主键，那么这个主键在聚簇索引中的位置将要发生变化。 对于这种更新主键的update语句，分两步进行处理 将旧记录执行delete mark操作 根据更新后各列的值，创建一条新记录，插入到聚簇索引中 如果被更新的列包含了二级索引列。就需要更新二级索引的数据 将旧记录执行delete mark操作 根据更新后各列的值，创建一条新的二级索引记录，插入到二级索引中 FIL_PAGE_UNDO_LOGundo日志存放在类型为 FIL_PAGE_UNDO_LOG的页面中。这种页面的通用结构如下： Undo Page HeaderUndo Page Header是undo日志独有的，结构如下 TRX_UNDO_PAGE_TYPE：本页面存放的undo日志类型 undo日志主要分为两个大类 TRX_UNDO_INSERT：一般由insert语句产生，更新语句更新主键时也会产生此类型的undo日志，TRX_UNDO_INSERT_REC的undo日志就属于这个大类。（这种类型的日志，在事务提交之后，可以直接删掉。下面这个类型的还需要为MVVC服务） TRX_UNDO_UPDATE：除了类型为TRX_UNDO_INSERT_REC的undo日志，其他类型的undo日志都属于这个大类。一般由DELETE、UPDATE语句产生的undo日志都属于这个大类。 TRX_UNDO_PAGE_TYPE属性的可选值就是上面两个，用来标记本页面用于存储哪个大类的undo日志。不同大类的undo日志不能混着存储。 TRX_UNDO_PAGE_START：第一条undo日志在本页面中的起始偏移量。 TRX_UNDO_PAGE_FREE：与上面的TRX_UNDO_PAGE_START对应，表示当前页面中存储的最后一条undo日志结束时的偏移量。 TRX_UNDO_PAGE_NODE：代表一个链表节点结构。 undo页面链表一个事务可能包含多个语句，一个语句也可能对多个聚簇索引的记录进行改动。在对每条聚簇索引记录改动前，都需要记录1条或2条undo日志。 一个事务执行过程中可能产生很多undo日志。这些日志可能一个页面放不下，需要放到多个页面中，这些页面通过TRX_UNDO_PAGE_NODE属性连成一个链表 一个事务执行过程中，可能会混合执行多种类型的语句，产生不同类型的undo日志。但是一个undo页面只能存储一个类型的undo日志。 所以一个事务的执行过程中，可能需要两个undo页面的链表。一条insert undo链表，另一条称为unpdate undo链表。 在对普通表和用户临时表的记录改动时所产生的undo日志要分别记录。所以一个事务最多有4个以undo页面为节点组成的链表。","categories":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/categories/MySql/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/tags/MySql/"}]},{"title":"InnoDB-BufferPool","slug":"MySql-BufferPool","date":"2024-04-14T06:55:16.000Z","updated":"2024-04-14T09:50:58.500Z","comments":true,"path":"2024/04/14/MySql-BufferPool/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/04/14/MySql-BufferPool/","excerpt":"","text":"其实就是一片连续的内存缓冲区，用于缓解CPU和磁盘的速度矛盾。 数据从磁盘加载出来后，会放到BufferPool中缓存起来，下次需要读取相同的页面时，直接从内存中获取即可。 BufferPoll的组成BufferPool会将一片连续的内存划分为若干个页面，页面大小与InnoDB表空间大小一致，也就是默认16KB， 每一个缓冲页对应一个控制块，记录了页面的一些元数据，比如该页面所属的表空间号，页号，缓冲页的物理地址等。 控制块也在BufferPool的内存中，放在缓冲页的前面，如下图 Free链表 为了知道哪一个缓冲页是空闲可用的。 MySql会将所有空闲的缓冲页的对应的控制块 作为一个节点放到链表中串起来，这个链表就是free链表（或空闲链表）. 在MySql服务刚刚启动时，会向操作系统申请一片连续的内存空间用于BufferPoll，将他划分为控制块和缓冲页，此时所有的缓冲页都是空闲可用的，即所有缓冲页（的控制块）都处于free链表中。当有数据需要加载进BufferPoll中时，从free链表中获取一个空闲的缓冲页，并将数据所对应的表空间、页号等信息填入缓冲页的控制块中，最后将该缓冲页对应的控制块从free链表中移除。 如何知道数据页是否在缓冲页中?在访问某个页的数据时，如果数据页已经被加载进BufferPool了，就不会再从磁盘读取数据，那么如何知道数据页已经被加载了呢？ 加载磁盘数据时，其实是通过表空间号 + 页号来定位一个唯一页面的。 MySql会维护一个hash表，hash表的key就是 表空间号 + 页号，value就是缓冲页控制块的地址。 当需要访问某个页面时，根据key从hash表中查找，如果value不为空，则直接访问内存中的数据； 如果value为空，则从磁盘加载页数据后，从free链表中获取一个缓冲页，将其缓存起来。 Flush链表 解决缓存一致性的问题 当某个要修改某行数据时，如果该页的数据已经被加载进BufferPoll了，那MySql只会先修改buffer pool中的数据，不会立马更新磁盘，那么该修改过的缓冲页就被称为脏页（Dirty Page）。 如果要修改二级索引数据，并且二级索引数据页不在buffer pool中，MySql会将其修改保存到change buffer中，待下次查询出来时，将其结果合并。change buffer属于buffer pool中的一小部分，change buffer只支持二级索引！ Mysql会维护一个flush链表，来管理这些脏页，由后台线程定期将脏页中的数据刷到磁盘 跟free链表结构差不多，flush链表也会将 脏页对应的控制块作为节点 LRU链表 缓冲页的淘汰策略 buffer pool的内存大小有限，总会有用完的一天，如果缓冲页全部被用完了怎么办呢？ MySql基于变种的LRU算法。将已经使用了的缓冲页对应的控制块串起来，用特定算法去淘汰掉最近最少使用的缓冲页。 free链表中的控制块一定不在LRU链表中，但是flush链表中的控制块一定在LRU链表中。 InnoDB的预读 有点空间局部性和时间局部性的味道 线性预读：当顺序访问某个区的页面超过了innodb_read_ahead_threshold的值，就会触发异步读取下一个区中的全部页面到Buffer Pool中 随机预读：如果某个区的13个连续的页面都已经被加载到了Buffer Pool中，就会触发一次异步读取本区的其他所有页面到Buffer Pool中。随机预读默认关闭，需要通过innodb_random_read_ahead开启。 预读可能导致 许多无用页面被加载到Buffer Pool中，影响到缓冲页的淘汰 MySql将LRU链表按照一定比例划分为两个区域 young区域：存储使用频率较高的缓冲页，这部分链表也称为热数据 old区域：存储使用频率不是很高的缓冲页，这部分链表也称为冷数据 当磁盘上的某个数据页在初次加载到Buffer Pool中时，该缓冲区对应的磁盘块会放到old区域的头部。如果该页面不进行后续访问，会逐渐从old区逐出，而不会影响到young区域中使用较频繁的缓存页。 对于全表扫描来说，短时间内访问大量使用频率非常低的页面（一个页面很有很数据，每次获取数据都相当于访问一次页面）。如果访问old区某个缓冲页的时间点，相较于上次访问的时间间隔 小于innodb_old_blocks_time的值，则不会将该old区的数据移动到young区。 只有访问的缓冲页位于young区域的1/4的后面时，才会被移动到LRU链表头部。这样可以降低调整链表的频率，提高性能 https://dev.mysql.com/doc/refman/5.7/en/innodb-change-buffer.html innodb_buffer_pool_instances在多线程环境下，访问Buffer Pool的各种链表都需要加锁，锁粒度较大，影响效率。于是可以将一个大的Buffer Pool拆成若干个小的Buffer Pool，每个Buffer Pool都是称为一个实例，他们是相互独立的——独立申请内存，独立管理各种链表。 可以通过修改系统参数 innodb_buffer_pool_instances的值来修改Buffer Pool实例的个数 innodb_buffer_pool_chunk_sizeMySql在申请buffer pool的内存时，是以一个chunk为单位向操作系统申请空间的，一个chunk就代表一片连续的内存空间。 一个Buffer Pool实例其实就是由若干个chunk组成的 我们可以通过修改参数innodb_buffer_pool_chunk_size来调整chunk的大小 tips innodb_buffer_pool_size的值 必须是 innodb_buffer_pool_chunk_size * innodb_buffer_pool_instances的倍数（主要为了保证每个Buffer Pool实例中的chunk数量相同 查看Buffer Pool信息可以通过语句show innodb engine status来查看innodb存储引擎运行过程中的一些状态信息，其中就有Buffer Pool的信息（也可以查看死锁等信息） 下面是部分信息 1234567891011121314151617181920----------------------BUFFER POOL AND MEMORY----------------------Total large memory allocated 8585216Dictionary memory allocated 229735Buffer pool size 512Free buffers 254Database pages 256Old database pages 0Modified db pages 0Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages made young 0, not young 00.00 youngs/s, 0.00 non-youngs/sPages read 480, created 57, written 1280.00 reads/s, 0.00 creates/s, 0.76 writes/sBuffer pool hit rate 1000 / 1000, young-making rate 0 / 1000 not 0 / 1000Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/sLRU len: 256, unzip_LRU len: 0I/O sum[34]:cur[0], unzip sum[0]:cur[0] Total memory allocated：代表Buffer Pool向操作系统申请的连续内存空间大小，包括全部控制块、缓存页、以及碎片的大小。 Dictionary memory allocated：为数据字典信息分配的内存空间大小，注意这个内存空间和Buffer Pool没啥关系，不包括在Total memory allocated中。 Buffer pool size：代表该Buffer Pool可以容纳多少缓存页，注意，单位是页！ Free buffers：代表当前Buffer Pool还有多少空闲缓存页，也就是free链表中还有多少个节点。 Database pages：代表LRU链表中的页的数量，包含young和old两个区域的节点数量。 Old database pages：代表LRU链表old区域的节点数量。 Modified db pages：代表脏页数量，也就是flush链表中节点的数量。 Pending reads：正在等待从磁盘上加载到Buffer Pool中的页面数量。 当准备从磁盘中加载某个页面时，会先为这个页面在Buffer Pool中分配一个缓存页以及它对应的控制块，然后把这个控制块添加到LRU的old区域的头部，但是这个时候真正的磁盘页并没有被加载进来，Pending reads的值会跟着加1。 Pending writes LRU：即将从LRU链表中刷新到磁盘中的页面数量。 Pending writes flush list：即将从flush链表中刷新到磁盘中的页面数量。 Pending writes single page：即将以单个页面的形式刷新到磁盘中的页面数量。 Pages made young：代表LRU链表中曾经从old区域移动到young区域头部的节点数量。 这里需要注意，一个节点每次只有从old区域移动到young区域头部时才会将Pages made young的值加1，也就是说如果该节点本来就在young区域，由于它符合在young区域1/4后边的要求，下一次访问这个页面时也会将它移动到young区域头部，但这个过程并不会导致Pages made young的值加1。 Page made not young：在将innodb_old_blocks_time设置的值大于0时，首次访问或者后续访问某个处在old区域的节点时由于不符合时间间隔的限制而不能将其移动到young区域头部时，Page made not young的值会加1。 这里需要注意，对于处在young区域的节点，如果由于它在young区域的1/4处而导致它没有被移动到young区域头部，这样的访问并不会将Page made not young的值加1。 youngs/s：代表每秒从old区域被移动到young区域头部的节点数量。 non-youngs/s：代表每秒由于不满足时间限制而不能从old区域移动到young区域头部的节点数量。 Pages read、created、written：代表读取，创建，写入了多少页。后边跟着读取、创建、写入的速率。 Buffer pool hit rate：表示在过去某段时间，平均访问1000次页面，有多少次该页面已经被缓存到Buffer Pool了。 young-making rate：表示在过去某段时间，平均访问1000次页面，有多少次访问使页面移动到young区域的头部了。 需要大家注意的一点是，这里统计的将页面移动到young区域的头部次数不仅仅包含从old区域移动到young区域头部的次数，还包括从young区域移动到young区域头部的次数（访问某个young区域的节点，只要该节点在young区域的1/4处往后，就会把它移动到young区域的头部）。 not (young-making rate)：表示在过去某段时间，平均访问1000次页面，有多少次访问没有使页面移动到young区域的头部。 需要大家注意的一点是，这里统计的没有将页面移动到young区域的头部次数不仅仅包含因为设置了innodb_old_blocks_time系统变量而导致访问了old区域中的节点但没把它们移动到young区域的次数，还包含因为该节点在young区域的前1/4处而没有被移动到young区域头部的次数。 LRU len：代表LRU链表中节点的数量。 unzip_LRU：代表unzip_LRU链表中节点的数量（由于我们没有具体唠叨过这个链表，现在可以忽略它的值）。 I/O sum：最近50s读取磁盘页的总数。 I/O cur：现在正在读取的磁盘页数量。 I/O unzip sum：最近50s解压的页面数量。 I/O unzip cur：正在解压的页面数量。","categories":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/categories/MySql/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/tags/MySql/"}]},{"title":"程序OOM时soft-reference没有被回收?","slug":"程序OOM时soft-reference没有被回收","date":"2024-03-30T14:57:37.000Z","updated":"2024-03-30T16:36:21.523Z","comments":true,"path":"2024/03/30/程序OOM时soft-reference没有被回收/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/03/30/%E7%A8%8B%E5%BA%8FOOM%E6%97%B6soft-reference%E6%B2%A1%E6%9C%89%E8%A2%AB%E5%9B%9E%E6%94%B6/","excerpt":"","text":"背景最近在编写一块缓存代码时，想到了软引用，但是不太清楚软引用究竟在什么时候会被回收，于是就写了一块测试代码 JDK1.8 -Xms60m -Xmx60m 123456789101112131415161718192021222324252627282930313233public class Test &#123; public static SoftReference&lt;byte[]&gt; cache = new SoftReference&lt;&gt;(new byte[0]); public static List&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); public static void main(String[] args) &#123; try &#123; func(); &#125; catch (OutOfMemoryError e) &#123; sniff(); e.printStackTrace(); &#125; &#125; public static void func() &#123; byte[] bytes = new byte[1024 * 1024]; cache = new SoftReference&lt;&gt;(bytes); for(;;) &#123; byte[] tmp = new byte[1024 * 1024]; list.add(tmp); &#125; &#125; public static void sniff() &#123; byte[] bytes = cache.get(); if (bytes == null) &#123; System.out.println(&quot;recycling data.&quot;); &#125; else &#123; System.out.println(&quot;object still live&quot;); &#125; &#125;&#125; 通过不断往list填充 大小为1M的字节数组，为了让程序发生OOM，并且在捕获OutOfMemoryError时，来观测软引用的对象是否被回收了 （cache.get() == null就说明软引用关联的对象，在即将OOM时，被GC回收了） 但是程序运行结果如下： object still live 说明在发生OOM时，GC并没有去回收这个软引用对象 原因什么叫软可达对象softly reachable 官网给出的原文如下： An object is softly reachable if it is not strongly reachable but can be reached by traversing a soft reference. oracle官方文档链接 很重要的一点，not strongly reachable，不被强引用关联! 上述例子中，就是因为 new byte[1024 * 1024] 除了被软引用关联外，还被变量bytes的强引用关联，所以，即使到最后发生了OOM，Garbage Collector也不会去回收它。 将代码改为 1234567public static void func() &#123; cache = new SoftReference&lt;&gt;(new byte[1024 * 1024]); for(;;) &#123; byte[] tmp = new byte[1024 * 1024]; list.add(tmp); &#125; &#125; 不再使用变量去关联new byte[1024 * 1024], 而是直接将他添加到引用对象中 程序运行结果： recycling data 软引用对象被正常回收 补充在上述例子中，如果将代码改为如下 123456789101112131415161718192021222324252627282930313233public class Test &#123; public static SoftReference&lt;byte[]&gt; cache = new SoftReference&lt;&gt;(new byte[0]); public static List&lt;byte[]&gt; list = new ArrayList&lt;&gt;(); public static void main(String[] args) &#123; try &#123; func(); &#125; catch (OutOfMemoryError e) &#123; sniff(); e.printStackTrace(); &#125; &#125; public static void func() &#123; for(;;) &#123; byte[] tmp = new byte[1024 * 1024]; list.add(tmp); byte[] bytes = new byte[1024 * 1024]; cache = new SoftReference&lt;&gt;(bytes); &#125; &#125; public static void sniff() &#123; byte[] bytes = cache.get(); if (bytes == null) &#123; System.out.println(&quot;recycling data.&quot;); &#125; else &#123; System.out.println(&quot;object still live&quot;); &#125; &#125;&#125; 也就是将 byte[] bytes = new byte[1024 * 1024]; cache = new SoftReference&lt;&gt;(bytes); 这两行代码放入for循环里面，list.add(tmp)后面 程序运行结果： recycling data. 又懵了呀！ 按照我们上述的分析来说，这里也有一个强引用bytes关联这个数组，为什么发生OOM时软引用还能被回收呢？ 因为这个例子有点特殊，事先说明一点，程序是运行到这一行发生的OOMbyte[] bytes = new byte[1024 * 1024]; 可以将代码加上几个打印点 1234567891011public static void func() &#123; for(;;) &#123; System.out.println(&quot;before&quot;); byte[] tmp = new byte[1024 * 1024]; list.add(tmp); System.out.println(&quot;add&quot;); byte[] bytes = new byte[1024 * 1024]; System.out.println(&quot;after&quot;); cache = new SoftReference&lt;&gt;(bytes); &#125;&#125; 程序是在输出add之后发生的OOM，但是并没有输出after 值得注意的是，在循环中，bytes所指向的对象一直在变化。 如图：在执行完某一次循环的最后一行代码后，对象的指针如下 紧接着继续循环，代码执行到byte[] bytes = new byte[1024 * 1024];时，对象的关系如下 此时，软引用所指向的对象 并没有强引用的关联关系，如果此时发生内存紧张，那么软引用所引用的对象就会被回收。 顺便一提，如果将那两行代码放在循环体的开始，程序运行结果又会不一样，究其原因还是当即将发生OOM时，软引用变量所持有的对象究竟有没有被强引用所关联。 在上述例子中，bytes变量所持有的对象的生命周期只在一个循环中，下次循环会被覆盖，原先的引用关系被断开。而list.add(tmp)，tmp所指向的对象一直被添加到static申明的变量中，生命周期也就和static变量一样 致谢感谢stackOverFlow上的这位老哥的答疑 原帖链接如下：（请忽略作者的垃圾英语水平） https://stackoverflow.com/questions/78247787/java-softreference-soft-references-were-not-collected-before-the-occurrence-of","categories":[{"name":"java","slug":"java","permalink":"http://c89757.gitee.io/colinstar/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://c89757.gitee.io/colinstar/tags/java/"},{"name":"GC","slug":"GC","permalink":"http://c89757.gitee.io/colinstar/tags/GC/"}]},{"title":"记-升级mariadb-java-client引发的问题","slug":"记-升级mariadb-java-client引发的问题","date":"2024-03-11T11:05:10.000Z","updated":"2024-03-11T11:39:04.373Z","comments":true,"path":"2024/03/11/记-升级mariadb-java-client引发的问题/","link":"","permalink":"http://c89757.gitee.io/colinstar/2024/03/11/%E8%AE%B0-%E5%8D%87%E7%BA%A7mariadb-java-client%E5%BC%95%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"背景项目中使用flywaydb作为数据库迁移工具 但是在执行一段DDL语句时，引发了报错 语句如下： 1ALTER TABLE table_name MODIFY COLUMN column_name data_type NOT NULL DEFAULT 1; 该字段之前默认NULL，现将其改为NOT NULL 执行却报错：Invalid use of null value; 排错网上查了下，因为表中已经存在了NULL值，所以不允许将其修改为NOT NULL。 但是，将这段脚本直接放到navicat中却能执行成功。 到此开始怀疑是项目升级mariadb-java-client至2.7.10导致的。且这种语句执行结果的差异化，大多和sql_mode有关。 查询mysql官网 https://dev.mysql.com/doc/refman/5.7/en/sql-mode.html 没有明确找到针对词条语句有做差异化的sql_mode，推测是与严格模式有关——STRICT_TRANS_TABLES; 在navicat中，查看sql_mode 12SELECT @@GLOBAL.sql_mode;SELECT @@SESSION.sql_mode; 结果都为空 设置session级别的sql_mode 1SET SESSION sql_mode = sys.list_add(@@session.sql_mode, &#x27;STRICT_TRANS_TABLES&#x27;); 设置完后，再次执行脚本，问题复现Invalid use of null value; 解决方案 可以在DDL之前，通过update语句，将全部的NULL值修改为不为NULL 在执行DDL之前，判断是否开启了STRICT_TRANS_TABLES, 如果有开启，可以先将其移除，DDL执行之后再将其加回来 123SET SESSION sql_mode = sys.list_drop(@@session.sql_mode, &#x27;STRICT_TRANS_TABLES&#x27;);&#123;&#123;DDL&#125;&#125;;SET SESSION sql_mode = sys.list_add(@@session.sql_mode, &#x27;STRICT_TRANS_TABLES&#x27;); 修改项目中数据库的URL连接串，添加参数jdbcCompliantTruncation=false 这个是通过源码发现的，当这个值为true时（默认为true)，mariadb连接mysql时，会添加上session级别的STRICT_TRANS_TABLES, 所以将他关掉即可。另外，开启这个值后，还影响一些其他功能，如：插入时，字段超长，将不会报错，而是截取","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"mysql事务隔离级别与MVVC","slug":"mysql事务隔离级别与MVVC","date":"2023-09-26T15:20:25.000Z","updated":"2024-04-20T17:46:01.226Z","comments":true,"path":"2023/09/26/mysql事务隔离级别与MVVC/","link":"","permalink":"http://c89757.gitee.io/colinstar/2023/09/26/mysql%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B8%8EMVVC/","excerpt":"","text":"一致性问题事务并发执行时会遇到的一致性问题 脏写 一个事务修改了另一个未提交事务修改过的数据 脏读 一个事务读到了另一个未提交事务修改过的数据 事务T1修改了数据项X的值，然后事务T2又读取了未提交事务T1针对数据项X修改后的值，之后T1中止，而T2提交，这就意味着T2读到了一个根本不存在的值。 不可重复读 一个事务修改了另一个未提交事务读取的数据 事务T1先读取了数据项X的值，然后T2又修改了未提交事务T1读取的数据项X的值，之后T2提交，然后T1再次读取数据项X的值时，会得到与第一次读取时不同的值。 幻读 一个事务先根据某些搜索条件查询出一些记录，在该事务未提交时，另一个事务写入了一些符合那些搜索条件的记录（可以是INSERT、DELETE、UPDATE操作），就意味着发生了幻读现象 T1先读取符合搜索条件P的记录，然后T2写入了符合条件P的记录。之后T1再次读取符合搜索条件P的记录时，会发现两次读取的记录是不一样的。 SQL标准中的四种隔离级别上述一致性问题，会对事务的一致性产生不同程度的影响。按照可能导致一致性问题的严重性给这些现象排一下序： 脏写 &gt; 脏读 &gt; 不可重复读 &gt; 幻读 sql标准中规定的并发事务执行过程中可以发生的现象 隔离级别 脏读 不可重复读 幻读 READ UNCOMMITED 可能 可能 可能 READ COMMITED 不可能 可能 可能 REPEATABLE READ 不可能 不可能 不可能 SERIALIZABLE 不可能 不可能 不可能 脏写情况比较严重，任何隔离级别下都不允许该情况发生 MVVC原理​ 对于InnoDB存储引擎的表来说，它的聚簇索引记录中都包含下面这两个必要的隐藏列（row_id并不是必要的；在创建表中有主键时，或许又不允许为NULL的UNIQUE键时，都不会包含row_id列） trx_id：一个事务每次对某条聚簇索引列记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列 roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中。这个隐藏列就相当于一个指针，可以通过它找到该记录修改前的信息 ​ 每对记录做一次改动，都会记录一条undo日志，每条undo日志也都有一个roll_pointer属性（insert操作对应的undo日志没有该属性，因为insert操作的记录并没有更早的版本），通过这个属性可以将这些undo日志串成一个链表。 ​ 在每次更新记录后，都会将旧值放入到一条undo日志中（就算是该记录的一个旧版本）。随着更新次数的增多，所有的版本都会被roll_pointer属性连接成一个链表，这个链表称为版本链。版本链的头节点就是当前记录的最新值。同时，每个版本中还包含生成该版本时对应的事务id。 利用版本链来控制并发事务访问相同记录时的行为，我们把这种机制称为多版本并发控制（Multi-Version Concurrency Control, MVVC） ReadView对于使用READ UNCOMMITTED隔离级别的事务来说，可以读到未提交事务修改过的记录，所以直接读取记录的最新版本就好了； 对于SERIALIZABLE隔离级别的事务来说，可以使用加锁的方式 对于READ COMMITED和REPEATABLE READ隔离级别的事务来说，都必须保证读到已经提交的事务修改过多记录。 核心问题就是需要判断版本链中的哪个版本是当前事务可见的。于是MySql提出了ReadView的概念 m_ids：在生成ReadView时，当前系统中活跃的读写事务的事务id列表 min_trx_id：在生成ReadView时，当前系统中活跃的读写事务中最小的事务id（也就是m_ids中的最小值） max_trx_id：在生成ReadView时，系统应该分配给下一个事务的事务id值 creator_trx_id：生成该ReadView的事务的事务id 只有在对表中的记录进行改动时（执行INSERT、UPDATE、DELETE语句这些语句时），才会为事务分配唯一的事务id，否则一个事务的事务id值都默认为0 有了ReadView后，在访问某条记录时，只需要按照下面的步骤来判断记录的某个版本是否可见 如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问 如果被访问版本的trx_id属性值小于ReadView中的min_trx_id值，表明生成该版本的事务 在当前事务生成ReadView前已经提交，所以可以被访问 如果被访问版本的trx_id属性值大于ReadView中的max_trx_id值，表明生成该版本的事务 在当前事务生成ReadView后才生成，所以不可被访问 如果被访问版本的trx_id属性值在ReadView的min_trx_id和max_trx_id之间，则需要判断该trx_id是否在 m_ids列表中。如果在，说明生成该版本的事务还是活跃的，不可以被访问。如果不在，说明事务已经提交，该版本可以被访问 如果某个版本的数据对当前事务不可见，那就顺着版本链找到下一个版本的数据1，（也就是记录头中的rool_pointer串成的undo日志链表）继续上面的过程判断可见性。 如果找完最后一个版本，也不能可见，说明该记录对当前事务完全不可见。 READ COMMITED 每次读取数据前都生成一个ReadView 所以READ COMMITEDy有不可重复读的问题， 事务T1先读取了数据项X的值，然后T2又修改了未提交事务T1读取的数据项X的值，之后T2提交，然后T1再次读取数据项X的值时，会得到与第一次读取时不同的值。 因为每次查询都会新生成一个ReadView，对于第二次查询生成的ReadView来说，由于事务T2已经提交了，所以他能读取到 REPEATABLE READ 只有第一次执行查询语句时，才会生成一个ReadView 所以它可以解决重复读的问题 事务T1先读取数据项X的值后，会生成一个ReadView，然后事务T2又修改了T1读取的数据项X的值，之后T2提交。 此时数据行记录的trx_id会变成T2提交的事务id，第二次查询时，发现生成的ReadView中，不满足可见性原则，（ReadView中的max_trx_id小于当前数据行中记录的trx_id）所以不会读到事务2修改后的值 REPEATABLE READ级别下，可以很大程度上解决幻读问题，但是并不能完全解决幻读 比如： 时刻 事务T1 事务T2 T1 BEGIN;SELECT * FROM student where number &gt;= 20221101; T2 BEGIN;INSERT INTO tmp.student (number, name, major) VALUES (20221104, ‘赵六’, ‘测试-RR级别下可能发生幻读问题’);COMMIT; T3 UPDATE student set name = ‘赵六2’ where number = 20221104; T4 SELECT * FROM student where number &gt;= 20221101;COMMIT; 在T4时刻，T1事务就会发生幻读现象。 原因是：UPDATE语句不是采用MVVC这种快照读，而是采用的当前读。 当前读是读取的数据库最新的数据，当前读和快照读不同，因为要读取最新的数据而且要保证事务的隔离性，所以当前读是需要对数据进行加锁的 也就是说，事务T1的update语句，会对事务2新增的记录进行加锁、修改字段值、并且将隐藏列trx_id修改为自己的事务id，所以T4时刻根据MVVC再去读取时，发现满足可见性，所以产生幻读现象 二级索引与MVVC只有聚簇索引才有trx_id和roll_pointer隐藏列。那么，如果某个查询语句是使用二级索引来查询的，该如何判断可见性呢？ 步骤一：二级索引页面的PAGE HEADER部分，有一个名为PAGE_MAX_TRX_ID的属性，每当对该页面中的记录执行增删改操作时，如果执行该操作的事务的事务id大于 PAGE_MAX_TRX_ID属性值，就会把就会把PAGE_MAX_TRX_ID属性设置为执行该操作的事务的事务id。 也就是说，PAGE_MAX_TRX_ID的值代表着修改该二级索引页面的最大事务id。 当select语句访问某个二级索引记录时，首先看一下对应ReadView中的min_trx_id是否大于该页面的PAGE_MAX_TRX_ID，如果大于，则表示该页面中的所有记录都对该ReadView可见；否则就需要执行步骤2，回表之后再判断可见性 步骤二：利用二级索引记录中的主键值进行回表操作，得到对应聚簇索引记录后再判断可见性","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"jvm常见命令","slug":"jvm常见命令","date":"2023-08-16T12:55:41.000Z","updated":"2023-08-19T13:22:45.297Z","comments":true,"path":"2023/08/16/jvm常见命令/","link":"","permalink":"http://c89757.gitee.io/colinstar/2023/08/16/jvm%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4/","excerpt":"","text":"JstatJIT相关 jstata -compiler [pid] 查看JIT编译器编译过的方法、耗时等 jstat -printcompilation 输出已经被JIT编译的方法 垃圾回收相关 -gc 显示与GC相关的对信息。包括Eden区、两个Survivor区、老年代、永久代等容量、已用空间 jstat -gc [pid] 1000 10: 每隔一秒（1000ms ）打印一次gc信息，总共打印10次 jstat -gc -t: 会多一列Timestamp，表示Java进程启动的总时间； 我们可以比较Java进程启动的总时间以及总GC时间（GCT列），或者两次测量的间隔时间以及GC总时间的增量，得到GC时间占运行时间的比例 如果该比例超过20%，则说明目前堆压力较大；如果超过90%，则说明堆里几乎没有可用空间，随时都可能抛出OOM异常 -gccapacoty 显示内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间。 -gcutil 显示内容与-gc基本相同。但输出主要关注已使用空间占总空间的百分比 -gccause 与-gcutil功能一样，但会额外输出导致最后一次或当前正在发生的GC产生的原因 -gcnew 显示新生代GC情况 -gcnewcapacity 显示内容与-gcnew基本相同，输出主要关注使用到的最大、最小空间 -geold 显示老年代GC情况 -gcolccapacity 显示内容与-gcold基本相同，输出主要关注使用到的最大、最小空间 -gcpermcapacity 显示永久代使用到的最大、最小空间 jstat还可以用来判断是否出现内存泄漏 1、在长时间运行的Java程序中，我们可以运行jstat命令连续获取多行性能数据，并取这几行数据中OU列（即已占用的老年代内存）的最小值 2、然后我们每隔一段较长的时间重复一次上述操作，来获得多组OU最小值。如果这些值呈上升趋势，则说明该Java程序的老年代内存已使用量在不断上涨，这意味着无法回收的对象在不断增加，因此很有可能存在内存泄漏 Jinfo查看虚拟机配置参数信息，也可用于调整虚拟机的配置参数 查看PID必须要加上 选项 说明 no optition 输出全部的参数和系统属性 -flag name 输出对应名称的参数 -flag [+-name] 开启或关闭对应名称的参数，只有被编辑为manageable的参数才可以被动态修改 -flag name=value 设定对应名称的参数 -flags 输出全部的参数 -sysprops 输出系统属性 修改jinfo甚至可以在运行时修改部分参数，并使之立即生效 但是，并非所有参数都支持动态修改，参数只有标记为manageable的flag可以被实时修改，其实，这个修改能力都是及其有限的 可以查看被标记为manageable的参数 java -XX:+PrintFlagsFinal -version |grep manageable 其他java -XX:+PrintFlagInitial 查看所有JVM参数启动的初始值 java -XX:+PrintFlagsFinal 查看所有JVM参数的最终只 java -XX+PrintCommandLineFlags 查看那些已经被用户或者JVM设置过的详细的XX参数的名称和值 jmap​ 作用一方面是获取dump文件（堆转储快照文件，二进制文件），它还可以获取目标java进程的内存相关信息，包括Java堆各区域的使用情况、堆中对象的统计信息、类加载信息等。 ​ 由于jmap将访问堆中的所有对象，为了保证在此过程中不被应用线程干扰，jmap需要借助安全点机制，让所有线程留在不改变堆中数据的状态。也就是说，由jmap导出的堆快照必定是安全点位置的。这可能导致基于该堆快照的分析结果存在偏差。 ​ 另外，如果某个线程长时间无法跑到安全点，jmap将一直等下去，与jstat则不同，垃圾回收器会主动将jstat所需要的摘要数据保存至固定位置之中，则jstat只需直接读取即可。 官方文档 -dump 生成Java堆转储快照：dump文件 -dumplive: 只保存堆中的存活对象 导出内存映像文件 手动的方式 jmap -dump:format=b,file=&lt;filename.hprof&gt; &lt;pid&gt; jmap -dump:live,format=b,file=&lt;filename.hprof&gt;&lt;pid&gt; format作用：使jmap生成文件与.hprof格式匹配起来 自动的方式 -XX:+HeapDumpOnOutOfMemoryError -XX:+HeapDumpPath=&lt;filename.hprof&gt; -heap 输出整个堆空间的详细信息，包括GC的使用、堆配置信息，以及内存的使用信息等 -histo 输出堆中对象的统计信息，包括类、实例数量的合计容量 -histo:live: 只统计堆中的存活对象（注意，此命令慎重使用，会引发FullGc） -permstat 以ClassLoader为统计口径输出永久代的内存状态信息 仅linux/solaris平台有效 -finalizerinfo 显示在F-Queue中等待Finailzer线程执行finalize方法的对象 仅linux/solaris平台有效 -F 当虚拟机进程对-dump选项没有任何响应时，可使用此选项强制执行生成dump文件 仅linux/solaris平台有效 -J &lt;flag&gt; 传递参数给jmap启动的jvm jhat​ Sun JDK提供的jhat命令与jmap命令搭配使用，用于分析jmap生成的heap dump文件（堆转储快照）。hgat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，用户可以在浏览器中查看分析结果 ​ 使用了jhat命令，就启动了一个http服务器，端口是7000，则http://localhost:7000 ​ 注意：jhat命令在JDK9后，已经被删除 基本使用语法： jhat [option] [dumpfile] jstack​ 用于生成虚拟机指定进程当前时刻的线程快照（虚拟机堆栈跟踪）。线程快照就是当前虚拟机内指定进程的每一条线程正在执行的方法堆栈的集合 ​ -F 当正常输出的请求不被响应时，强制输出线程堆栈 -l 除堆栈外，显示关于锁的附加信息 -m 如果调用到本地方法的话，可以显示C/C++的堆栈 在thread dump中，要留意下面几种状态 死锁，Deadlock (重点关注) 等待资源，Waiting on condition (重点关注) 等待获取监视器，Waiting on monitor entry (重点关注) 阻塞，Blocked （重点关注） 执行中，Runnable 暂停，Suspended 对象等待中，Object.wait() 或 TIMED_WAITING 停止， Parked jcmd在JDK 1.7以后，新增了一个命令行工具jcmd 它是一个多功能的工具，可以用来实现前面除了jstat之外的所有命令的功能 。比如：用它来导出堆、内存使用、查看Java进程、导出线程信息、执行GC、JVM运行时间等。 相关jvm参数 -verbose:gc 输出gc日志信息，默认输出到标准输出 -XX:+PrintGc 等同于-verbose:gc，表示打开简化的GC日志 -XX:+PrintGCDetails 在发生垃圾回收时打印内存回收详细的日志 -XX:+PrintGCDateStamps 输出GC发生时的时间戳 -XX:+PrintHeapAtGc 每一个GC前和GC后，都打印堆信息 -Xlogg&lt;file&gt; 把GC日志写入到一个文件中去，而不是打印到标准输出中","categories":[{"name":"jvm","slug":"jvm","permalink":"http://c89757.gitee.io/colinstar/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://c89757.gitee.io/colinstar/tags/jvm/"}]},{"title":"线上cpu飙升排查","slug":"线上cpu飙升排查","date":"2023-08-09T14:58:45.000Z","updated":"2023-08-17T12:58:48.379Z","comments":true,"path":"2023/08/09/线上cpu飙升排查/","link":"","permalink":"http://c89757.gitee.io/colinstar/2023/08/09/%E7%BA%BF%E4%B8%8Acpu%E9%A3%99%E5%8D%87%E6%8E%92%E6%9F%A5/","excerpt":"","text":"1、找出服务运行的进程号 1jps 2、利用top命令查看对应进程下，各个线程占用情况 1top -H -p &#123;pid&#125; 3、找到占用最高的线程，拿到线程其线程号，将其转为十六进制（因为java里面记录的线程号都是十六进制） 1printf &#x27;%x\\n&#x27; &#123;tid&#125; 4、利用jstack抓取线程快照 1jstack -l &#123;pid&#125; |grep ‘&#123;十六进制tid&#125;&#x27;","categories":[{"name":"jvm","slug":"jvm","permalink":"http://c89757.gitee.io/colinstar/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://c89757.gitee.io/colinstar/tags/jvm/"},{"name":"questions","slug":"questions","permalink":"http://c89757.gitee.io/colinstar/tags/questions/"}]},{"title":"阻塞队列","slug":"阻塞队列","date":"2023-03-09T15:21:33.000Z","updated":"2023-03-09T16:28:23.725Z","comments":true,"path":"2023/03/09/阻塞队列/","link":"","permalink":"http://c89757.gitee.io/colinstar/2023/03/09/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/","excerpt":"","text":"JDK里的阻塞队列 ArrayBlockingQueue 数组构成的有界阻塞队列 LinkedBlockingQueue 链表构成的无界阻塞队列 tips: 使用无界阻塞队列的put或offer方法时，永远不会阻塞， 因为队列不可能满 PriorityBlockingQueue 一个支持优先级排序的无界阻塞队列 DelayQueue 一个使用优先级队列实现的无界阻塞队列 SynchronousQueue 一个不存储元素的阻塞队列 LinkedTransferQueue 由链表组成的无界阻塞队列 LinkedBlockingDeque 由链表结构组成的双向阻塞队列","categories":[{"name":"java","slug":"java","permalink":"http://c89757.gitee.io/colinstar/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://c89757.gitee.io/colinstar/tags/java/"}]},{"title":"Mysql索引合并","slug":"Mysql索引合并","date":"2023-02-20T14:40:41.000Z","updated":"2023-02-20T15:08:50.511Z","comments":true,"path":"2023/02/20/Mysql索引合并/","link":"","permalink":"http://c89757.gitee.io/colinstar/2023/02/20/Mysql%E7%B4%A2%E5%BC%95%E5%90%88%E5%B9%B6/","excerpt":"","text":"Intersection索引合并例如以下查询 1select * from table_name where key1 = &#x27;a&#x27; and key3 = &#x27;b&#x27;; 其中key1、key3加了普通索引，分别名为idx_key1，idx_key3 那么，有如下几种方案执行该查询 1、使用idx_key1索引执行该查询，此时对应的扫描区间就是 [‘a’, ‘a’]。对于获取的每条二级索引记录，都需要根据它的id值执行回表操作后获取到完整的用户记录，再判断key3 = ‘b’是否成立。其中，二级索引中，对于key1 = ‘a’的id列是按照主键值排序的 2、使用idx_key3索引执行 该查询，同样的，需要回表判断key1的条件是否成立 方案3：同时使用idx_key1和idx_key3进行查询。也就是在idx_key1中扫描key1值在[‘a’,’a’]区间中的二级索引记录，同时在idx_key3中扫描key3在[‘b’,’b’]区间中的二级索引记录，然后从两者的操作结果中找出id列值相同的值，进行回表（这样可以省下很多回表操作） Intersection索引合并指的就是从不同索引中扫描的记录id取交集，只会为这些共同的id值进行回表操作。 如果使用Intersection索引合并的方式进行查询，并且每个使用的索引都是二级索引的话，则要求从每个索引中获取到的二级索引记录都是按照主键值排序的 Union索引合并例如以下查询 1select * from table_name where key1 = &#x27;a&#x27; or key3 = &#x27;b&#x27;; 其中key1、key3加了普通索引，分别名为idx_key1，idx_key3 上述查询，可以同时使用idx_key1和idx_key2来执行查询。也就是在idx_key1中扫描key1值位于[‘a’,’a’]区间中的二级索引记录，同时在idx_key3中扫描key3值位于[‘b’,’b’]区间中的二级索引记录，然后根据二级索引记录的id值在两者的结果中进行去重，再根据去重后的id值执行回表操作，这样重复的id值只需要回表一次 如果使用Union索引合并的方式进行查询，并且每个使用的索引都是二级索引的话，则要求从每个索引中获取到的二级索引记录都是按照主键值排序的 如果在使用某个二级索引执行查询时，从对应的扫描区间中读取出的二级索引记录不是按照主键值排序的，则不可以使用Union索引合并的方式执行查询。比如下面的查询 1select * from table_name where key1 &gt; &#x27;a&#x27; or key3 = &#x27;b&#x27;; 因为从idx_key1的扫描区间（’a’, +∞）中获取到的记录并不是按照主键值排序的（只有在key1列相同的时候，它相对应的主键是有序的） Sort-Union索引合并1select * from table_name where key1 &lt; &#x27;a&#x27; or key3 &gt; &#x27;z&#x27;; 这个查询不能用union索引合并查询，但是我们可以像如下操作： 1、先根据key1 &lt; ‘a’条件从idx_key1二级索引中获取二级索引记录，并将获取到的二级索引记录的主键进行排序 2、再根据key3 &gt; ‘z’条件从idx_key3二级索引中获取二级索引记录，并将获取到的二级索引记录的主键进行排序 3、因此上述两个二级索引主键值都是排好序了，剩下的操作就是使用union索引合并","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"innodb数据页","slug":"innodb数据页","date":"2023-02-18T14:54:52.000Z","updated":"2023-02-19T16:04:56.828Z","comments":true,"path":"2023/02/18/innodb数据页/","link":"","permalink":"http://c89757.gitee.io/colinstar/2023/02/18/innodb%E6%95%B0%E6%8D%AE%E9%A1%B5/","excerpt":"","text":"概述 innodb页目录结构大致如下 先说说行格式，compact行格式结构如下 （其中，记录的真实数据，除了用户真实的数据以外，还有一些隐藏列， row_id - 行id，唯一标识一条记录，没有定义主键时，会添加此隐藏列； 事务id - 事务ID roll_pointer：回滚指针） 记录头各属性及其解释如下 表中记录大致如下 Page Directory ​ 记录在页中是按照主键值由小到大的顺序串联成一个单项链表，如果要查找表中一条记录，最简单的方法就是遍历链表，但是当记录非常多时，是很耗费性能的，于是就有了page directory页目录。其实就是一个字典 1、将所有正常的记录（包括Infimum和Supremum记录，但是不包括已经移除到垃圾链表的记录）划分为几个组 2、每个组的最后一条记录（也就是组内最大的那条记录）相当于带头大哥，组内其余的记录相当于小弟，带头大哥记录的头信息中的n_owned属性表示该组内共有几条记录 3、将每个组中最后一条记录在页面中的地址偏移量（就是该记录的真实数据与页面中第0个字节之间的距离）单独提取出来，按顺序存储到靠近页尾部的地方，这个地方就是Page Directory.页目录中这些地址偏移量称为槽（Slot)，每个槽占用2字节，页目录就是由多个槽组成的 Infimum记录中的n_owned值为1，表示以Infimum记录为最后一个节点的这个组中只有一条记录，也就是Infimum记录自身 Supremum记录的n_owned值为3，表示以Supremum记录为最后一个节点的这个分组中有3条记录，即除了Supremum记录自身外，还有两条记录 分组的依据： 对于Infimum记录所在的分组只能有1条记录，Supremum记录所在的分组拥有的记录条数只能在18之间，剩下分组中的条数范围只能是48之间。 Page Header 页面头部 存储数据页中的记录的各种状态信息 File Header 记录页面当前页号，以及上一页、下一页的页号（并不是所有类型的页都会记录上一页、下一页的页号） 每一个页都有一个单独的页号，就跟你的身份证号码一样，InnoDB通过页号来可以唯一定位一个页。 FIL_PAGE_TYPE 我们存放记录的数据页的类型其实是FIL_PAGE_INDEX，也就是所谓的索引页 File Trailer 文件尾部，用于检验一个页是否完整（刷盘时，不可预知的情况可能导致刷盘只刷新了一部分)","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"G1 GC","slug":"G1-GC","date":"2023-02-05T07:13:35.000Z","updated":"2024-03-11T11:46:21.143Z","comments":true,"path":"2023/02/05/G1-GC/","link":"","permalink":"http://c89757.gitee.io/colinstar/2023/02/05/G1-GC/","excerpt":"","text":"Grabage First简介​ G1是一款主要面向服务端的垃圾收集器，在JDK9时，取代了Parallel Scavenge + Parallel Old组合，成为了默认的垃圾收集器。 ​ 在G1出现之前，垃圾收集的目标范围要么是整个新生代（Minor GC），要么是整个老年代（Major GC），再要么就是整个Java堆（Full GC）。而G1可以面向堆内存任何部分来组成回收集（Collection Set，简称CSet）进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是G1收集器的Mixed GC模式。 ​ G1不再坚持固定大小以及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region都可以根据需要扮演新生代的Eden、Survivor、或者老年代 。 ​ Humongous，专门存储大对象（超过了一个Region容量一半的对象，即达到1.5倍region）。每个Region的大小可以通过参数 -XX:G1HeapRegionSize设定。取值范围为1MB~32MB，且应为2的N次幂。而超过了整个Region容量的超级大对象，将会被存放在N个连续的Humongous Region之中。（G1的大多数行为把Humongous当作老年代的一部分看待） ​ G1仍然保留新生代和老年代的概念，但新生代和老年代不再是固定的了。 Remembered Set一个Region中的对象可能被其他任意Region中的对象所引用，判断对象存活时，是否需要扫描整合java堆才能保证准确？ 比如新生代Region中的对象被老年代Region中的对象引用，回收新生代时不得不同时扫描老年代，这样的话会降低Minor GC的效率 无论是G1还是其他分代收集器，JVM都是使用Remembered Set来避免全局扫描 每个Region都有一个对应的Remembered Set G1内存占用比较高，需要维护记忆集、卡表等。至少要耗费大约相当于堆容量的10%~20%的额外内存来维持收集器工作 美团技术团队：https://tech.meituan.com/2016/09/23/g1.html","categories":[{"name":"jvm","slug":"jvm","permalink":"http://c89757.gitee.io/colinstar/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://c89757.gitee.io/colinstar/tags/jvm/"}]},{"title":"记-并发情况下mysql死锁问题","slug":"记-并发情况下mysql死锁问题","date":"2023-01-28T15:30:14.000Z","updated":"2023-01-28T15:59:34.017Z","comments":true,"path":"2023/01/28/记-并发情况下mysql死锁问题/","link":"","permalink":"http://c89757.gitee.io/colinstar/2023/01/28/%E8%AE%B0-%E5%B9%B6%E5%8F%91%E6%83%85%E5%86%B5%E4%B8%8Bmysql%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"背景：业务中采用先删除后插入的逻辑，开启了事务。 表结构大概如下： 123456789CREATE TABLE `table_test` ( `id` int(11) NOT NULL AUTO_INCREMENT, `key1` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `column1` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `column2` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE, INDEX `idx_key1`(`key1`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; 先根据二级索引key1删除表中数据（相同的key1），再批量插入数据，在并发情况下，频繁出现死锁问题。 利用 set GLOBAL innodb_status_output_locks = on; show engine innodb status; 可以查看mysql最后一次发生死锁的情况 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859------------------------LATEST DETECTED DEADLOCK------------------------2023-01-28 23:25:46 0x14e90*** (1) TRANSACTION:TRANSACTION 62092, ACTIVE 0 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 6 lock struct(s), heap size 1136, 6 row lock(s)MySQL thread id 239, OS thread handle 20368, query id 105887 localhost 127.0.0.1 root updatingdelete from table_test where key1 = &#x27;aaa&#x27;*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 308 page no 3 n bits 152 index PRIMARY of table `db`.`table_test` trx id 62092 lock_mode X locks rec but not gap waitingRecord lock, heap no 56 PHYSICAL RECORD: n_fields 6; compact format; info bits 32 0: len 4; hex 80001e9c; asc ;; 1: len 6; hex 00000000f28e; asc ;; 2: len 7; hex 79000001ff139a; asc y ;; 3: len 3; hex 616161; asc aaa;; 4: len 1; hex 31; asc 1;; 5: len 1; hex 32; asc 2;;*** (2) TRANSACTION:TRANSACTION 62094, ACTIVE 0 sec updating or deleting, thread declared inside InnoDB 0mysql tables in use 1, locked 15 lock struct(s), heap size 1136, 6 row lock(s), undo log entries 1MySQL thread id 242, OS thread handle 85648, query id 105894 localhost 127.0.0.1 root updatingdelete from table_test where key1 = &#x27;aaa&#x27;*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 308 page no 3 n bits 152 index PRIMARY of table `db`.`table_test` trx id 62094 lock_mode XRecord lock, heap no 56 PHYSICAL RECORD: n_fields 6; compact format; info bits 32 0: len 4; hex 80001e9c; asc ;; 1: len 6; hex 00000000f28e; asc ;; 2: len 7; hex 79000001ff139a; asc y ;; 3: len 3; hex 616161; asc aaa;; 4: len 1; hex 31; asc 1;; 5: len 1; hex 32; asc 2;;Record lock, heap no 71 PHYSICAL RECORD: n_fields 6; compact format; info bits 32 0: len 4; hex 80001e9b; asc ;; 1: len 6; hex 00000000f282; asc ;; 2: len 7; hex 72000001ba2356; asc r #V;; 3: len 3; hex 616161; asc aaa;; 4: len 1; hex 31; asc 1;; 5: len 1; hex 32; asc 2;;Record lock, heap no 80 PHYSICAL RECORD: n_fields 6; compact format; info bits 32 0: len 4; hex 80001e9a; asc ;; 1: len 6; hex 00000000f288; asc ;; 2: len 7; hex 75000001e919c8; asc u ;; 3: len 3; hex 616161; asc aaa;; 4: len 1; hex 31; asc 1;; 5: len 1; hex 32; asc 2;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 308 page no 4 n bits 152 index idx_key1 of table `db`.`table_test` trx id 62094 lock_mode X locks rec but not gap waitingRecord lock, heap no 39 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 3; hex 616161; asc aaa;; 1: len 4; hex 80001e9c; asc ;;*** WE ROLL BACK TRANSACTION (2) 可以看到，两个事务，分别持有了聚簇索引的锁与二级索引key1上的锁，导致死锁。 解决方案：可以先根据key1查询出主键，再根据主键去操作。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"JUC","slug":"JUC","date":"2022-12-04T14:47:30.000Z","updated":"2022-12-04T15:15:03.663Z","comments":true,"path":"2022/12/04/JUC/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/12/04/JUC/","excerpt":"","text":"冯诺依曼计算机计算机五大核心组成部分 控制器(Control)：是整个计算机的中枢神经，其功能是对程序规定的控制信息进行解释，根据其要求进行控制，调度程序、数据、地址，协调计算机各部分工作及内存与外设的访问等。 运算器(Datapath)：运算器的功能是对数据进行各种算术运算和逻辑运算，即对数据进行加工处理。 存储器(Memory)：存储器的功能是存储程序、数据和各种信号、命令等信息，并在需要时提供这些信息。 输入(Input system)：输入设备是计算机的重要组成部分，输入设备与输出设备合你为外部设备，简称外设，输入设备的作用是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息输入到计算机。常见的输入设备有键盘、鼠标器、光电输入机、磁带机、磁盘机、光盘机等。 输出(Output system)：输出设备与输入设备同样是计算机的重要组成部分，它把外算机的中间结果或最后结果、机内的各种数据符号及文字或各种控制信号等信息输出出来。 微机常用的输出设备有显示终端CRT、打印机、激光印字机、绘图仪及磁带、光盘机等。 下图——冯诺依曼计算机模型图 上面的模型是一个理论的抽象简化模型，它的具体应用就是现代计算机当中的硬件结构设计： 在上图硬件结构中，最核心的两部分：CPU、内存 CPU内部结构 控制单元 运算单元 数据单元 控制单元 控制单元是整个CPU的指挥控制中心，由指令寄存器IR（Instructio Register)、指令译码器ID（Instruction Decoder)和操作控制器OD(Operation Controller)等组成。 CPU缓存结构 现在CPU为了提升执行效率， 减少CPU与内存的交互（交互影响CPU效率），一般在CPU上集成了多级缓存架构，常见的三级缓存结构 L1 Cache，分为数据缓存和指令缓存，逻辑核独占 L2 Cache，物理核独占，逻辑核共享 L3 Cache，所有物理核共享 存储器存储空间大小：内存 &gt; L3 &gt; L2 &gt; L1 &gt; 寄存器 存储器速度快慢排序：寄存器 &gt; L1 &gt; L2 &gt; L3 &gt; 内存 还有一点值得注意的是：缓存是由最小的存储区块——缓存行（cacheline）组成，缓存行大小通常为64byte 什么是缓存行？ 比如你的L1缓存大小为512kb，而cacheline = 64byte，那么L1里有512 * 1024 / 64 个cacheline CPU读取存储器数据过程： 1、CPU要取寄存器X的值，只需要一步：直接读取 2、CPU要取L1 Cache的某个值，需要 1 - 3步（或者更多）: 把cache行锁住，把某个数据拿来，解锁 3、CPU要读取L2 Cache的某个值，先要到L1 Cache里取，L1当中不存在，在L2里，L2开始加锁，加锁以后，把 L2里的数据复制到L1，在执行读L1的过程，上面的三步再解锁 4、CPU取L3 Cache的也是一样，只不过先由L3复制到L2，L2复制到L1，从L1到CPU 5、CPU取内存则最复杂：通知内存控制器占用总线带宽，通知内存加锁，发起内存读请求，等待回应，回应数据保存在L3（如果没有就到L2），再从L3/L2到L1，再从L1到CPU，之后解除总线锁定 CPU为何要有高速缓存？ CPU在摩尔定律的指导下以每18月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU，这就造成了高性能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题。CPU厂商在CPU中内置了少量的高速缓存以解决I\\O速度和CPU运算之间的不匹配问题 在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理 **时间局部性（Temporal Localit）**：如果一个信息项正在被访问，那么在近期它很有可能还会被再次访问。比如循环、递归、方法的反复调用等 **空间局部性（Spatial Locality）**：如果一个存储器的位置被引用，那么将来它附近的位置也会被引用。比如顺序执行的代码，连续创建的两个对象，数组等。 空间局部性——&gt; 并不仅仅取主内存访问x = 0 ,会把x = 0 的附近的位置也拿到L3 Cache中 带有高速缓存的CPU执行计算的流程 程序以及数据被加载到主内存 指令和数据被加载到CPU的高速缓存 CPU执行指令，把结果写到高速缓存 高速缓存中的数据写回主内存 操作系统内存管理 执行空间保护 操作系统有用户空间和内核空间两个概念，目的也是为了做到程序运行安全隔离与稳定 以32位操作系统4G大小内存空间为例 Linux为内核代码和数据结构预留了几个页框，这些页永远不会被转出到磁盘上。从0x00000000到0xc000000(PAGE_OFFSET)的线性地址可由用户代码和内核代码进行引用（即用户空间）。 从0xc0000000（PAGE_OFFSET）到 0xFFFFFFFFF的线性地址只能由内核代码进行访问（即内核空间）。内核代码及其数据结构都必须位于这1GB的地址空间中，但是对于此地址空间而言，更大的消费者是物理地址的虚拟应用 这意味着在4GB的内存空间中，只有3GB可以用于用户应用程序。进程与线程只能运行在用户方式（usermode）或内核方式（kernelmode）下。用户程序运行在用户方式下，而系统调用运行在内核方式下。这两种方式下所用的堆栈不一样：用户方式下用的是一般的堆栈（用户空间的堆栈），而内核方式下用的是固定大小的堆栈（内核空间的堆栈，一般为一个内存页的大小），即每个进程与线程其实有两个堆栈，分别运行在用户态与内核态 CPU调度的基本单位线程，也可以划分为： 1、内核线程模型（KLT) 2、用户线程模型（ULT） 内核线程模型 **内核线程（KLT）**：系统内核管理线程（KLT），内核保存线程的状态和上下文信息，线程阻塞不会引起进程阻塞。在多处理器系统上，多线程在多处理器上并行运行。线程的创建、调度和管理由内核完成，效率比ULT更慢，比进程操作快 用户线程模型 **用户线程（ULT）**：用户程序实现，不依赖操作系统核心，应用提供创建、同步、调度和管理线程的函数来控制用户线程。不需要用户态/内核态切换，速度快。内核对ULT无感知，线程阻塞则进程（包括它的所有线程）阻塞。 虚拟机指令集架构 虚拟机指令集架构主要分为两种： 1、栈指令集架构 2、寄存器指令集架构 栈指令集架构： 设计和实现更简单，适用于资源受限的系统 避开了寄存器的分配难题，使用零地址指令方式分配 指令流中的指令大部分是零地址指令,其执行过程依赖与操作栈,指令集更小,编译器容易实现; 不需要硬件支持,可移植性更好,更好实现跨平台 寄存器指令架构 典型的应用是x86的二进制指令集：比如传统的PC以及Android的Davlik虚拟机。 指令集架构则完全依赖硬件，可移植性差 性能优秀和执行更高效 花费更少的指令去完成一项操作 大部分情况下,基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主,而基于栈式架构的指令集却是以零地址指令为主 JMM模型概述 Java内存模型（Java Memory Model简称JMM）是一种抽象的概念，并不真实存在，它描述的是一组规则或规范；通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式 JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方称为栈空间)，用于存储线程私有的数据，而Java 内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作(读取赋值等)必须在工作内存中进行；首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 JMM不同于JVM内存区域模型 JMM与JVM内存区域的划分是不同的概念层次，更恰当说JMM描述的是一组规则，通过这组规则控制程序中各个变量在共享数据区域和私有数据区域的访问方式，==JMM是围绕原子性、有序性、可见性展开==。JMM与JVM内存区域唯一相似点，都存在共享数据区域和私有数据区域，在JMM中主内存属于共享数据区域，从某个程度上讲应该包括了堆和方法区，而工作内存数据线程私有数据区域，从某个程度上讲应该包括程序计数器、虚拟机栈以及本地方法栈 线程、工作内存、主内存工作交互图（基于JMM规范）: 主内存：主要存储的是Java实例对象，所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量还是方法中的本地变量（也称局部变量），当然也包括了共享的类信息、常量、静态变量。由于是共享数据区域，多条线程对同一个变量进行访问可能会发生线程安全问题 工作内存：主要存储当前方法的所有本地变量信息(工作内存中存储着主内存中的变量副本拷贝)，每个线程只能访问自己的工作内存，即线程中的本地变量对其它线程是不可见的，就算是两个线程执行的是同一段代码，它们也会各自在自己的工作内存中创建属于当前线程的本地变量，当然也包括了字节码行号指示器、相关Native方法的信息。注意：由于工作内存是每个线程的私有数据，线程间无法相互访问工作内存，因此存储在工作内存的数据不存在线程安全问题 根据JVM虚拟机规范，主内存与工作内存的数据存储类型以及操作方式，对于一个实例对象中的成员方法而言，如果方法中包含本地变量是基本数据类型（boolean,byte,short,char,int,long,float,double)，将直接存储在工作内存的栈帧结构中，但堂托本地变量是引用类型，那么该变量的引用会存储在工作内存的栈帧中，而对象实例将存储在主内存（共享数据区域，堆）中。但对于实例对象的成员变量，不管它是基本数据类型或者包装类型（Integer、Double等）还是引用类型，都会被存储到堆区。至于static变量以及类本身相关信息将会存储在主内存中。需要注意的是，在主内存中实例对象可以被多个线程共享，倘若两个线程同时调用了同一个对象的同一个方法，那么两条线程会将要操作的数据拷贝一份到自己的工作内存中，执行完成操作后才刷新到主内存模型如下图所示 Java内存模型与硬件内存架构的关系通过对前面的硬件内存架构、Java内存模型以及Java多线程的实现原理的了解，我们应该已经意识到，多线程的执行最终都会映射到硬件处理器上进行执行，但Java内存模型和硬件内存架构并不完全一致。对于硬件内存来说只有寄存器、缓存内存、主内存的概念，并没有工作内存(线程私有数据区域)和主内存(堆内存)之分，也就是说Java内存模型对内存的划分对硬件内存并没有任何影响。 因为JMM只是一种抽象的概念，是一组规则，并不实际存在，不管是工作内存的数据还是主内存的数据，对于计算机硬件来说都会存储在计算机主内存中，当然也有可能存储到CPU缓存或者寄存器中，因此总体上来说，Java内存模型和计算机硬件内存架构是一个相互交叉的关系，是一种抽象概念划分与真实物理硬件的交叉。(注意对于Java内存区域划分也是同样的道理) JMM存在的必要性 假设主内存中存在一个共享变量x，现在有A和B两条线程分别对该变量x=1进行操作， A/B线程各自的工作内存中存在共享变量副本x。假设现在A线程想要修改x的值为2，而B线程却想要读取x的值，那么B线程读取到的值是A线程更新后的值2还是更新前的值1呢？答案是，不确定，即B线程有可能读取到A线程更新前的值1，也有可能读取到A线程更新后的值 2，这是因为工作内存是每个线程私有的数据区域，而线程A变量x时，首先是将变量从主内存拷贝到A线程的工作内存中，然后对变量进行操作，操作完成后再将变量x写回主内，而对于B线程的也是类似的，这样就有可能造成主内存与工作内存间数据存在一致性问题，假如A线程修改完后正在将数据写回主内存，而B线程此时正在读取主内存，即将x=1拷贝到自己的工作内存中，这样B线程读取到的值就是x=1，但如果A线程已将x=2写回主内存后，B线程才开始读取的话，那么此时B线程读取到的就是x=2，但到底是哪种情况先发生呢？ 以上关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成 数据同步八大原子操作 lock(锁定)：作用于主内存的变量，把一个变量标记为一条线程独占状态 unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read(读取)：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中 use(使用)：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎 assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量 store(存储)：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作 write(写入)：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中 如果要把一个变量从主内存复制到工作内存中，就需要按顺序地执行read和load操作，如果把变量从工作内存中同步到主内存中，就需要按顺序地执行store和write操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行 同步规则分析 不允许一个线程无原因的（没有发生过任何assign操作）把数据从工作内存同步回主内存中 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或者assign)的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load操作 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用变量之前需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作) 并发编程的可见性、原子性与有序性问题原子性指的是一个操作是不可中断的，即使在多线程环境下，一个操作一旦开始就不会被其他线程影响 在java中，对基本数据类型的变量的读取和赋值操作是原子性操作有点要注意的是，对于32位系统的来说，long类型数据和double类型数据(对于基本数据类型， byte,short,int,float,boolean,char读写是原子操作)，它们的读写并非原子性的，也就是说如果存在两条线程同时对long类型或者double类型的数据进行读写是存在相互干扰的，因为对于32位虚拟机来说，每次原子读写是32位的，而long和double则是64位的存储单元，这样会导致一个线程在写时，操作完前32位的原子操作后，轮到B线程读取时，恰好只读取到了后32位的数据，这样可能会读取到一个既非原值又不是线程修改值的变量，它可能是“半个变量”的数值，即64位数据被两个线程分成了两次读取。但也不必太担心，因为读取到“半个变量”的情况比较少见，至少在目前的商用的虚拟机中，几乎都把64位的数据的读写操作作为原子操作来执行，因此对于这个问题不必太在意，知道这么回事即可。 可见性： 可见性指的是当一个线程修改了某个共享变量的值，其他线程能否马上得知这个修改的值。对于串行程序来说，可见性是不存在的，因为我们在任何一个操作中修改了某个变量的值，后续的操作中都能读取到这个变量值，并且是修改过的新值 但在多线程环境中可就不一定了，由于线程对共享变量的操作都是线程拷贝到各自的工作内存进行操作后才写回到主内存中的，这就可能存在一个线程A修改了共享变量x的值，还未写回到主内存时，另外一个线程B又对主内存中同一个共享变量x进行操作，但此时A线程工作内存中变量x对线程B来说并不可见，这种工作内存与主内存同步延迟线现象就造成了可见性问题。另外指令重排及编译器优化也可能导致可见性问题 有序性： 有序性是指对于单线程的执行代码，我们总是认为代码的执行是按顺序依次执行的，这样的理解并没有毛病，毕竟对于单线程而言确实如此。但对于多线程环境下，则可能出现乱序现象，因为程序编译成机器码指令后可能会出现指令重排，重排后的指令与原指令的顺序未必一致 12345678910111213141516171819202122232425public class TestVolatile &#123;private static boolean flag = false;public static void main(String[] args) throws InterruptedException &#123;Thread threadA = new Thread(() -&gt; &#123; while (!flag) &#123; &#125; log.info(Thread.currentThread().getName() + &quot;的当前线程flag的状态改变&quot;);&#125;,&quot;ThreadA&quot;);threadA.start();Thread.sleep(100);Thread threadB = new Thread(() -&gt; &#123; log.info(Thread.currentThread().getName() + &quot;refresh data...&quot;); flag = true; log.info(Thread.currentThread().getName() + &quot;refresh data success&quot;);&#125;,&quot;ThreadB&quot;);threadB.start();&#125;&#125;// threadA嗅探不到threadB对共享变量的修改，因为这里是空的死循环，空循环的优先级特别高，几乎不会让出CPU资源；如果在循环里执行一点操作，如打印一句话什么的，那么threadA是有可能嗅探到值的变化的，只是什么时候会感知到，这个不确定，而volatile能保证立马感知到 voloatile禁止重排优化 volatile关键字另一个作用就是禁止指令重排优化，从而避免多线程环境下程序出现乱序执行的现象，voloatile禁止重排的关键在于内存屏障（Memory Barrier) 硬件层的内存屏障 Intel硬件提供了一系列的内存屏障，主要有： Ifence,是一种Load Barrier读屏障 sfence，是一种Store Barrier写屏障 mfence，是一种全能型的屏障，具备lfence和sfence的能力 Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁，它后面可以跟ADD,ADC,AND,BTC等指令 不同硬件实现内存屏障的方式不同，Java内存模型屏蔽了这种底层硬件平台的差异，由JVM来为不同的平台生成相应的机器码.JVM中提供了四类内存屏障指令： 屏障类型 指令示例 说明 LoadLoad Load1；LoadLoad；Load2 保证Load1的读取操作在Load2及后续读取操作之前执行 StoreStore Store1；StoreStore；Store2 在store2及其后的写操作执行前，保证store1的写操作 LoadStore Load1；LoadStore；Store2 在Store2及其后的写操作执行前，保证load1的读操作已执行 StoreLoad Stroe1；StoreLoad；Load2 保证Store1的写操作已刷新到主内存之后，Load2及其后 内存屏障，又叫内存栅栏，是一个CPU指令，它的作用有两个，==一个是保证特定操作的执行顺序，二是保证某些变量的内存可见性==（利用该特性实现volatile的内存可见性） 由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。Memory Barrier的另外一个作用：是强制刷出各种CPU的缓存数据，因此任何CPU上的线程读取到这些数据的最新版本;总之，volatile变量正是通过内存屏障实现其在内存中的语义，即可见性和禁止重排优化 volatile内存语义的实现 前面提到过重排序分为编译器重排序和处理器重排序。为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型 下图是JMM针对编译器制定的volatile重排序规则表 第一个操作 第二个操作：普通读写 第二个操作：volatile读 第二个操作：volatile写 普通读写 可以重排 可以重排 不可以重排 volatile读 不可以重排 不可以重排 不可以重排 volatile写 可以重排 不可以重排 不可以重排 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略 在每个volatile写操作的前面插入一个StoreStore屏障 在每个volatile写操作的后面插入一个StoreLoad屏障 在每个volatile读操作的后面插入一个LoadLoad屏障 在每个volatile读操作的后面插入一个LoadStore屏障 上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图 缓存一致性协议MESI多个CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致，不让系统数据混乱，就引出了个一致性的协议MESI MESI协议缓存状态 MESI是指4种状态的首字母。每个Cache line有4个状态，可用2个bit表示，它们分别是： 状态 描述 监听任务 M修改（Modified） 该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中 缓存行必须时刻监听所有试图读该缓存行写回主存 并将状态变为S(共享） E独享、互斥 （Exclusive） 该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中 缓存行也必须监听其它缓存读主存中变成S（共享）状态 S共享 （Shared） 该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中 缓存行也必须监听其它缓存使该缓存成无效（Invalid） I 无效 （Invalid） 该Cache line无效 无 ==注意==：对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的，而S状态可能是非一致的。如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其他缓存不会广播他们作废掉该缓存行的通知，同样由于该缓存并没有保存该缓存行的copy数量，因此（即使有这样的通知）也没有办法确定自己是否已经独享了该缓存行。 如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务 缓存行伪共享 Cpu缓存系统中是以缓存行（cache line）为单位存储的。目前主流的CPU Cache的Cache Line大小都是64bytes.在多线程情况下，如果需要修改“共享在同一个缓存行的变量”，就会无意中影响彼此的性能，这就是伪共享 例如：现在有2个long型变量a,b , 如果有t1在访问a, t2在访问b, 而a与b刚好在同一个cache line中，此时t1先修改a,将导致b被刷新 Java8中新增了一个注解：@sun.misc.Contended.加上这个注解的类会自动补齐缓存行，需要注意的是此注解默认是无效的，需要在jvm启动时设置-XX:RestrictContended才会生效 MESI优化和他们引入的问题 缓存的一致性消息传递是要时间的，这就使其切换时会产生延迟。当一个缓存被切换状态时，其他缓存收到消息完成各自的切换并且发出回应消息，这么一长串的时间中CPU都会等待所有缓存响应完成。可能出现的的阻塞都会导致各种各样的性能问题和稳定性问题 切换状态阻塞解决——CPU存储缓存（Store Bufferes） 比如你需要修改本地缓存的一条消息，那么你必须将I（无效）状态通知到其他拥有该缓存数据的CPU缓存中，并且等待确认，等待确认的过程会阻塞处理器，这会降低处理器性能。因为这个等待远远比上一个指令的执行时间长的多 Store Bufferes 为了避免这种CPU运算能力的浪费，Store Bufferes（存储缓存）被引入使用。处理器把它想要写入到主存的值，先写到存储缓存，然后继续去处理其他事情。当所有失效确认（Invalidate Acknowledge)都接收到时，数据才会最终被提交 这样做有两个风险 Store Bufferes的风险 第一：就是处理器会尝试从存储缓存（Store buffer)中读取值，但它还没有进行提交。这个的解决方案称为Store Foewarding，它使得加载的时候，如果存储缓存中存在，则进行返回。 第二：保存什么时候会完成，这个并没有任何保证 硬件内存模型 执行失效也不是一个简单的操作，它需要处理器去处理。另外，存储缓存（Store Buffers）并不是无穷大的，所以处理器有时需要等待失效确认的返回。这两个操作都会使得性能大幅降低。为了应付这种情况，引入了失效队列。他们的约定如下： 对于所有的收到的Invalidate请求，Invalidate Acknowlege消息必须立刻发送 Invalidate并不真正执行，而是被放在一个特殊的队列中，在方便的时候才会去执行 处理器不会发送任何消息给所处理的缓存条目，直到它处理Invalidate。即便是这样处理器已经不知道什么时候优化是允许的，而什么时候并不允许，干脆处理器将这个任务丢给了写代码的人。这就是内存屏障 写屏障 Store Memory Barrier(a.k.a. ST, SMB, smp_wmb)是一条告诉处理器在执行这之后的指令之前，先执行所有已经在存储缓存（store buffer）中的保存的指令。 读屏障Load Memory Barrier (a.k.a. LD, RMB, smp_rmb)是一条告诉处理器在执行任何的加载前，先执行所有已经在失效队列中的失效操作的指令。 Synchronized详解 设计同步器的意义多线程编程中，有可能会出现多个线程同时访问同一个共享，可变资源的情况下，这个资源我么称之为临界资源；这种资源可能是：对象、变量、文件等 共享：资源可以由多个线程同时访问 可变：资源可以在其生命周期内被修改 由于线程执行的过程是不可控的，所以需要采用同步机制来协同对对象可变状态的访问 如何解决线程并发安全问题？ 实际上，所有的并发模式在执行线程安全问题时，采用的方案都是序列化访问临界资源。即在同一时刻，只能有一个线程访问临界资源，也称作同步互斥访问 Java中，提供了两种方式来实现同步互斥访问：synchronized和lock同步器的本质就是加锁目的：序列化访问临界资源，即同一时刻只能有一个线程访问临界资源（同步互斥访问）不过有一点需要区别的是：当多个线程执行一个方法时，该方法内部的局部变量并不是临界资源，因为这些局部变量是在每个线程的私有栈中，因此不具有共享性，不会导致线程安全问题 Synchronized原理详解synchronized内置锁是一种对象锁（锁的是对象而非引用），作用粒度是对象，可以用来实现对临界资源的同步互斥访问，是可重入的 加锁的方式： 同步实例方法，锁的是当前实例对象 同步类方法，锁的是当前类对象（class) 同步代码块，锁的是括号里面的对象 Synchronized底层原理synchronized是基于JVM内置锁实现，通过内部对象Monitor(监视器锁）实现，基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖底层操作系统的Mutex lock(互斥锁）实现，它是一个重量级锁，性能较低。当然，JVM内置锁在1.5之后版本做了重大的优化，如锁粗化(Lock Coarsening),锁消除（Lock Elimination）,轻量级锁（Lightweight Locking)、偏向锁（Biased Locking)、适应性自旋（Adaptive Spinning)等技术来减少锁操作的开销，内置锁的并发性能已经基本与Lock持平。Synchronized关键字被编译成字节码后会被翻译成 monitorenter 和monitorexit 两条指令分别在同步块逻辑代码的起始位置与结束位置 每个对象都有一个自己的Monitor（监视器锁） Monitor监视器锁 任何一个对象都有一个Monitor与之关联，当且一个Monitor被持有后，它将处于锁定状态。Synchronized在JVM里的实现都是 基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的Monitorenter和Monitorexit指令来实现。 monitorenter：每个对象都是一个监视器锁（Monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下： 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者 如果该线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1 如果其他线程占有该monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权 monitorexit：执行monitorexit的线程必须是object ref对应的monitor的所有者。指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor,步再是这个monitor的所有者，其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权 Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。 看一个同步方法，例如： 123public synchronized void method()&#123;System.out.println(&quot;hello world&quot;);&#125; javap解析后 从编译的结果来看，方法的同步 并没有 通过指令 monitorenter 和 monitorexit 来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了ACC_SYNCHRONIZED 标示符。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个 monitor对象。 两种不同方式本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。两个指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间的来回切换，对性能有较大性能 什么是monitor？ 可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。与一切皆对象一样，所有的java对象是天生的Monitor，每一个Java对象都有称为Monitor的潜质，因为在java的设计中，每一个Java对象自打娘胎里出来就带了把看不见的锁，它叫做内置锁或者Monitor锁；也就是通常说的Synchronized的对象锁，MarkWord锁标识位为**10**，其中指针指向的是Monitor对象的起始位置；在Java虚拟机（HotSpot）中，Monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） 12345678910111213141516171819ObjectMonitor()&#123;_header = NULL;_count = 0; // 记录个数_waiters = 0,_recursions = 0;_object = NULL;_owner = NULL;_WaitSet = NULL; // 处于wait状态的线程，会被加入到_WaitSet_WaitSetLock = 0 ;_Responsible = NULL ;_succ = NULL ;_cxq = NULL ;FreeNext = NULL ;_EntryList = NULL ; // 处于等待锁block状态的线程，会被加入到该列表_SpinFreq = 0 ;_SpinClock = 0 ;OwnerIsThread = 0 ;&#125; ObjectMonitor中有两个队列，\\_WaitSet 和 \\_EntryList，用来保存ObjectWaiter对象列表（每个等待锁的线程都会被封装成ObjectWaiter对象） _owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时 首先会进入_EntryList集合，当线程获取到对象的Monitor后，进入_Owner区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1 若线程调用wait方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入WaitSet集合中等待被唤醒 若当前线程执行完毕，也将释放monitor（锁）并复位count的值，以便其他线程进入获取monitor(锁）；同时，Monitor对象存在于每个Java对象的对象头Mark Word中（存储的指针的指向),synchronized锁便是通过这种方式获取锁的， 也是为什么java中任意对象可以作为锁的原因，同时notify/notifyAll/wait等方法会使用到Monitor锁对象，所以必须在同步代码块中使用。 监视器Monitor有两种同步方式：互斥与协作 多线程环境下线程之间如果需要共享数据，需要解决互斥访问数据的问题，监视器可以确保监视器上的数据在同一时刻只会有一个线程在访问。那么有个问题来了，我们知道synchronized加锁加在对象上，对象是如何记录锁状态的呢？答案是==锁状态是被记录在每个对象的对象头==（Mark Word）中，下面我们一起认识一下对象的内存布局 对象的内存布局HotSpot虚拟机中，对象在内存中存储的布局分为三块区域：对象头（Header)、示例数据（Instance Data）和对齐填充（Padding） 对象头：比如Hash码，对象GC存活年代，对象锁，锁状态标志，偏向锁（线程）ID，偏向时间，数组长度（数组对象）等。Java对象头一般占有2个机器码（ 在32位虚拟机中，1个机器码等于4字节，也就是32bit，在64位虚拟机中，1个机器码是8个字节，也就是64bit ）； 但是如果对象是数组类型，则需要3个机器码，因为JVM虚拟机可以通过Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确定数组的大小，所以用一块来记录数组的长度 实例数据：存放类的属性数据信息，包括父类的属性信息 对齐填充：由于虚拟机要求对象起始地址必须是8字节的整数倍，填充数据不是必须存在的，仅仅是为了字节对齐 HotSpot虚拟机的对象头包括两部分信息，第一部分是&quot;Mark Word&quot;，用于存储对象自身的运行时数据，如哈希码（HashCode），GC分代年龄、锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等等，它是实现轻量级锁和偏向锁的关键。这部分数据的长度在32位和64位的虚拟机（暂不考虑开启压缩指针的场景）中分别位32个和64个Bits，官方称它为“Mark Word”。对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。 在32位的HotSpot虚拟机 中对象未被锁定的状态下，Mark Word的32个Bits空间中的25Bits用于存储对象哈希码（HashCode），4Bits用于存储对象分代年龄，2Bits用于存储锁标志位，1Bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示： 32位虚拟机 64位虚拟机 现在的虚拟机基本上是64位的，而64位的对象头有点浪费空间，JVM默认会开启指针压缩，所以基本上也是按32位的形式记录对象头的。 手动设置: -XX:+UseCompressedOops 哪些信息会被压缩？ 对象的全局静态变量(即类属性) 对象头信息：64位平台下，原生对象头大小为16字节，压缩后为12字节 对象的引用类型：64位平台下，引用类型本身大小为8字节，压缩后为4字节 对象数组类型：64位平台下，数组类型本身大小为24字节，压缩后16字节 对象头分析工具 分析工具JOL，它是OpenJDK开源工具包，maven坐标如下 12345&lt;dependency&gt;&lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;&lt;artifactId&gt;jol-core&lt;/artifactId&gt;&lt;version&gt;0.10&lt;/version&gt;&lt;/dependency&gt; 12345public static void main(String[] args) &#123;Object o = new Object();// 打印markwordSystem.out.println(ClassLayout.parseInstance(o).toPrintable());&#125; 打印出来的对象内存信息如下： 12345678java.lang.Object object internals:OFFSET SIZE TYPE DESCRIPTION VALUE0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) # 此处是Mark Word4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0)8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 第一行为Mark Word 00000001 00000000 00000000 00000000 会发现与上面的图对比，发现是轻量级锁状态，原因： 大端模式和小端模式： 所谓的【大端模式】，是指数据的【低位】保存在内存的【高地址】中，而数据的高位，保存在内存的低地址中； 所谓的【小端模式】，是指数据的【低位】保存在内存的【低地址】中，而数据的高位保存在内存的高地址中。（大部分的操作系统都是小端，而通讯协议是大端） 因为是小端模式，所以真正的bit位是——&gt;00000000 00000000 00000000 00000001，是无锁状态 然是无锁状态，前25位表示hashcode值，为什么hashcode是0？ 因为这个hashcode是jvm内置函数，类似于懒加载，此时还没有计算 此时将代码修改为如下： 1234567public static void main(String[] args) &#123;Object o = new Object();System.out.println(ClassLayout.parseInstance(o).toPrintable());synchronized (o)&#123;System.out.println(ClassLayout.parseInstance(o).toPrintable());&#125;&#125; 打印的Mark Word为 00011000 11110111 00000010 00000010 即 00000010 00000010 11110111 00011000 发现对象头从无锁——&gt;轻量级锁 为什么不是偏向锁？ 因为JVM会延迟去启动偏向锁，JVM启动时依赖大量的hashMap class对象等，这些对象里面也存在大量的同步快，JVM启动时内部也会去启动十几个线程，这些线程内部也会存在竞争，JVM为了避免造成 偏向锁 到 轻量级锁 到重量级锁 这种锁升级过程，减少锁升级的开销，所以把偏向锁推迟启动 把代码睡眠几秒钟 12345678public static void main(String[] args) throws InterruptedException &#123;TimeUnit.SECONDS.sleep(10);Object o = new Object();System.out.println(ClassLayout.parseInstance(o).toPrintable());synchronized (o)&#123;System.out.println(ClassLayout.parseInstance(o).toPrintable());&#125;&#125; 123456789101112131415161718java.lang.Object object internals:OFFSET SIZE TYPE DESCRIPTION VALUE0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5)4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0)8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes totaljava.lang.Object object internals:OFFSET SIZE TYPE DESCRIPTION VALUE0 4 (object header) a8 f7 06 03 (10101000 11110111 00000110 00000011) (50788264)4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0)8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 第一次打印的：00000101 00000000 00000000 00000000 就已经是偏向锁状态了，但是偏向锁的前23bit位会记录线程ID，此处并没有，这种 称之为匿名偏向，可偏向状态 如果一直处于偏向状态，无法重偏向的话，那么MarkWord会一直记录最后一个偏向线程的状态 锁的膨胀升级过程 锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级到重量级锁，但是锁的升级是单向的，也就是只能从低到高升级，不会出现锁的降级。从JDK1.6中默认是开启偏向锁和轻量级的，可以通过-XX:-UseBiasedLocking来禁用偏向锁 偏向锁： 偏向锁是Java6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁（会涉及到一些CAS操作，耗时）的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提高了程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。 默认开启偏向锁 开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0 关闭偏向锁：-XX:-UseBiasedLocking 轻量级锁： 倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时，Mark Word的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 自旋锁： 轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程就可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环（这也是称为自旋的原因），一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。后没办法也就只能升级为重量级锁 锁消除： 消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间。锁消除的依据是逃逸分析的数据支持 锁消除，前提是Java必须运行在server模式，（server模式会比client模式作更多的优化），同时必须开启逃逸分析 -XX:+DoEscapeAnalysis 开启逃逸分析 -XX:+EliminateLocks 表示开启锁消除 使用逃逸分析，编译器可以对代码做如下优化： 同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步 将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配 分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中 AQSJava并发编程核心在于java.concurrent.util包，而juc当中的大多数同步器实现都是围绕着共同的基础行为，比如等待队列、条件队列、独占获取、共享获取等，而这个行为的抽象就是基于AbstractQueuedSychronizer简称AQS，AQS定义了一套多线程访问共享资源的同步器框架，是一个依赖状态（state）的同步器。 ReentrantLockReentrantLock是一种基于AQS框架的应用实现，是JDK中的一种线程并发访问的同步手段，它的功能类似于synchronized，是一种互斥锁，可以保证线程安全，而且它具有比sychronized更多的特性，比如它支持手动加锁与解锁，支持加锁的公平性 12345ReentrantLock lock = new ReentrantLock(false); // false为非公平锁；true为公平锁public void func()&#123;lock.lock(); // 加锁lock.unlock(); // 解锁&#125; ReentrantLock如何实现sychronized不具备的公平与非公平性呢？ 在ReentranLock内部定义了一个Sync的内部类，该类继承AbstractQueuedSynchronized，对该抽象类的部分方法做了实现；并且还定义了两个子类 1、FairSync公平锁的实现 2、NonfairSync非公平锁的实现 这两个类都继承自Sync，也就是间接继承了AbstractQueuedSynchronized，所以这一个ReentrantLock同时具备公平与非公平特性 上面设涉及的主要设计模式：模板模式-子类根据需要做具体业务实现 ReentrantLock默认是非公平锁 123public ReentrantLock() &#123;sync = new NonfairSync();&#125; AQS具备特性 阻塞等待队列共享/独占公平/非公平可重入 允许中断 除了Lock外，Java.concurrent.util当中同步器的实现Lock,Barrier,BlockingQueue等，都是基于AQS框架实现，一般通过定义内部类Sync继承AQS 将同步器所有调用都映射到Sync对应的方法 ASQ内部维护属性volatile int state(32位) state表示资源的可用状态 State三种访问方式 getState()、setState()、compareAndSetState() AQS定义两种资源共享方式 Exclusive-独占，只有一个线程能执行，如ReentrantLock Share-共享，多个线程可以同时执行，如Semaphore/CountDownLatch AQS定义两种队列 同步等待队列 条件等待队列 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： isHeldExclusively()：该线程是否正在独占资源，只有用到condition才需要去实现它 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true,失败则返回false tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false tryAcquireShare：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true,否则返回false AQS类中的内部类Node 12345678910111213141516// 标记结点为独占模式static final Node EXCLUSIVE = null;// 在同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待static final int CANCELLED = 1;// 后继结点的线程处于等待状态，而当前的结点如果释放了同步状态或者被取消，将会通知后继结点，使后继节点的线程得以运行static final int SIGNAL = -1;// 节点在等待队列中，节点的线程等待在Condition上，当其他线程对Condition调用了signal()方法后，// 该节点会从等待等待中转移到同步队列中，加入到同步状态的获取中static final int CONDITION = -2;// 表示下一次共享式同步状态获取将会被无条件地传播下去static final int PROPAGATE = -3;/*** 标记当前代结点的信号量状态（1，0，-1，-2，-3）* 使用CAS更改状态，volatile保证线程可见性*/volatile int waitStatus; 123final void lock() &#123;acquire(1);&#125; acquire方法 123456public final void acquire(int arg) &#123; // arg = 1if (!tryAcquire(arg) &amp;&amp;acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 这里如果线程是中断被唤醒的，会返回true，就会走下面的自我中断selfInterrupt(); // 自我中断 为什么要自我中断呢？因为上面的acquireQueued（）方法返回true代表线程因为中断而唤醒的，但是我们不能直接杀死这个线程；在java以前的版本中，有个Thread.stop方法（现在已经过时）// 当我们不需要这个线程继续工作时，进行调用，但是这个线程可能正工作一半，这样立即停止可能会出问题，所以就引出来了中断信号，我们可以在后面的代码中，去判断线程是否被中断，来采取措施，例如下面&#125; 我们可以自己在代码里进行判断中断信号，而进行优雅的线程退出 1234567891011public void func()&#123;lock.lock();for(;;)&#123;if(Thread.interrupted())&#123;break; // 线程如果是被中断唤醒的话，不走下面的业务逻辑代码( 如果是中断唤醒，selfInterrupt()方法会打上中断标记)// ps:Thread.interrupted()调用会擦除中断信号，所以需要在selfInterrupt()方法里重新打上标记&#125;// 业务逻辑代码&#125;lock.unlock();&#125; tryAcquire 方法：尝试获取资源；如果此时hasQueuedPredecessors()中已经有线程等待，则返回false;上一步就会走 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)方法。 addWaiter(Node.EXCLUSIVE) EXCLUSIVE表示独占模式 1234567891011121314151617181920protected final boolean tryAcquire(int acquires) &#123; // acquires = 1final Thread current = Thread.currentThread();int c = getState(); // state状态，没被占用时状态为0if (c == 0) &#123;if (!hasQueuedPredecessors() &amp;&amp; // 判断同步队列中是否有人等待compareAndSetState(0, acquires)) &#123; //CAS 将state 修改为1setExclusiveOwnerThread(current); // 设置当前线程为锁的拥有者return true;&#125;&#125;// 如果当前是锁的拥有者是自己else if (current == getExclusiveOwnerThread()) &#123;int nextc = c + acquires;if (nextc &lt; 0)throw new Error(&quot;Maximum lock count exceeded&quot;);setState(nextc);return true;&#125;return false;&#125; addWaiter方法 1234567891011121314private Node addWaiter(Node mode) &#123;Node node = new Node(Thread.currentThread(), mode); // new 一个Node节点，将模式设为独占模式，里面的thread属性设置为当前线程// Try the fast path of enq; backup to full enq on failureNode pred = tail; // tail标记同步队列尾部节点if (pred != null) &#123;node.prev = pred;if (compareAndSetTail(pred, node)) &#123;pred.next = node;return node;&#125;&#125;enq(node); // 自旋return node; //返回当前节点&#125; enp(node)方法 123456789101112131415private Node enq(final Node node) &#123;for (;;) &#123;Node t = tail;if (t == null) &#123; // 作者思想是，先初始化队列，头节点和尾节点指向一个 空Node,以免后续出现空指针，方便后续操作if (compareAndSetHead(new Node()))tail = head;&#125; else &#123; // 如果尾部节点不为空，node.prev = t; // 将当前节点的前节点指向 尾部t所指向的节点（也就是最后一个节点）；（当前节点要变成尾节点）if (compareAndSetTail(t, node)) &#123; // 然后cas将tail尾部指针 指向当前节点t.next = node; // 将之前旧的尾节点（变化之后现在是倒数第二个节点）的next属性指向当前nodereturn t;&#125;&#125;&#125;&#125; **acquireQueued(addWaiter(Node.EXCLUSIVE), arg)**方法，尝试加入队列，addWaiter(Node.EXCLUSIVE)方法返回的是当前节点， 1234567891011121314151617181920212223final boolean acquireQueued(final Node node, int arg) &#123;boolean failed = true;try &#123;boolean interrupted = false;for (;;) &#123;final Node p = node.predecessor(); // 这一步获取当前的节点的前驱节点if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 如果前驱节点是head,不会立马加入队列，会让你再次尝试去获取资源，避免阻塞影响性能// 获取资源成功后setHead(node); // head = node;node.thread = null;node.prev = null; 将head头节点指向当前节点，并将当前节点变为空p.next = null; // 原先的头节点 指向断掉，下次GC回收 具体参考下图failed = false;return interrupted;&#125;// 不能获取资源，阻塞等待唤醒if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;parkAndCheckInterrupt())interrupted = true;&#125;&#125; finally &#123;if (failed)cancelAcquire(node);&#125;&#125; shouldParkAfterFailedAcquire()方法 1、第一次循环时会去修改前驱节点的waitStatus= -1， 返回false; 2、第二次循环，前驱节点已经修改为-1，返回true时，才会走上面的parkAndCheckInterrupt()方法 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) waitStatus控制的是下一个节点 用前驱节点记录有什么好处？ 当前节点唤醒获取资源后，head指针指向当前Node节点（此时Node节点里thread记录的线程为空）waitState也是0，不需要判断waitState状态,每次都会去修改waitState状态为-1，保证可以唤醒，因为waitState信号量可能为会变（-3） waitState节点的生命状态：信号量 SIGNAL = -1 //可被唤醒 CANCELLED = 1 // 代表出现异常，中断引起的，需要废弃结束 CONDITION = -2 // 条件等待 PROPAGATE = -3 // 传播 0 — 初始状态Init状态 1234567891011121314private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;int ws = pred.waitStatus; // 判断前驱节点的waitStatus； waitStatus初始状态都是0if (ws == Node.SIGNAL) // Node.SIGNAL = -1return true;if (ws &gt; 0) &#123;do &#123;node.prev = pred = pred.prev;&#125; while (pred.waitStatus &gt; 0);pred.next = node;&#125; else &#123;compareAndSetWaitStatus(pred, ws, Node.SIGNAL); // waitStatus=0；所以会走这里，将前驱节点的waitStatus状态改为SIGNAL -1；-1代表可被唤醒&#125;return false;&#125; waitStatus=0 –&gt; -1 , head节点为什么改到-1，因为持有锁的线程T0在释放锁的时候，会判断head节点的waitStatus是否 !=0 ,如果不等于0，会将head节点的waitStatus改成0；要想唤醒正在排队的第一个线程T1，T1被唤醒后再走acquireQueued（）方法中的循环，再去判断前驱节点是否是头节点，再去拿锁（如果是非公平锁，抢锁是可能失败的） if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; 的parkAndCheckInterrupt（）方法 1234private final boolean parkAndCheckInterrupt() &#123;LockSupport.park(this) // 调用LockSupport的park方法阻塞线程return Thread.interrupted(); // 线程是否被中断，如果线程走到这里是因为中断唤醒的，会返回true,也就是返回线程里的中断信号； 注意： Thread.interrupted()调用会擦除中断信号，所以需要在外面acquires方法里调用selfInterrupt()重新打上中断信号&#125; LockSupport.park阻塞线程(会进入waiting等待状态)。唤醒有两种方式，一种是ReentrantLock里的unlock方法里面，会调用LockSupport.unpark方法唤醒 另一种就是线程被中断唤醒 Reentrantlock还有一个lockInterruptibly（）方法，跟lock一样能起到同样的效果，只是会抛出编译性异常 12345678910public void lockInterruptibly() throws InterruptedException &#123;sync.acquireInterruptibly(1);&#125;public final void acquireInterruptibly(int arg) throws InterruptedException &#123;if (Thread.interrupted())throw new InterruptedException();if (!tryAcquire(arg)) // 一样的尝试获取资源doAcquireInterruptibly(arg);&#125; doAcquireInterruptibly(arg)方法 跟lock里面的逻辑几乎一模一样。只是再parkAndCheckInterrupt()方法里如果是被中断唤醒的，会抛出异常; 最后走finally的时候呢，failed为true，会走cancelAcquire(node)方法，会在此方法里面将Node节点 waitStatus改成CANCELLED（也就是1） 12345678910111213141516171819202122private void doAcquireInterruptibly(int arg)throws InterruptedException &#123;final Node node = addWaiter(Node.EXCLUSIVE);boolean failed = true;try &#123;for (;;) &#123;final Node p = node.predecessor();if (p == head &amp;&amp; tryAcquire(arg)) &#123;setHead(node);p.next = null;failed = false;return;&#125;if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;parkAndCheckInterrupt())throw new InterruptedException();&#125;&#125; finally &#123;if (failed)cancelAcquire(node);&#125;&#125; 阻塞队列BlockingQueueblockQueue的特性是任意时刻只有一个线程可以进行take或者put操作，并且BlockQueue提供了超时return null的机制，在许多生产场景里都可以看到这个这个工具的身影 线程通信的一个工具，在任意时刻，不管并发有多高，在单JVM上，同一时间永远都只有都只有一个线程能够对队列进行入队或者出队操作 队列类型 1、无限队列（unbounded queue）- 几乎可以无限增长 2、有限队列（bounded queue）- 定义了最大容量 队列数据结构 队列实质就是一种存储数据的结构，通常用链表或者数组实现 一般而言队列具备FIFO先进先出的特性，当然也有双端队列（Deque）优先级队列 主要操作：入队（EnQueue）与出队（Dequeue) 常见的四种阻塞队列 ArrayBlockingQueue 由数组支持的有界队列 LinkedBlockingQueue由链接节点支持的可选有界队列 PriorityBlockingQueue由优先级堆支持的无界优先级队列 DelayQueue由优先级堆支持的，基于时间的调度队列 ArrayBlockingQueue new ArrayBlockingQueue&lt;&gt;(10); 1234567891011121314public ArrayBlockingQueue(int capacity) &#123;this(capacity, false);&#125;public ArrayBlockingQueue(int capacity, boolean fair) &#123;if (capacity &lt;= 0)throw new IllegalArgumentException();this.items = new Object[capacity];lock = new ReentrantLock(fair); // 创建一把锁notEmpty = lock.newCondition(); // 条件对象notFull = lock.newCondition(); // 条件对象&#125; 123456789101112public void put(E e) throws InterruptedException &#123;checkNotNull(e);final ReentrantLock lock = this.lock;lock.lockInterruptibly();try &#123;while (count == items.length) // 队列满了notFull.await(); // 释放锁enqueue(e);&#125; finally &#123;lock.unlock();&#125;&#125; notFull.await()方法 12345678910111213141516171819public final void await() throws InterruptedException &#123;if (Thread.interrupted()) // 线程被中断,直接抛出异常throw new InterruptedException();Node node = addConditionWaiter(); // 加入条件等待队列int savedState = fullyRelease(node); // 释放锁int interruptMode = 0;while (!isOnSyncQueue(node)) &#123;LockSupport.park(this);if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)break;&#125;if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)interruptMode = REINTERRUPT;if (node.nextWaiter != null) // clean up if cancelledunlinkCancelledWaiters();if (interruptMode != 0)reportInterruptAfterWait(interruptMode);&#125; addConditionWaiter()方法 123456789101112131415private Node addConditionWaiter() &#123;Node t = lastWaiter;// If lastWaiter is cancelled, clean out. 判断是不是无效的队列if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123;unlinkCancelledWaiters();t = lastWaiter;&#125;Node node = new Node(Thread.currentThread(), Node.CONDITION);if (t == null)firstWaiter = node;elset.nextWaiter = node;lastWaiter = node;return node;&#125; fullyRelease(node)方法 123456789101112131415final int fullyRelease(Node node) &#123;boolean failed = true;try &#123;int savedState = getState(); // 获取锁的信号量if (release(savedState)) &#123; // 释放锁failed = false;return savedState;&#125; else &#123;throw new IllegalMonitorStateException();&#125;&#125; finally &#123;if (failed)node.waitStatus = Node.CANCELLED;&#125;&#125; Semaphore从字面意思是信号量的意思，它的作用是控制访问特定资源的线程数目，底层依赖AQS的状态state 怎么使用Semaphore123456789101112131415161718Semaphore semaphore = new Semaphore(5); // state会初始化为5，相当于总的容量池子....semaphore.acquire(1); // 从总的池子里拿出一个凭据 state - 1....semaphore.release(1); // 将凭据还回总的池子 state + 1semaphore.acquire(1); 支持中断式的，如果线程被中断，会抛出异常；semaphore.acquireUninterruptibly()就不会如果获取信号量之后的逻辑代码执行时间过长，导致其他线程长时间阻塞，消耗资源semaphore.tryAcquire(500,TimeUnit.SECONDS); // 尝试获取资源并且允许的最大等待时间if (semaphore.tryAcquire(500, TimeUnit.MILLISECONDS)) &#123;// 尝试去获取信号量 ，最长等待500msSystem.out.println(Thread.currentThread().getContextClassLoader() + &quot; acquire() at time : &quot; + System.currentTimeMillis());TimeUnit.SECONDS.sleep(5);semaphore.release();&#125;else &#123;// 或者返回托底数据throw new RuntimeException(&quot;获取资源超时&quot;);&#125; 源码剖析 Semaphore类中结构 1234567891011121314public class Semaphore implements java.io.Serializable &#123;private final Sync sync;abstract static class Sync extends AbstractQueuedSynchronizer &#123;......&#125;static final class NonfairSync extends Sync &#123;......&#125;static final class FairSync extends Sync &#123;......&#125;&#125; 调用new Semaphore(2)时； 12345678public Semaphore(int permits) &#123;sync = new NonfairSync(permits); // 默认非公平锁&#125;// boolean fair 为 true时为公平锁public Semaphore(int permits, boolean fair) &#123;sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125; 最终会将AQS中的state设置为2 前景：假设两个信号量都被人取完，此时state = 0 再然后我们调用**semaphore.acquire()**时 （ps:以下基于公平锁） 1234567891011public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); // 默认传1&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 线程如果中断，抛出异常 if (tryAcquireShared(arg) &lt; 0) // 尝试获取信号量 doAcquireSharedInterruptibly(arg); // 如果tryAcquireShared返回-1， 会走到下面的2、doAcquireSharedInterruptibly(int arg)方法&#125; 1、tryAcquireShared(arg)方法 1234567891011protected int tryAcquireShared(int acquires) &#123; // acquires = 1 for (; ; ) &#123; if (hasQueuedPredecessors()) // 判断CLH队列中是否有元素 return -1; // 如果已经有人在排队了，直接返回false int available = getState(); // 获取AQS中的state int remaining = available - acquires; if (remaining &lt; 0 || // 基于上面的场景的话，这里为true,返回-1 compareAndSetState(available, remaining)) // CAS操作修改state的值，修改失败会自旋 return remaining; &#125;&#125; 2、doAcquireSharedInterruptibly(int arg)方法 123456789101112131415161718192021222324252627private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); // 加入CLH队列，共享模式的节点 boolean failed = true; // failed初始值 try &#123; for (; ; ) &#123; final Node p = node.predecessor(); // 获取当前节点的前驱节点 if (p == head) &#123; // 如果当前节点的前驱节点是头节点 int r = tryAcquireShared(arg); // 会再次尝试下获取资源 if (r &gt;= 0) &#123; // 如果获取到资源了 setHeadAndPropagate(node, r); // 设置头节点，即下面的 setHeadAndPropagate方法 p.next = null; // 原先p指向的头节点的指针，可以断开GC了 failed = false; return; &#125; &#125;// 如果当前节点的前驱节点 不是头节点，那么会去修改前驱节点的waitState = -1 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 那么此时有两种情况 第一，当前节点加入队列时，是头节点，并且获取资源成功 第二，当前节点加入队列时，前面已经有人入队了，或者获取资源失败，那么会尝试阻塞自己 我们先看第二种情况，节点入队 12if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;parkAndCheckInterrupt()) shouldParkAfterFailedAcquire()方法 总的来说，此方法是为了修改前驱节点的waitStatus为SIGNAL， 如果前驱节点的waitStatus已经是Signal,返回true; 值得注意的是，如果要加入队列，那么上面的doAcquireSharedInterruptibly方法的自旋会走两遍，第一遍循环执行完此方法后，修改前驱节点状态，第二次循环才返回true,然后才会走parkAndCheckInterrupt()方法 123456789101112131415161718private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // ！！！调用 LockSupport.park方法将自己阻塞在这里 return Thread.interrupted(); &#125; private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // pred 当前节点的前驱节点，node为当前节点 int ws = pred.waitStatus; // 获取前驱节点的waitStatus （节点创建时waitStatus默认都为0） if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; compareAndSetWaitStatus(pred, ws, Node.SIGNAL); // cas去修改前驱节点的waitStatus为SINGAL，即-1 &#125; return false; &#125; 那么接下来我们看第一种情况，线程发现自己的前驱节点就是头节点，并且尝试获取资源成功了（比如此时有线程归还了信号量，AQS中state由0 ——&gt; 1） 那么就会走下面的setHeadAndPropagate方法 final Node p = node.predecessor();if (p == head) {int r = tryAcquireShared(arg);if (r &gt;= 0) { setHeadAndPropagate(node, r); p.next = null; failed = false; return;}} setHeadAndPropagate方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void setHeadAndPropagate(Node node, int propagate) &#123; // node为当前节点，propagate &gt; 1;此处场景下为1 Node h = head; // h指向旧的头节点 setHead(node); // 设置当前节点为新的头节点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || // propagate= 1 &gt; 0 ,走下面的逻辑 (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; // 获取当前节点的下一个节点 if (s == null || s.isShared()) // 如果此时后面有新的节点加进来了，走doReleaseShared doReleaseShared(); &#125;&#125;private void doReleaseShared() &#123; for (;;) &#123; Node h = head; // 获取头节点（此种情况下，头节点就是当前节点，因为上面已经修改过了) if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; // 获取头节点waitStatus if (ws == Node.SIGNAL) &#123; // 如果waitStatus状态是SIGNAL即-1 // (注意！！新加进来的节点都会去修改前节点的waitStatus为SIGNAL，即上面说的第二种情况的shouldParkAfterFailedAcquire方法) // 所以这里的情况ws == Node.SIGNAL为真 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) // CAS去修改h指向的头节点的waitStatus为0 continue; unparkSuccessor(h); // 如果修改成功了 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // 在某一个线程执行上面方法时，可能会有别的线程加进来，导致头节点变更 break; &#125;&#125;private void unparkSuccessor(Node node) &#123; // node 即为上面h所指向的头节点 int ws = node.waitStatus; // 此时waitStatus被CAS修改为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; // 获取当前节点的下一节点 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) // 如果下一节点不为空，唤醒它 LockSupport.unpark(s.thread);&#125;private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // ！！！如果下一节点阻塞在这里，会被唤醒接着进行自旋 return Thread.interrupted();&#125; semaphore.release() 123456789101112public void release() &#123; sync.releaseShared(1); // 默认释放1&#125;public final boolean releaseShared(int arg) &#123; // arg = 1 if (tryReleaseShared(arg)) &#123; // 成功释放返回true doReleaseShared(); // 走下面的doReleaseShared()方法 return true; &#125; return false;&#125; tryReleaseShared(arg)方法 12345678910protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); // 获取AQS中的state int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next)) // CAS将信号量还回去 return true; &#125;&#125; doReleaseShared()方法 12345678910111213141516171819就是上面semaphore.acquire()里面setHeadAndPropagate设置头节点所调用的方法 private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; CountDownLatch1234567891011121314151617181920212223242526272829303132333435@Slf4jpublic class SeeDoctorTask implements Runnable&#123; private CountDownLatch countDownLatch; public SeeDoctorTask(CountDownLatch countDownLatch) &#123; this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; try &#123; log.info(&quot;开始看医生&quot;); TimeUnit.SECONDS.sleep(2); log.info(&quot;看医生结束，准备离开病房&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; if (countDownLatch != null)&#123; countDownLatch.countDown(); &#125; &#125; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(2); Thread t1 = new Thread(new SeeDoctorTask(countDownLatch)); Thread t2 = new Thread(new SeeDoctorTask(countDownLatch)); t1.start(); t2.start(); log.info(&quot;等待countDownLatch归0&quot;); countDownLatch.await(); // 主线程会阻塞等待，直到上面线程执行完 log.info(&quot;结束.....&quot;);&#125; CyclicBarrier 栅栏1234567891011121314151617181920212223242526272829303132333435363738394041public class CyclicBarrierRunner implements Runnable &#123; private CyclicBarrier cyclicBarrier; private int index; public CyclicBarrierRunner(CyclicBarrier cyclicBarrier, int index) &#123; this.cyclicBarrier = cyclicBarrier; this.index = index; &#125; @Override public void run() &#123; try &#123; System.out.println(&quot;index - &quot; + index); cyclicBarrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws BrokenBarrierException, InterruptedException &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(10, new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;所有线程执行完毕....&quot;); &#125; &#125;); for (int i = 0; i &lt; 10; i++) &#123; new Thread(new CyclicBarrierRunner(cyclicBarrier,i)).start(); &#125; // ===========上面十个线程冲破栅栏后，会打印&lt;所有线程执行完毕&gt;=========== cyclicBarrier.await(); // 主线程也算一个 // ==== 如果没有下面的九个线程，那么会一直阻塞，cyclicBarrier可以反复使用==== System.out.println(&quot;全部到达栅栏&quot;); for (int i = 0; i &lt; 9; i++) &#123; new Thread(new CyclicBarrierRunner(cyclicBarrier,i)).start(); &#125; &#125;&#125; Atomic&amp;Unsafe魔法类详解 原子操作 原子（atom)本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation)意为“不可被中断的一个或一系列操作”。 相关术语 术语名称 英文 解释 缓存行 Cache line 缓存的最小操作单位 比较并交换 Compare and Swap CAS操作需要输入两个数值，一个旧值（期望操作前的值）和一个新值，在操作期间先比较是否发生变化，如果没有发生变化，才交换成新值，发生 CPU流水线 CPU pipeline CPU流水线的工作方式就象工业生产上的装配流水线，在CPU中由56个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成56步后再由这些电路单元分别执行，这样就能实现在一个CPU时钟周期 完成一条指令，因此提高CPU的运算速度。 内存顺序冲突 Memory order violation 内存顺序冲突一般是由假共享引起，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效 处理器如何实现原子操作 32位处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 处理器自动保证基本内存操作的原子性 首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 使用总线锁保证原子性 第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致 例子：如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。如下图 原因是有可能多个处理器同时从各自的缓存行中读取变量i,分别进行加1操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求要求将被阻塞住,那么该处理器可以独占使用共享内存 使用缓存锁保证原子性 第二个机制就是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性的即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 频繁使用的内存会缓存在处理器的L1,L2和L3高速缓存里，那么原子操作就可以直接在处理器内存缓存中进行，并不需要声明总线锁。 在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效，在上述例子中，当CPU1修改缓存行中的i时使用缓存锁定，那么CPU2就不能同时缓存了i的缓存行。 但是有两种情况下处理器不会使用缓存锁定。第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行，则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。 以上两个机制我们可以通过Inter处理器提供了很多Lock前缀的指令来实现。比如位测试和修改指令BTS，BTR，BTC，交换指令XADD，CMPXCHG和其他一些操作数和逻辑指令，比如ADD(加），OR(或）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问他 Java当中如何实现原子操作 在Java中可以通过锁和循环CAS的方式来实现原子操作 JVM中的CAS操作正式利用了上文中提到的处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环CAS操作直到操作成功为止。 Atomic在Atomic包里一共有12个类，四种原子更新方式，分别是原子更新基本类型，原子更新数组，原子更新数组，原子更新引用和原子更新字段。Atomic包里的类基本都是使用Unsafe实现的包装类 基本类：AtomicInteger，AtomicLong，AtomicBoolean; 引用类型：AtomicReferernce、AtomicReference的ABA实例、AtomicStampedRerence、AtomicMarkableReference； 数组类型：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray 属性原子修改器（Updater）：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater atomic底层实现是基于Unsafe提供的三大cas-api完成；而Unsafe基于硬件原语-CMPXCHG实现原子操作cas compareAndSwapObject compareAndSwapInt compareAndSwapLong AtomicInteger的getAndIncrement()方法分析 123public final int getAndIncrement() &#123;return unsafe.getAndAddInt(this, valueOffset, 1);&#125; 123456789101112public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); // 读取AtomicInteger里的value值（AtomicInteger有个value属性） &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); // var1 -- AtomicInteger // var2 -- valueOffset value属性在对象内存当中的偏移量 // var3 -- oldValue // var5 + var4 -- oldValue + 1 return var5;&#125; CAS的ABA问题 123456789101112131415161718192021222324252627282930313233@Slf4jpublic class TestABA &#123;static AtomicInteger atomicInteger = new AtomicInteger(1);private static CountDownLatch countDownLatch = new CountDownLatch(2);public static void main(String[] args) throws InterruptedException &#123;new Thread(() -&gt;&#123; countDownLatch.countDown(); int a = atomicInteger.get(); log.info(Thread.currentThread().getName() + &quot;操作前的数值&quot;+a); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean res = atomicInteger.compareAndSet(a, 2); if (res)&#123; log.info(Thread.currentThread().getName()+ &quot; cas操作后的数值 &quot;+atomicInteger.get()); &#125;else &#123; log.info(&quot;修改失败&quot;); &#125;&#125;,&quot;t1&quot;).start();new Thread(()-&gt;&#123; countDownLatch.countDown(); atomicInteger.incrementAndGet(); log.info(Thread.currentThread().getName() + &quot; increase后的值 &quot;+ atomicInteger.get()); int j = atomicInteger.decrementAndGet(); log.info(Thread.currentThread().getName() + &quot; decrease后的值 &quot;+ atomicInteger.get());&#125;,&quot;t2&quot;).start();countDownLatch.await();&#125;&#125; 怎么解决ABA问题？ 加上版本号 。A（0）- B（1）- A（2） 如果关注过程，就可以用AtomicStampedReference，AtomicStampedReference接口有一个版本号参数 1234567891011121314151617181920212223242526272829303132@Slf4jpublic class ABASloution &#123;private static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(1,0);public static void main(String[] args) throws IOException &#123;new Thread(() -&gt; &#123; int stamp = atomicStampedReference.getStamp(); // 获取当前标识 log.info(Thread.currentThread().getName() + &quot; stamp = &quot; + stamp + &quot; 初始值 = &quot; + atomicStampedReference.getReference() ); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean b = atomicStampedReference.compareAndSet(1, 2,stamp,++stamp); log.info(Thread.currentThread().getName() + &quot; stamp = &quot; + stamp + &quot; cas操作结果: &quot; + b);&#125;,&quot;t0&quot;).start();new Thread( () -&gt; &#123; int stamp = atomicStampedReference.getStamp(); atomicStampedReference.compareAndSet(1,2,stamp,++stamp); log.info(Thread.currentThread().getName() + &quot; stamp = &quot; + atomicStampedReference.getStamp() + &quot; increment 值: &quot; + atomicStampedReference.getReference()); stamp = atomicStampedReference.getStamp(); atomicStampedReference.compareAndSet(2,1,stamp,++stamp); log.info(Thread.currentThread().getName() + &quot; stamp = &quot; + atomicStampedReference.getStamp() + &quot; decrease 值: &quot; + atomicStampedReference.getReference());&#125;,&quot;t1&quot;).start();System.in.read();&#125;&#125; Unsafe应用解析Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。 Unsafe类为一单例实现，提供静态方法getUnsafge获取Unsaefe实例，当且仅当调用getUnsafe方法的类为引导类加载器所加载时才合法，否则抛出SecurityException异常 如何获取Unsafe实例？ 1、从getUnsafe方法的使用限制条件出发，通过Java命令 -Xbootclasspath/a 把调用Unsafe相关方法的类A所在jar包路径追加到默认的bootstrap路径中，使得该类A被 引导类加载器加载，从而通过Unsafe.getUnsafe方法安全的获取Unsafe实例 java ­Xbootclasspath/a:${path} // 其中path为调用Unsafe相关方法的类所在jar包路径 2、通过反射获取单例对象theUnsafe 1234567891011121314public class UnsafeInstance &#123;public static Unsafe reflectGetUnsafe()&#123;try&#123; Class&lt;Unsafe&gt; unsafeClass = Unsafe.class; Field theUnsafe = unsafeClass.getDeclaredField(&quot;theUnsafe&quot;); theUnsafe.setAccessible(true); return (Unsafe)theUnsafe.get(null);&#125;catch (Exception e)&#123; e.printStackTrace();&#125;return null;&#125;&#125; Unsafe功能介绍 unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类 1、内存操作这部分主要包含堆外内存的分配、拷贝、释放、给定地址值操作等方法 分配内存, 相当于C++的malloc函数 public native long allocateMemory(long bytes); 扩充内存 public native long reallocateMemory(long address, long bytes); 释放内存 public native void freeMemory(long address); 在给定的内存块中设置值 public native void setMemory(Object o, long offset, long bytes, byte value); 内存拷贝 public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes); 获取给定地址值，忽略修饰限定符的访问限制。与此类似操作还有: getInt，getDouble，getLong，getChar等 public native Object getObject(Object o, long offset); 为给定地址设置值，忽略修饰限定符的访问限制，与此类似操作还有:putInt,putDouble，putLong，putChar等 public native void putObject(Object o, long offset, Object x); public native byte getByte(long address); 为给定地址设置byte类型的值（当且仅当该内存地址为allocateMemory分配 时，此方法结果才是确定的） public native void putByte(long address, byte x); 通常我们在Java中创建的对象都处于堆内内存（heap)中，堆内内存是由JVM所掌控的Java进程内存，并且他遵循JVM的内存管理机制，JVM采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法 使用堆外内存的原因 对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在GC时减少回收停顿对于应用的影响 提升程序I/O操作的性能。通常在I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存 典型应用 DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty,MINA等NIO框架中应用广泛。DirectByteBuffer对于堆外，使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。 DirectByteBuffer构造函数、创建DirectBuffer的时候，通过Unsafe.allocateMemory分配内存、Unsafe.setMemory进行内存初始化，而后构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，分配的堆外内存一起被释放 2、线程调度包括线程挂起、恢复、锁机制等方法 // 取消阻塞线程 public native void unpark(Object thread); // 阻塞线程 public native void park(boolean isAbsolute,long time); //获得对象锁（可重入） @Deprecated public native void monitorEnter(Object o); //释放对象锁 @Deprecated public native void monitorExit(Object o); //尝试获取对象锁 @Deprecated public native boolean tryMonitorEnter(Object o); 方法park，unpark即可实现线程的挂起与恢复，将一个线程进行挂起是通过park方法实现的，调用park方法后，线程将一直阻塞直到超时或者中断等条件出现； unpark可以终止一个挂起的线程，使其恢复正常 3、内存屏障在Java 8中引入，用于定义内存屏障（也叫内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才开始执行此点之后的操作），避免代码重排序 // 内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前 public native void loadFence(); // 内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前 public native void storeFence(); //内存屏障，禁止load，store操作重排序 public void fullFence(); 典型应用 在Java8中引入了一种锁的新机制——StampedLock，它可以看成是读写锁的一个改进版本。StampedLock提供了一种乐观读锁的实现，这种乐观读锁类似于无锁的操作，完全不会阻塞写线程获取写锁，从而缓解读多写少时写线程”饥饿“现象 由于StampedLock提供的乐观读锁不阻塞写线程获取读锁，当线程共享变量从主内存load到线程工作内存时，会存在数据不一致问题，所以当使用StampedLock的乐观读锁时，需要遵从如下图用例中使用的模式来确保数据的一致性 如上图用例所示计算坐标点Point对象，包含点移动方法move及计算此点到原点的距离的方法distanceFromOrigin。在方法distanceFromOrigin中，首先，通过 tryOptimisticRead方法获取乐观读标记；然后从主内存中加载点的坐标值 (x,y)；而后通过 StampedLock的validate方法校验锁状态，判断坐标点(x,y)从主内存加载到线程工作内存过程中，主内存的值是否已被其他线程通过move方法修改，如果validate返回值为true，证明(x, y)的值未被修改，可参与后续计算；否则，需加悲观读锁，再次从主内存加载(x,y) 的 新值，然后再进行距离计算。其中，校验锁状态这步操作至关重要，需要判断锁状态是否发生改变，从而判断之前copy到线程工作内存中的值是否与主内存的值存在不一致。 Collections之Map&amp;List&amp;Set HashMap数据结构 数组+链表（红黑树JDK&gt;=8) 源码分析 重要成员变量 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // hash表默认初始容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // hash表 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 默认的加载因子 static final int TREEIFY_THRESHOLD = 8; // 链表转红黑树阈值 static final int UNTREEIFY_THRESHOLD = 6; // 红黑树转链表阈值 static final int MIN_TREEIFY_CAPACITY = 64; // 链表转红黑树时hash表最小容量阈值，达不到优先扩容 HashMap时线程不安全的，不安全的具体原因就是在高并发场景下，扩容可能产生死锁（jdk1.7存在）以及get操作可能带来的数据丢失 Jdk7——扩容死锁分析死锁问题核心在于下面代码，多线程扩容导致形成的链表环 key,hashCode通过位运算 获取数组下标，会产生hash碰撞，采用头插法 插入链表 针对以下代码分析源码 123HashMap&lt;Object, String&gt; hashMap = new HashMap&lt;&gt;(11);hashMap.put(&quot;2021&quot;, &quot;colin&quot;); new HashMap&lt;&gt;(11)时 构造函数如下： 1234567891011121314151617public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap(int initialCapacity, float loadFactor) &#123; // 此处initialCapacity= 11 ,loadFactor = DEFAULT_LOAD_FACTOR = 0.75f if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) // 如果初始值大小大于最大容量，将他赋值为最大值 initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; // 加载因子赋值 threshold = initialCapacity; // threshold = 11 init(); // 空方法，什么都没有，java.util.LinkedHashMap对此方法进行了重写&#125; hashMap.put方法 123456789101112131415161718192021public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; // 如果数组为空，则进行初始化 inflateTable(threshold); // threshold = 11（构造函数里赋值） &#125; if (key == null) return putForNullKey(value); int hash = hash(key); // 计算hash值 int i = indexFor(hash, table.length); // 计算索引 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; // 遍历数组索引处所在的链表 Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; // 如果当前节点的key等于put的key,将其替换 V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); // 加入节点 return null;&#125; 1.1 inflateTable(threshold) 初始化数组 方法 1234567private void inflateTable(int toSize) &#123; // toSize = 11 int capacity = roundUpToPowerOf2(toSize); // 计算出toSize的最小2次幂(即&gt;=size，并且使2的指数倍)。计算出来的就是hashMap数组的容量 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // threshold阈值 = 当前容量 * 加载因子 / MAXIMUM_CAPACITY + 1 取最小的 table = new Entry[capacity]; // initHashSeedAsNeeded(capacity);&#125; 1.1.1 roundUpToPowerOf2方法 123456789private static int roundUpToPowerOf2(int number) &#123; // number == 11 return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1;&#125; 1.1.1.1 highestOneBit方法 12345678public static int highestOneBit(int i) &#123; // i = 11 &lt;&lt; 1 = 26i |= (i &gt;&gt; 1);i |= (i &gt;&gt; 2);i |= (i &gt;&gt; 4);i |= (i &gt;&gt; 8);i |= (i &gt;&gt; 16); // 以上操作都是把二进制的低位变成1return i - (i &gt;&gt;&gt; 1);&#125; i |= (i &gt;&gt; 1) i = 0001 1010 向右移1位 变成 0000 1101，然后二者进行或运算 0001 1010 或运算 ——&gt; 0001 1111 0000 1101 后面的同理，目的是把低位全变成1，最后的 i就等于 0001 1111，即31 然后 return i - (i &gt;&gt;&gt; 1) i &gt;&gt;&gt; 1 , 无符号右移1位，忽略符号位，空位都以0补齐。变成 0000 1111，即等于7，最后return 31 -15 = 16 1.2 indexFor 计算索引 12345static int indexFor(int h, int length) &#123; // hash, table.lengthreturn h &amp; (length-1);&#125; 为什么要length -1，因为table.length是2的指数次幂，所以length的二进制只会是2的整数倍，如0000 1000，0010 0000 这样子的 而hash值是随机的，所以，如果不减1，那么进行与运算的结果就只有两种，一个就是lenth本身，一个是0；那么元素放置在数组的位置就只有两个了，还会越界 length 减去1，那么length低位全变成1，与hash进行与运算得到的结果只会是0-length-1范围里面 1.3 addEntry节点 123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; // hash - 计算出来的hash值 bucketIndex -- 计算出来的索引 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; // 如果当前大小 大于等于 阈值 并且 当前数组索引处不为空，则进行扩容 resize(2 * table.length); // 扩容为当前数组长度的两倍，因为长度需要是2的指数次幂 hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 1.3.1 resize扩容方式 12345678910111213void resize(int newCapacity) &#123; // newCapacity = 2 * table.length Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); // 将旧数据转移到新hashTable table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 1.3.1.1 transfer——转移数据 多线程情况下会产生环形链表，死锁 https://www.processon.com/diagraming/5eda27f7e0b34d4139010c23 123456789101112131415161718192021void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123;// 外层循环是数组 while(null != e) &#123; // 内层循环的是数组节点的上链表 Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); // 重新计算hash e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 为什么加载因子loadfactor是0.75？ HashMap类上面的源码注释已经给出了答案； 一般来说，默认负载系数（0.75）在时间和空间成本之间 提供了一个很好的折中方案。较高的值会减少空间开销，但会增加查找成本，反映在HashMap类，包括get和put。这个应采用映射中的预期条目数及其加载系数 在设置其初始容量时应予以考虑，以尽量减少再灰化操作的数量。如果初始容量更大大于最大条目数除以负载系数，再灰化作业将永远不会发生。 基于牛顿二项式，算出来折中考虑 HashMap8的扩容方法，完全绕开了rehash重新计算hash的方法，采用高低位指针 JDK8中的HashMap12345// 无参构造，只是赋予了默认了加载因子0.75fpublic HashMap() &#123;this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;//hash（）计算hash值static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // 刚开始put时，成员属性table为null n = (tab = resize()).length; // resize()方法初始化hashMap， n = 16 if ((p = tab[i = (n - 1) &amp; hash]) == null) // i = (n - 1) &amp; hash 计算索引，n=table.length，长度-1跟jdk7一样保证索引落在0-15以内 tab[i] = newNode(hash, key, value, null); // new 一个 Node节点，并放在数组索引处 else &#123; // 如果索引处已经有元素了，添加到链表上 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 如果key相等。p为数组索引处第一个节点 e = p; else if (p instanceof TreeNode) // TreeNode是Node的子类 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 如果p下一个节点为null (p为数组索引处第一个节点) p.next = newNode(hash, key, value, null); // 【尾插法】插入链表 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // TREEIFY_THRESHOLD = 8. 如果长度大于8 treeifyBin(tab, hash); // 转红黑树或者扩容 break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 如果key相同，break break; p = e; &#125; &#125; if (e != null) &#123; // 将旧值替换并返回 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; resize()初始化，下面只贴出初始化会走的逻辑 123456789101112131415161718192021222324final Node&lt;K, V&gt;[] resize() &#123; Node&lt;K, V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; // oldCap = 0 int oldThr = threshold; // oldThr = 0 int newCap, newThr = 0; if (oldCap &gt; 0) &#123; ....// 初始化不会走这里 &#125; else if (oldThr &gt; 0) // false newCap = oldThr; else &#123; newCap = DEFAULT_INITIAL_CAPACITY; // 默认初始容量16 newThr = (int) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); // 默认加载因子0.75 * 16 = 12 &#125; if (newThr == 0) &#123; // false ... &#125; threshold = newThr; // threshold = 12 Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) new Node[newCap]; // new Node[16] table = newTab; if (oldTab != null) &#123; // false ... &#125; return newTab; // 返回初始化的数组&#125; treeifyBin()方法 1234567891011121314151617181920final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 如果table.length &lt; MIN_TREEIFY_CAPACITY = 64,则进行扩容 resize(); // 扩容方法（也就是初始化时调的方法）我们下面回过头看扩容的逻辑 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; // 否则将链表转为红黑树 TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; resize()扩容 123456789101112131415161718192021222324252627282930313233343536373839404142if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125;&#125; CountcurrentHashMap 数据结构 ConcurrentHashMap的数据结构与HashMap基本类似，区别在于： 1、内部在数据写入时加入了同步机制（分段锁）保证线程安全，读操作是无锁操作； 2、扩容时老数据的转移是并发执行的，这样扩容的效率更高。 并发安全控制 Java7ConcurrentHashMap基于ReentrantLock实现分段锁 Java8中ConcurrentHashMap基于分段锁+CAS保证线程安全，分段锁基于synchronized关键字实现 源码分析 重要成员变量 LOAD_FACTOR：负载因子，默认0.75，当table使用率达到75%时，为了减少table的hash碰撞，table长度将扩容一倍。 TREEIFY_THRESHOLD: 默认为8，当链表长度大于8时，将链表转变成红黑树 UNTREEIFY_THRESHOLD：默认为6，红黑树转变为链表的阈值 MIN_TRANSFER_STRIDE：默认为16，table扩容时，每个线程最少迁移table的槽位个数 MOVED：值为-1，当Node.hash为MOVED时，代表着table正在扩容 THEEBINl：值为-2,代表此元素后接红黑树 nextTable：table迁移过程临时变量，在迁移过程中将元素全部迁移到nextTable上。 sizeCtl：用来标志table初始化和扩容的，不同的取值代表着不同的含义 0：table还没有初始化 -1：table正在初始化 小于-1：实际值为 resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT + 2，表明table正在扩容 大于0：初始化完成后，代表table最大存放元素的个数，默认为0.75*n （代码中写法为：sc = n - (n &gt;&gt;&gt; 2);sizeCtl = sc） transferIndex：table容量从n扩到2n时，是从索引n-1的元素开始迁移，transferIndex代表当前已经迁移的元素下标 ForwardingNode：一个特殊的Node节点，其hashCode=MOVED，代表着此时table正在做扩容操作。扩容期间，若table某个元素为null，那么该元素设置为ForwardingNode，当下个线程向这个元素插入数据时，检查hashcode=MOVED，就会帮着扩容 ConcurrentHashMap由三部分构成，table+链表+红黑树，其中table是一个数组，既然是数组，必须要在使用时确定数组的大小，当table存放的元素过多时，就需要扩容，以减少碰撞发生次数 源码分析 无参构造 12public ConcurrentHashMap() &#123;&#125; 有参构造 12345678public ConcurrentHashMap(int initialCapacity) &#123;if (initialCapacity &lt; 0)throw new IllegalArgumentException();int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ?MAXIMUM_CAPACITY :tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1));this.sizeCtl = cap;&#125; put方法 12345public V put(K key, V value) &#123;return putVal(key, value, false);&#125; putVal方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); // 计算hash值 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; // 循环时为了考虑并发情况，如：多个线程去初始化时只能有一个初始化 Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); // 初始化 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) // 如果此时正在扩容。ps:扩容的时候会将链表首节点包装成ForwardingNode，并用nextTable指向原table tab = helpTransfer(tab, f); // 帮忙迁移扩容 else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; initTable初始化方法 12345678910111213141516171819202122private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; // cas去修改sizeCtl的值为-1，多个线程去修改的话，会出现失败情况，失败的继续走循环 try &#123; if ((tab = table) == null || tab.length == 0) &#123; // 为什么还要判断一次？因为失败的第二次循环去修改时，也会可能成功 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; // SC在有参构造时会赋值，不然默认为0；DEFAULT_CAPACITY = 16 @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); // 即0.75*n， 代表table最大存放元素的个数， &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; helpTransfer帮助扩容方法 123456789101112131415161718192021final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); // 根据length得到一个标识符号 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; // 说明还在扩容 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || // 达到最大的帮助线程 || 判断扩容转移下标是否在调整（扩容结束） sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; // cas修改sizectl + 1, 表示增加了一个线程帮助其扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125; transfer扩容 123456789101112131415161718private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range 每个线程最小迁移16个槽位 if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; ......&#125; CopyOnWriteArrayListCopyOnWrite机制 核心思想：读写分离，空间换时间，避免为保证并发安全而导致的激烈的锁竞争 CopyOnWrite适用于读多写少的情况，最大程度的提高读的效率 CopyOnWrite是最终一致性，在写的过程中，原有读的数据是不会发生更新的，只有新的读才能读到最新数据 如何使其他线程能过够及时读到新的数据，需要使用volatile修饰 写的时候不能并发写，需要对写操作进行加锁 源码分析 add（）方法，写时复制 1234567891011121314public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); // 复制一个array副本,并且长度为原先的加1 newElements[len] = e; // 往副本里写入新元素 setArray(newElements); // 副本替换原本，成为新的原本 return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 读API 123public E get(int index) &#123;return get(getArray(), index); // 无锁&#125; 123456789public class CopyOnWriteArrayList&lt;E&gt;implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123;......private transient volatile Object[] array;final Object[] getArray() &#123;return array;&#125;&#125; Executor线程池原理线程是调度CPU资源的最小单位，线程模型分为KLT模型与ULT模型，JVM使用的KLT模型，Java线程与OS线程保持1：1的映射关系，也就是说有一个Java线程也会在操作系统里有一个对应的线程，Java线程有多种生命状态，被定义在java.lang.Thread.State NEW：新建 RUNNABLE：运行 BLOCKED：阻塞 WAITING：等待 TIMED_WAITING：超时等待 TERMINATED：终结 协程 协程（纤程，用户级线程），目的是为了追求最大力度的发挥硬件性能和提升软件的速度，协程基本原理是：在某个点挂起当前的任务，并且保存栈信息，去执行另一个任务；等完成或达到某个条件时，再还原原来的栈信息并继续执行（整个过程线程不需要上下文切换） Java原生不支持协程，在纯java代码里需要使用协程的话需要引入第三方包，如：quasar 线程池 线程是稀缺资源，如果被无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，因此Java中提供线程池对线程进行统一分配、调优和监控线程池 在web开发中，服务器需要接收并处理请求，所以会为一个请求来分配一个线程来进行处理。如果每次请求都创建一个线程的话实现起来非常简便，但是存在一个问题，如果并发请求数量非常多，但每个线程执行的时间很短，这样就会频繁的创建和销毁线程，如此一来会大大降低系统的效率。可能出现服务器在为每个请求创建新线程和销毁线程上花费的时间和消耗的资源要比处理实际的用户的时间和资源更多 线程池的目的就是执行完一个任务，线程并不被销毁，而是可以继续执行其他的任务。 什么时候使用线程池? 单个任务处理时间比较长 需要处理的任务数量很大 Executor框架Executor接口是线程池框架中最基础的部分，定义了一个用于执行Runnable的execute方法 Executor有一个重要子接口ExecutorService，其中定义了线程池的具体行为 1、execute（Runnable command）：履行Runnable类型的任务 2、submit（task）：可以来提交Callable或Runnable任务，并返回代表此任务的Future对象 3、shutdown（）：在完成已提交的任务后封闭办事，不再接管新任务 4、shutdownNow（）：停止所有正在履行的任务并封闭办事 5、isTerminated（）：测试是否所有任务都履行完毕了 6、isShutdown（）：测试是否该ExecutorService已被关闭 线程池的五种状态 private static final int COUNT_BITS = Integer.SIZE - 3; // 29 private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // 1 &lt;&lt; 29 - 1 = 2 ^ 29 - 1 即 0000 1111 … 1111 // 位图，高三位记录线程池状态，后29位记录线程数量 private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 101 0 0000 …. 0000 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 000 0 0000 …. 0000 private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 001 0 0000 …. 0000 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 010 0 0000 …. 0000 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // 011 0 0000 …. 0000 RUNNING 状态说明：线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务处理 状态切换：线程池的初始化状态是RUNNING。换句话说，线程池一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0； SHUTDOWN 状态说明：线程池处在SHUTDOWN状态时，不接受新任务，但能处理已添加的任务。 状态切换：调用线程池的shutdown（）接口时，线程池由RUNNING ——&gt; SHUTDOWN STOP 状态说明：线程池处在STOP状态时，不接受新任务，不处理已添加的任务，并且会中断正在处理的任务 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN) ——&gt; STOP TIDYING tidying 英 [ˈtaɪdiɪŋ] 美 [ˈtaɪdiɪŋ] v.使整洁;使整齐 ;使有条理;整理 状态说明：当所有的任务已终止，ctl记录的“任务数量”为0，线程池会变为tidying状态。当线程池变为tidying状态时，会执行钩子函数terminated()。 terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由SHUTDOWN ——&gt; TIDYING。当线程池在STOP状态下，线程池中执行任务为空时，就会由STOP ——&gt; TIDYING TERMINATED 状态说明：线程池彻底终止，就变成TERMINATED状态 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由TIDYING ——&gt; TERMINATED 进入TERMINATED的条件如下： 线程池不是RUNNING状态 线程池状态不是TIDYING状态或TERMINATED 如果线程池状态是SHUTDOWN并且workerQuere为空 workerCount为0 设置TIDYING状态成功 构造函数（全参），入参如下 1234567891011int maximumPoolSize, // 最大线程数long keepAliveTime, // 最大允许线程不干活的时间TimeUnit unit, // 时间单位BlockingQueue&lt;Runnable&gt; workQueue, // 存放未来得及执行的任务ThreadFactory threadFactory, // 创建线程的工厂RejectedExecutionHandler handler // 拒绝策略 corePoolSize 线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；继续提交的任务将被保存在阻 塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程 maxinumPoolSize 线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maxinumPoolSize keepAliveTime 线程池维护线程所允许的空闲时间，当线程池中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime unit 指定keepAliveTime的时间单位 workQueue 用来保存等待被执行的任务的阻塞队列，且任务必须实现Runable接口，在JDK中提供了如下阻塞队列： 1、ArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务 2、LinkedBlockingQueue：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQueue 3、SychronousQueue：一个不存储元素的阻塞队列，每个插入操作一直处于阻塞队列，吞吐量通常要高于LinkedBlockingQueue 4、priorityBlockingQueue：具有优先级的无界阻塞队列； threadFactory 它是ThreadFactory类型的变量，用来创建新线程。默认使用Executors.defaultThreadFactory()来创建新线程 使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称 handler 线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种拒绝策略 AbortPolicy：默认的策略，直接抛出异常； CallerRunsPolicy：用调用者所在的线程自己来执行任务 DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务 DiscardPolicy：直接丢弃任务； 上面的四种策略都是ThreadPoolExecutor的内部类,也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务","categories":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/categories/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/tags/JUC/"},{"name":"多线程","slug":"多线程","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"volatile关键字","slug":"volatile关键字","date":"2022-12-04T14:30:07.000Z","updated":"2022-12-04T15:52:29.612Z","comments":true,"path":"2022/12/04/volatile关键字/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/12/04/volatile%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"​ volatile比synchroized的执行成本更低，因为他不会引起线程上下文的切换和调度。 ​ 在对volatile变量进行写操作时，JIT编译器生成的汇编指令处，会有一个lock指令。Lock前缀的指令在多核处理器下会引发两件事： 将当前处理缓存行的数据写回系统内存 这个写回内存的操作会使其他CPU里缓存了该内存地址的数据无效 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1、L2或其他）后，再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回内存，其他处理器缓存的值还是旧值，就会有问题。所以，在多处理器下，为了保证各个处理器的缓存时一致的，就会实现缓存一致性协议，每个处理通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 LOCK前缀指令会引起处理器缓存回写主存：LOCK前缀指令会确保当前处理器可以独占共享内存（会锁住总线，导致其他cpu不能访问总线，不能访问总线就意味着不能访问系统内存）。但是，在最近的处理器里，一般不锁总线，锁总线开销大，而是锁缓存行。 一个处理器的缓存回写到内存会导致其他处理器的缓存无效：处理器会使用MESI控制协议去维护内存缓存和其他处理器缓存的一致性。通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充","categories":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/categories/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/tags/JUC/"},{"name":"多线程","slug":"多线程","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"mysql查看事务加锁情况","slug":"mysql查看事务加锁情况","date":"2022-11-30T14:28:17.000Z","updated":"2022-11-30T15:34:33.540Z","comments":true,"path":"2022/11/30/mysql查看事务加锁情况/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/30/mysql%E6%9F%A5%E7%9C%8B%E4%BA%8B%E5%8A%A1%E5%8A%A0%E9%94%81%E6%83%85%E5%86%B5/","excerpt":"","text":"在information_schema数据库中，有几个与事务和锁紧密相关的表。 INNODB_TRX该表存储了InnoDB存储引擎当前正在执行的事务信息，包括事务id（如果没有为该事务分配唯一的事务id，则会输出该事务对应的内存结构的指针）、事务状态（事务是正在运行还是等待获取某个锁、事务正在执行的语句等）。 例如： 在一个会话中，开启事务T1 12BEGIN;SELECT * FROM single_table WHERE id = 20 FOR UPDATE; 然后在另一个会话中查询INNODB_TRX表 1SELECT * FROM information_schema.INNODB_TRX; trx_id：事务id trx_state：事务状态 trx_tables_locked：表示当前事务目前加了多少个表级锁； trx_rows_locked：表示该事务目前加了多少个行级锁（不包括隐式锁）； trx_lock_structs：表示当前该事务生成了多少个内存中的锁结构； INNODB_LOCKS 该表记录一些锁信息，主要包括以下两个方面。 如果一个事务想要获取某个锁但未获取到，则记录该锁信息 如果一个事务获取到了某个锁，但是这个锁阻塞了别的事务，则记录该锁信息 tips：只有当系统中发生了某个事务因为获取不到锁而被阻塞的情况时，该表中才会有记录 例如： 会话1，开启事务T1 12BEGIN;SELECT * FROM single_table WHERE id = 20 FOR UPDATE; 会话2，开启事务T2 1SELECT * FROM single_table WHERE id = 20 FOR UPDATE; 此时查询INNODB_LOCKS表 1SELECT * FROM information_schema.INNODB_LOCKS; 可以看到trx_id为44849和44848的两个事务被显现出来。但是无法凭借上述内容区分到底谁占用了其他事务需要的锁。 我们可以通过INNODB_LOCK_WAITS表来查看更多信息 INNODB_LOCK_WAITS该表中，表明了每个阻塞的事务是一位内获取不到哪个事务持有的锁而阻塞。接着上面的例子，查询一下该表 1SELECT * FROM information_schema.INNODB_LOCK_WAITS; 其中，requesting_trx_id表示因为获取不到锁而被阻塞的事务id; blocking_trx_id表示因为获取到别的事务的锁而导致其被阻塞的事务的事务id; tips：INNODB_LOCKS和INNODB_LOCK_WAITS这两个表在mysql5.7中被标记为过时，在mysql8.0中被移除 使用SHOW ENGINE INNODB STATUS获取锁信息 12set global innodb_status_output_locks=on; -- 可以查看到更完整的信息SHOW ENGINE INNODB STATUS; 执行该语句，得到以下内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374=====================================2022-11-30 23:02:49 0x5484 INNODB MONITOR OUTPUT=====================================Per second averages calculated from the last 60 seconds-----------------BACKGROUND THREAD-----------------srv_master_thread loops: 295 srv_active, 0 srv_shutdown, 465878 srv_idlesrv_master_thread log flush and writes: 466173----------SEMAPHORES----------OS WAIT ARRAY INFO: reservation count 172OS WAIT ARRAY INFO: signal count 167RW-shared spins 0, rounds 310, OS waits 156RW-excl spins 0, rounds 397, OS waits 1RW-sx spins 0, rounds 0, OS waits 0Spin rounds per wait: 310.00 RW-shared, 397.00 RW-excl, 0.00 RW-sx------------TRANSACTIONS------------# 下一个待分配的事务id信息Trx id counter 44852 # 一些关于purge的信息Purge done for trx&#x27;s n:o &lt; 44848 undo n:o &lt; 0 state: running but idle# 每个回滚段中都有一个history链表，这些链表的总长度History list length 38# 各个事务的具体信息LIST OF TRANSACTIONS FOR EACH SESSION:---TRANSACTION 284597729996288, not started0 lock struct(s), heap size 1136, 0 row lock(s)---TRANSACTION 284597729997160, not started0 lock struct(s), heap size 1136, 0 row lock(s)# 事务id 44851的具体信息，活跃11秒---TRANSACTION 44851, ACTIVE 11 sec starting index readmysql tables in use 1, locked 1# 该事务由2个锁结构，1个行锁LOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s)MySQL thread id 59, OS thread handle 52760, query id 63263 localhost ::1 root statistics# 该事务对某个库下的某个表加了IX独占意向锁TABLE LOCK table `tmp`.`single_table` trx id 44855 lock mode IXSELECT * FROM single_table WHERE id = 20 FOR UPDATE------- TRX HAS BEEN WAITING 11 SEC FOR THIS LOCK TO BE GRANTED:# 以下表示一个表结构，Space id 为290，page no 为9， n_bits属性为264 index对应的索引是primary， 锁结构中存放的所类型是X行记录锁# lock_mode X locks rec but not gap 行记录锁# lock_mode X locks gap before rec X型gap锁# lock_mode X X型next-key锁RECORD LOCKS space id 290 page no 8 n bits 264 index PRIMARY of table `tmp`.`single_table` trx id 44851 lock_mode X locks rec but not gap waiting# 记录锁Record lock, heap no 21 PHYSICAL RECORD: n_fields 10; compact format; info bits 0# hex 80000014； 主键值，20(16进制) 0: len 4; hex 80000014; asc ;; 1: len 6; hex 000000005ff4; asc _ ;; 2: len 7; hex eb000001a80110; asc ;; 3: len 5; hex 3164316136; asc 1d1a6;; 4: len 4; hex 80000014; asc ;; 5: len 5; hex 6338323337; asc c8237;; 6: len 8; hex 3664376636366161; asc 6d7f66aa;; 7: len 8; hex 6634613534376666; asc f4a547ff;; 8: len 8; hex 3566306137646365; asc 5f0a7dce;; 9: len 10; hex 33616634373037666566; asc 3af4707fef;;---------------------TRANSACTION 44848, ACTIVE 2220 sec2 lock struct(s), heap size 1136, 1 row lock(s)MySQL thread id 56, OS thread handle 21628, query id 63220 localhost ::1 root--------FILE I/O--------.....省略.....END OF INNODB MONITOR OUTPUT============================ SHOW ENGINE INNODB STATUS;还可以用来查看死锁 LATEST DETECTED DEADLOCK 开始的内容，即表示最近一次发生的死锁信息； 注意的是，此语句默认只会显示最近一次发生的死锁信息，可以将全局系统变量innodb_print_all_deadlocks设置为ON，这样可以将每个死锁发生时的信息都记录在Mysql的错误日志中了。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"explain详解","slug":"explain详解","date":"2022-11-15T14:35:26.000Z","updated":"2023-02-19T14:59:28.146Z","comments":true,"path":"2022/11/15/explain详解/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/15/explain%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"table该条记录代表该表的表名 id 查询语句中每出现一个select关键字，mysql就会为它分配一个唯一的id; 1select * from single_table INNER JOIN single_table2 在连接查询的执行计划中，每个表都会对应一条记录，这些记录的id值时相同的：出现在前面的表表示驱动表，出现在后面的表表示被驱动表。 对于union子句来说，会有点不同；如下 union：会把多个查询的结果集合并起来并对结果集中的记录去重。会使用临时表 所以表名是 &lt;union1,2&gt; ，即在内部创建了一个名为 &lt;union1,2&gt;的临时表；id为null表明这个临时表是为了合并两个查询的结果集而创建的。 select_type simple 查询语句中不包含UNION或者子查询的查询都算作SIMPLE类型。 primary 对于包含UNION、UNION ALL或者子查询的大查询来说，它是由几个小查询组成的：其中最左边的那个查询的select_type值就是primary; union 对于包含UNION或者UNION ALL的大查询来说，它是由几个小查询组成的：其中除了最左边的那个小查询以外，其余小查询的select_type值就是UNION。 union result Mysql选择使用临时表的来完成UNION查询的去重工作，针对该临时表的查询就是UNION RESULT subquery 如果包含子查询的查询语句不能够被转换为对应的半连接形式，并且该子查询是不相关子查询，而且查询优化器决定采用将该子查询物化的方案来执行子查询时，该子查询的第一个select 关键字代表的那个查询的select type就是subquery 由于select type为subquery的子查询会被物化，所以该子查询只会被查询一次 dependent subquery 如果包含子查询的查询语句不能够被转换为对应的半连接形式，并且该子查询被查询优化器转换为相应相关子查询的形式，则该子查询的第一个select关键字代表的那个查询的select_type就是dependent subquery。 select type为dependent subquery的子查询可能会被执行多次 dependent union 在包含union或者union all的大查询中，如果各个小查询都依赖于外层查询，则除了最左边的那个小查询以外，其余小查询的select_type的值就是dependent union derived 在包含派生表的查询中，如果是以物化派生表的方式执行查询，则派生表对应的子查询就的select_type就是derived; tips：在from后面的子查询称为派生表 1EXPLAIN SELECT * FROM (SELECT key1, count(*) as c FROM s1 GROUP BY key1) AS derived_s1 where c &gt; 1; id为2的记录就是代表子查询的查询方式，select_type为derived，说明该子查询是以物化的方式执行的； id为1的记录的table显示的是&lt;derived2&gt;，表示该查询是针对将派生表物化后的表进行查询的 materialized 当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询。 执行计划的第三条记录的select_type值为materialized，查询优化器是将子查询先转换为物化表。 执行计划的前两条记录的id值都是1，说明这两条记录对应的表进行的是连接查询，第二条记录的table列的值是&lt;subquery2&gt;，说明该表其实就是执行计划中id为2对应的子查询物化之后产生的物化表；然后再将s1和该物化表进行连接查询， type system 当表中只有一条记录并且该表使用的存储引擎（如Myisam、Memory）的统计数据都是精确的，那么对该表的访问方式就是system const 当我们根据主键或者唯一二级索引列与常数进行等值匹配时，对单表的访问方式就是const eq_ref 执行连接查询时， 如果被驱动表是通过主键或者不允许存储null值的唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一不为空索引都是联合索引，则所有的索引列都必须是等值比较），则对该被驱动表的访问方式就是eq_ref ref 当通过普通的二级索引列与常量进行等值匹配的方式来查询某个表时，对该表的访问方法就可能是ref 如果是连接查询，被动表中的某个普通二级索引列与驱动表中的某个列进行等值匹配，那么被驱动表也可能使用ref的访问方式 fulltxt 全文检索 ref_or_null 当对普通二级索引列进行等值匹配，且该索引列的值也可以是null值时 index_merge 一般只会为单个索引生成扫描区间，特殊情况下可以使用索引合并 unique_subquery ​ 类似于两表连接中被驱动表的eq_ref访问方法，unique_subquery是针对在一些包含IN子查询的查询语句中，如果查询优化器决定将IN子查询转换为EXISTS子查询，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的type列的值就是unique_subquery 1EXPLAIN SELECT * FROM s1 WHERE key2 IN (SELECT id FROM s2 where s1.key1 = s2.key1) OR key3 = &#x27;a&#x27;; 会被改写成： 1select * from s1 where exists ( select 1 from s1 , s2 where s1.key2 = s2.id and s1.key1 = s2.key1) or key3 = &#x27;a&#x27; index_subquery 与unique_subquey类似，只不过在访问子查询中的表时使用的是普通索引 range 如果使用索引获取某些范围区间的记录，那么就可能使用到range访问方法，比如下边的这个查询： 1SELECT * FROM s1 WHERE key1 IN (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;); index 当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是index 1SELECT key_part2 FROM s1 WHERE key_part3 = &#x27;a&#x27;; 上述查询中的搜索列表中只有key_part2一个列，而且搜索条件中也只有key_part3一个列，这两个列又恰好包含在idx_key_part这个联合索引中，可是搜索条件key_part3不能直接使用该索引进行ref或者range方式的访问，只能扫描整个idx_key_part索引的记录，所以查询计划的type列的值就是index。 另外，对于Innodb来说，当我们需要执行全表扫描，并且需要对主键排序时，此时的type列也是index all全表扫描 possible_keys 与 keypossible_keys：对某个表执行单表查询可能使用到的索引有哪些 key：表示实际用到的索引有哪些 tips：possible_keys列的值并不是越多越好，可以使用的索引越多，查询优化器在计算查询成本时花费的时间也越长 在使用index访问方式查询某个表时，possible_keys列时空的，而key列展示实际用到的索引 key_len","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"Mysql子查询","slug":"Mysql子查询","date":"2022-11-13T10:07:59.000Z","updated":"2023-08-26T15:20:32.293Z","comments":true,"path":"2022/11/13/Mysql子查询/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/13/Mysql%E5%AD%90%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"子查询的分类按照出现位置区分1、在select子句中 如： 1select (select m1 from t1 limit 1); 2、在From子句中 如： 1select m,n from (select m2 as m , n2 as n from t2 where m &gt; 2 ) as t ; 放在FROM子句后面的子查询被称为派生表 3、在where或on子句的表达式中 如： 1select * from t1 where m1 in ( select m2 from t2 ); 按返回的结果集区分 标量子查询 只返回一个单一列值的子查询 比如： 1select * from t1 where m1 = ( select MIN(m2) from t2); 在select子句中的子查询必须是标量子查询 行子查询 返回一条记录的（一行的）子查询。不过这条记录需要包含多个列（如果只包含一个列，就是标量子查询） 如： 1select * from t1 where (m1 ,n1) = (select m2 ,n2 from t2 limit 1); 列子查询 查询出一个列的数据，不过这一列包含很多（其他行的）数据 如： 1select * from t1 where m1 in (select m2 from t2); 表子查询 即子查询的结果既包含很多条记录，又包含很多个列 如： 1select * from t1 where (m1,n1) in ( select m2 , n2 from t2); 按与外层查询的关系来区分 不相关子查询 子查询可以单独运行出结果，不依赖于外层查询的值 相关子查询 子查询的执行需要依赖于外层查询的值 如： 1select * from t1 where m1 in (select m2 from t2 where n1 = n2); 子查询与布尔表达式 使用=、&gt;、&lt;、&gt;=、&lt;=、&lt;&gt;、!=、&lt;=&gt; 作为布尔表达式的操作符 操作数 【表达式】 （子查询） 这里的操作数可以是某个列名、或者常量等。但是，这里的子查询只能是标量子查询或行子查询（只能有单一的值或者一条记录） 如 12345select * from t1 where m1 &lt; (select MIN(m2) from t2);select * from m1 where (m1, n1) = (select m2, n2 from t2 limit 1); [NOT] IN/ANY/SOME/ALL子查询 子查询的结果集往往有多条，是一个集合 123456789select * from t1 where (m1, n1) in (select m2, n2 from t2);select * from t1 where m1 &gt; ANY(select m2 from t2); // ANY与SOME表达的意思相同select * from t1 where m1 &gt; ALL(select m2 from t2); // 本质上等价于 select * from t1 where m1 &gt; (select MAX(m2) from t2); Tips 对于[NOT] IN/ANY/SOME/ALL子查询来说 子查询中不允许有LIMIT子句 子查询的结果其实是一个集合，集合里的值是否排序一点儿都不重要 - 子查询里的order by 无意义 子查询中的DISTINCT无意义 （子查询建立的临时表会去重） 没有聚合函数以及HAVING子句时，GROUP BY 子句无意义 如：select * from t1 where m1 in (select m2 from t2 group by m2) 子查询的执行过程标量、行子查询的执行过程不相关查询如： 1select * from s1 where key1 = (select common_field from s2 where key3 = &#x27;a&#x27; limit 1); 1、先单独执行子查询 2、然后将子查询得到的结果作为外层查询的参数，再执行外层的 select * from s1 where key1 = xxx 相关查询如： 1select * from s1 where key1 = (select common_field from s2 where s1.key3 = s2.key3 limit 1) 1、先从外层查询获取一条记录。即先从s1表中获取一条记录 2、然后从这条记录中找出子查询涉及的列。即key3 ，然后执行子查询 3、根据子查询的查询结果，来检测是否与外层查询的where条件相符合。如果条件成立符合，加入结果集。反之丢弃 4、跳到步骤1，重复此过程，直到外层查询获取不到记录为止 IN子查询的优化物化表对于不相关子查询，如 1select * from s1 where key1 in (select common_field from s2 where key3 = &#x27;a&#x27;) 如果子查询的结果条数很少，那么按照我们之前的想法，先执行子查询，获取一条记录，然后放到外面的查询执行，判断结果是否满足。这种其实没啥问题 如果子查询的结果条数很多，可能内存都放不下。 于是我们可以这样： 不直接将子查询的结果集当作外层查询的参数，而是将结果集写入一个临时表。写入临时表时，需要注意两点 该临时表的列就是子查询结果集中的列 写入临时表的记录会被去重（临时表也是表，给该表建立唯一索引或者主键即可实现） 一般情况下，子查询的结果集不会太离谱，所以会为它建立基于内存的Memory存储引擎的临时表，而且还会为该表建立哈希索引 （in语句的本值就是判断某一列或多列是否存在于某个集合中，有了哈希索引，这个判断过程非常快） ​ 如果子查询的集合非常大，超过了系统变量tmp_table_size或者max_heap_table_size的值，临时表会转而使用基于磁盘的存储引擎来保存结果集，索引类型也转换为B+数索引。 物化：将子查询结果集中的记录保存到临时表的过程 物化表：存储子查询结果集的临时表称为物化表 物化表转连接 例如： 1select * from s1 where key1 in (select common_field from s2 where key3 = &#x27;a&#x27;); 语义：对于s1表来说，如果能在s2表中找到相匹配的数据，就将其加入到结果集 也就是说，上面的查询相当于表S1与子查询物化之后的表进行内连接(我们用materialized_table表示物化表) 1select s1.* from s1 inner join materialized_table m on key1 = m.common_field 转成内连接后，查询优化器就可以分析成本，抉择驱动表，选择成本最低的执行计划了。 虽然这样转换之后，查询速度有所提升，但是将子查询物化之后在执行查询的操作都会有建立临时表的成本，那么！我们是否可以不进行物化操作，直接将子查询转换成连接呢？ 如： 1select s1.* from s1 inner join s2 on s1.key1 = s2.common_field where s2.key3 = &#x27;a&#x27;; 其实效果是很像的，但是区别在于，我们并不知道子查询的结果有多少条。如果有多条，那查询出来的结果可能会重复加入结果集 我们可以分为三种情况讨论 1、对于s1表中的某条记录来说，s2表中没有任何记录满足s1.key1 = s2.common_field，那么该结果不会加入结果集 2、对于s1表中的某条记录来说，s2表中有且只有一条记录满足s1.key1 = s2.common_field，那么该结果会被加入结果集 3、对于s1表中的某条记录来说，s2表中至少有两条记录满足s1.key1 = s2.common_field，那么该结果会被多次加入最终的结果集 对于s1表中的某条记录来说，我们只关心s2表中是否存在记满足key1 = s2.common_field条件，并不关心具体有多少条记录与之匹配； 因为情况三的存在，包含IN子查询的查询和两表连接查询之间并不等价（子查询物化的临时表，自带去重效果）。于是mysql提出了半连接的概念 半连接(semi-join)：将s1表和s2表进行半连接的意思就是，对于s1表中的某条记录来说，我们只关心在s2表中是否存在与之匹配的记录，而不关心具体有多少条记录匹配，最终的结果集中只保留s1表中的记录。 如何实现半连接?有以下几种方法 半连接Table pullout（子查询中的表上拉）当子查询的查询列表处只有主键或者唯一索引列时，可以直接把子查询中的表上拉到外层查询的from子句中，并把子查询中的搜索条件合并到外层查询的搜索条件中。 如： 1select * from s1 where key2 in (select key2 from s2 where key3 = &#x27;a&#x27;); key2是唯一二级索引列，我们可以直接进行table pullout。上拉后的查询就是下面这样 1select s1.* from s1 inner join s2 on s1.key2 = s2.key2 where s2.key3 = &#x27;a&#x27;; Duplicate Weedout（重复值消除）如： 1select * from s1 where key1 in ( select common_field from s2 where key3 = &#x27;a&#x27; ) 在转换为半连接查询后，s1表中的某条记录可能在s2表中有多条匹配的记录，所以该条记录可能多次被添加到最后的结果集中。 我们可以建立一个临时表，比如这个临时表如下所示： 123CREATE TABLE tmp ( id int primary key ); 这样在执行连接查询的过程中，每当某条s1表中的记录要加入到结果集时，就首先把这条记录的id值加入到这个临时表中。 如果添加成功，则说明之前这条s1表中的记录并没有加入最终的结果集，现在把该记录添加到最终的结果集；如果添加失败，则说明这条s1表中的记录之前已经加入到最终的结果集。这种使用临时表消除半连接结果集中重复值的方式Duplicate Weebout。 LooseScan（松散扫描）1select * from s1 where key3 in ( select key1 from s2 where key1 &gt; &#x27;a&#x27; and key1 &lt; &#x27;d&#x27;); 在子查询中，对于s2表的访问可以使用到key1列的索引，而子查询的查询列表处恰好就是在key1列。 可以将子查询后的s2作为驱动表，然后从查询出来的结果集中，只取键值相同的第一条记录去执行匹配操作 Semi-join Materialization (半连接物化)前文所说的物化表：“先将外层查询的IN子句中的不相关子查询进行物化，然后再与外层查询的表进行连接”本质上也属于半连接的实现方案 FirstMatch(首次匹配)与相关子查询的执行方式是一样的。 先取一条外层查询中的记录，然后到子查询的表中寻找符合匹配条件的记录。如果能找到一条，则将该外层查询的记录放入最终的结果集，并且停止查找更多匹配的记录。如果找不到，则把该外层查询的记录丢弃掉。然后取下一条外层查询中的记录。不断重复此过程，直到外层查询获取不到记录为止。 半连接适用条件并不是所有的IN子查询的查询语句都可以转换为半连接 1、该子查询必须是与IN操作符组成的布尔表达式，并且在外层的where 或者 on 子句中出现 2、外层查询也可以有其他的搜索条件，只不过必须使用AND操作符与IN子查询的搜索条件 3、该子查询必须是一个单一的查询，不能是由UNION连接起来的若干查询 4、该子查询不能包含GROUP BY 、HAVING语句或者聚合函数 不适用于半连接的情况 1、在外层查询的WHERE子句中，存在其他搜索条件使用OR操作符与IN子查询组成的布尔表达式连接起来的情况 2、使用NOT IN 而不是IN 3、位于select子句中的IN子查询 4、子查询包含GROUP BY 、HAVING语句或者聚合函数 5、子查询中包含UNION的情况 但是，mysql仍然可以优化不能转为半连接查询的子查询。 对于不相关的子查询，可以尝试把它们物化之后再参与查询 如： 1select * from s1 where key1 not in (select common_field from s2 where key3 = &#x27;a&#x27;) 先将子查询物化，然后再判断key1是否在物化表中的结果集中。这样可以加快查询的执行速度 注意：这里子查询物化之后，不能转为与外层表连接查询。因为是not in 无论子查询是相关的还是不相关的，都可以把IN子查询尝试转为EXISTS子查询 1outer_expr IN (select inner_expr from ... where subquery_where) 可以被转换为： 1EXISTS （select inner_expr from .... where subquery_where AND outer_expr=inner_expr) 某些情况，不转换的话可能用不到索引。 tips: select null in (null); 转换为exists ——&gt; select exists (select 1 from dual where null = null)。不过幸运的是，在where或者on后面的子句是不区分null和false的 如果IN子查询符合转换半连接的条件，查询优化器会优先把该子查询转换为半连接，然后再考虑上述五种半连接的策略中，选取成本最低的策略来执行子查询 如果IN子查询不符合转换为半连接的条件，那么查询优化器会从下面两种策略中找出一种成本最低的方式来执行子查询。 先将子查询物化，再执行查询 执行IN到EXISTS的转化 [NOT] EXISTS子查询的执行如果[NOT] EXISTS子查询是不相关子查询。可以先执行子查询，得出该子查询的结果是true还是false，然后重写原先的查询语句 如： 1select * from s1 where exists (select 1 from s2 where key1 = &#x27;a&#x27;) or key2 &gt; 100; 因为该子查询是不相关子查询，所以查询优化器会首先执行该子查询。最后查询优化器会重写查询： 1select * from s1 where TRUE|FALSE or key2 &gt; 100 对于相关的[NOT] EXISTS子查询来说，如： 1select * from s1 where exists (select 1 from s2 where s1.common_field = s2.common_field) 那么只能最原始的执行方式来执行。先从外层取一条数据，然后作为内层查询的参数，判断条件是否匹配。 不过我们可以使用索引，加快查询速度。如给s2.common_field加上索引 派生表的优化把子查询放在外层查询的FROM子句后，这个子查询相当于一个派生表。 对于含有派生表的查询，Mysql提供了两种执行策略 把派生表物化 我们可以将派生表的结果集写到一个内部的临时表中，然后把这个物化表当作普通表一样来参与查询。 再对派生表物化时，mysql使用了一种称为延迟物化的策略，也就是查询过程中，真正使用到派生表时，才会去尝试物化派生表，而不是查询之前就先把派生表物化。 1select * from (select * from s1 where key1 = &#x27;a&#x27; ) as drived_s1 inner join s2 on drived_s1.key1 = s2.key1 where s2.key2 = 1; 如果采用物化表的方式执行这个查询，在执行时首先会到s2表中找出满足s2.key2=1的记录，如果压根儿找不到，说明参与连接的s2表记录为空，结果集为空，没必要去物化表了。 将派生表和外层查询合并 即：将查询重写为没有派生表的形式 1select * from (select * from s1 where key1 = &#x27;a&#x27; ) as drived_s1 inner join s2 on drived_s1.key1 = s2.key1 where s2.key2 = 1; 我们可以将派生表与外层查询合并 1select * from s1 inner join s2 on s1.key1 = s2.key1 where s1.key1 = &#x27;a&#x27; where s2.key2 = 1; 这样改写后，成功的消除了派生表，也就意味着我们没必要付出创建和访问临时表的成本了。 并不是所有带有派生表的查询都能成功的与外层查询合并。当派生表中有下面这些函数或语句时，就不可以与外层查询合并 聚合函数，比如MAX()，MIN()，SUM()等 DISTINCT GROUP BY HAVING LIMIT UNION 或者 UNION ALL 派生表对应的子查询的select 子句中含有另一个子查询 …… 所以，mysql在执行带有派生表的查询时，会优先尝试把派生表和外层查询进行合并；如果不行，再采用物化表执行查询","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"查询的成本","slug":"查询的成本","date":"2022-11-07T15:15:38.000Z","updated":"2022-11-30T15:43:24.430Z","comments":true,"path":"2022/11/07/查询的成本/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/07/%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%88%90%E6%9C%AC/","excerpt":"","text":"单表查询的成本概述IO成本：我们的表经常使用的MyISAM、InnoDB存储引擎都是将数据和索引都存储到磁盘上的，当我们想查询表中的记录时，需要先把数据或者索引加载到内存中然后再操作。这个从磁盘到内存这个加载的过程损耗的时间称之为I/O成本。 CPU成本：读取以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称之为CPU成本。 对于InnoDB来说，页是磁盘和内存之间进行交互的基本单位。Mysql规定，读取一个页面花费的成本默认是1.0；读取以及检测一条记录是否符合搜索条件的成本默认是0.2。 tips：在读取记录时，即使不需要检测记录是否符合搜索条件，其成本也算作0.2 准备工作 123456789101112131415CREATE TABLE single_table ( id int NOT NULL auto_increment, key1 VARCHAR ( 100 ), key2 INT, key3 VARCHAR ( 100 ), key_part1 VARCHAR ( 100 ), key_part2 VARCHAR ( 100 ), key_part3 VARCHAR ( 100 ), common_field VARCHAR ( 100 ), PRIMARY KEY ( id ), KEY idx_key1 ( key1 ), UNIQUE KEY uk_key2 ( key2 ), KEY idx_ke3 ( key3 ),KEY idx_key_part ( key_part1, key_part2, key_part3 ) ) ENGINE = INNODB CHARSET = utf8; 存储过程脚本插入1w数据 12345678910111213141516CREATE DEFINER=`root`@`localhost` PROCEDURE `genData`()begin DECLARE n INT DEFAULT 1; WHILE n &lt;= 10000 DO insert into single_table(key1,key2,key3,key_part1,key_part2,key_part3,common_field) values( substring(md5(rand()), 1, 5), n, substring(md5(rand()), 1, 5), substring(md5(rand()), 1, 8), substring(md5(rand()), 1, 8), substring(md5(rand()), 1, 8), substring(md5(rand()), 1, 10)); SET n = n + 1; END WHILE;end 基于成本的优化步骤​ 在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案，这个成本最低的方案就是所谓的执行计划，之后才会调用存储引擎提供的接口真正的执行查询，这个过程总结一下就是这样： 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种执行方案的代价，找出成本最低的那一个 如下面的查询语句： 12345678910SELECT * FROM single_table WHERE key1 IN ( &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27; ) AND key2 &gt; 10 AND key2 &lt; 1000 AND key3 &gt; key2 AND key_part1 LIKE &#x27;%hello%&#x27; AND common_field = &#x27;123&#x27;; 根据搜索条件，找出所有可能使用的索引​ 很显然，上面的查询语句，可能用到的索引有 idx_key1( key1) 、uk_key2(key2) 计算全表扫描的代价​ 全表扫描即：把聚簇索引中的记录都依次与给定的搜索条件进行比较，并把符合条件的记录加入结果集中。所以需要将聚簇索引对应的页面加载到内存中，然后再检测记录是否符合搜索条件。 ​ 由于查询成本 = I/O成本 + CPU成本。所以计算全表扫描的代价需要两个信息： 聚簇索引占用的页面数 该表中的记录数 Mysql为每个表维护了一系列的统计信息。我们可以通过如下sql进行查询 1SHOW TABLE STATUS LIKE &#x27;single_table&#x27; 结果大致如下： 其中： Rows：表示表中记录条数。对于Myisam存储引擎来说，该值是准确的；对于Innodb来说，该值是估计值 Data_length：表示表占用的存储空间字节数。对于Myisam来说，该值就是数据文件的大小；对于Innodb引擎来说，该值就相当于聚簇索引占用的存储空间大小。 对于Innodb的存储引擎来说，Data_length = 聚簇索引的页面数量 * 每个页面大小 由于默认页面大小为16kb，上面查询出来的Data_length = 1589248，所以可以求出聚簇索引的页面数量 ​ 聚簇索引的页面数量 = 1589248 / 16 / 1024 = 97 所以I/O成本 = 97 * 1.0 = 97 （97页，每页成本1.0） CPU成本 = 9317 * 0.2 = 1863.4 （Rows = 9317行，每行检索成本0.2） 总成本 = 97 + 1863.4 = 1960.4 所以对该表的全表扫描成本即为 1960.4 计算使用不同索引执行查询的代价Mysql查询优化器会优先分析使用唯一二级索引的成本，再分析普通索引的成本。所以先分析uk_key2的成本 uk_key2的对应的搜索条件为 key2 &gt; 10 and key2 &lt; 1000，即对应扫描区间为（10，1000） 扫描区间数量 无论某个扫描区间的二级索引到底占用了多少页面，查询优化器粗暴的认为读取索引的一个扫描区间的I/O成本与读取一个页面的I/O成本相同； 此处的扫描区间数量只有一个: （10，1000），所以加载页面的I/O成本为1.0 需要回表的记录数 查询优化器需要先计算二级索引的某个扫描区间到底包含多少记录，对于本例来说，就是计算uk_key2在扫描区间（10，1000）中包含多少二级索引记录。 计算过程如下： 1、先根据key2 &gt; 10条件访问uk_key2对应的B+树索引，找到满足key2 &gt; 10 的第一条记录，称为最左记录。（此过程性能消耗可以忽略不计） 2、然后再根据key2 &lt; 1000条件访问uk_key2对应的B+树索引，找到最后一条满足key2 &lt; 1000的记录，称为最右记录。 3、如果最左记录和最右记录相隔不太远（Mysql5.7.22版本中，只要不大于10个页面即可），就可以精确统计出满足key2 &gt; 10 and key2 &lt; 1000条件的二级索引记录条数 tips：数据页中有个Page Header部分。Page Header中有一个PAGE_N_RECS属性，记录了该页面中目前有多少条记录。所以如果最左记录和最右记录相隔不太远，直接遍历这些页面，拿到这个属性相加即可 如果最左记录和最右记录相隔比较远，则沿着最左记录向右读10个页面，计算每个页面平均包含多少记录，然后用这个平均值乘以最左记录和最右记录之前的页面数量即可。 假设根据上述方法，测得uk_key2再区间（10，1000）中大约有95条记录。读取这95条二级索引记录需要付出的CPU成本为 95 * 0.2 = 19 根据这些记录的主键值到聚簇索引中执行回表操作 Mysql在评估回标操作的I/O成本时，粗暴的认为每次回表操作都相当于访问一个页面； 所以I/O成本就是 95 * 1.0 = 95 回表得到完整记录后，再检测其他搜索条件是否成立 我们通过扫描区间获取到的二级索引记录有95条，对应着聚簇索引中的95条完整用户记录。读取并检测这些完整的用户记录是否符合其余的搜索条件，所以CPU成本为：95 * 0.2 = 19 所以综上所述，使用uk_key2执行查询的总成本为：1.0 + 95 * 0.2 + 95 * 1.0 + 95 * 0.2 = 134 使用普通二级索引执行查询的成本略 基于索引统计数据的成本计算有时候，在使用索引执行查询时，会有很多个单点扫描区间，比如in语句： 1select * from single_table where key1 in (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27; , .... &#x27;zzz&#x27;); 很显然这个查询语句可能使用到的索引就是idx_key1。由于这个索引并不是唯一二级索引，所以并不能确定一个单点扫描区间内对应的二级索引记录的条数有多少（唯一二级索引不重复，所以有多少个in就有多少个等值比较；但普通索引，一个in值里可能包含许多重复的值）。所以我们要去计算一下，计算方式就是先获取索引对应的B+树的区间最左记录和最右记录，然后再计算这两条记录之间有多少记录。 这种通过直接访问索引对应的B+树来计算某个扫面区间内对应的索引记录条数的方式称为**index dive** 如果只是零星几个单点扫描区间的话，使用index dive来计算这些单点扫描区间对应的记录数没什么问题。但是当扫描区间很多时，使用这种方法带来的性能损耗太大了，可能计算这些扫描区间对应的索引记录条数的成本比直接全表扫描的成本都大。 mysql中提供了一个系统变量eq_range_index_limit 1SHOW VARIABLES LIKE &#x27;%dive%&#x27; 也就是说，如果in语句生成的单点扫描区间的数量小于200个，将使用index dive来计算各个单点扫描区间对应的记录条数。 如果大于等于200个，将使用索引统计数据（index statistics）来进行估算。具体如何估算如下： Mysql会为表中每个索引维护一份统计数据。可以通过如下sql查看 1show index from single_table; Non_uniqe：该列所属索引是否是唯一索引。 Seq_in_index：该列在索引包含的列中位置。对于联合索引idx_key_part来说，key_part1的位置是1，key_part2的位置是2 Cardinality：该列中不重复值的数量。（是一个估算值，并不精确）比如对于一个有10000行记录的表来说，如果Cardinality = 10000，表明表中没有重复的值；如果Cardinality = 1，表示该列的值全部都是重复值； 索引统计数据（index statistics) 1、使用show table status语句显示出来的rows值，表示表中有多少记录 2、使用show index from语句显示出来的Cardinality值， 我们可以计算出，某一个列中一个值平均重复多少次。即 rows / Cardinality 假设Rows值为9693，key1列Cardinality值为968，计算出来单个列的平均重复次数为：9693 / 968 ≈ 10条 假设in语句包含着2000个单点扫描区间。每个扫描区间大约对应10条记录。所以总共需要回表的成本就是 2000 * 10 * 1.0 tips：索引统计数据致命弱点是不准确！算出来的查询成本与实际执行时的成本可能相差较大。如果eq_range_index_limit值太小，则很容易采用索引统计数据来计算查询成本，可能导致计算出来的查询成本太大而导致不走索引。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/tags/Mysql/"}]},{"title":"表空间","slug":"表空间","date":"2022-11-05T05:29:02.000Z","updated":"2024-04-13T13:43:33.336Z","comments":true,"path":"2022/11/05/表空间/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/11/05/%E8%A1%A8%E7%A9%BA%E9%97%B4/","excerpt":"","text":"mysql为了更好管理各个页面，对于16KB的页面来说，将连续的64个页称为一个区（extent），也就是默认情况下，一个区占用1MB大小。每256个区又被划分为一组。 为了保证逻辑相邻的两个页在磁盘上也是连续性的。 当表中数据很大时，为索引分配空间的时候，不再按照页为单位分配，而是按照区为单位进行分配 叶子节点和非叶子节点进行分别存储，存放叶子节点的区的集合是一个段，存放非叶子节点的区的集合的是另外一个段。分别称为叶子节点段，非叶子节点段。（一个二级索引会产生两个段） 碎片区：一个索引两个段，一个区占用1MB，如果一上来就以区为单位来分配，对于小表来说太浪费空间。于是就提出了碎片区的概念。碎片区中的页可以作用不同的目的，也就是说可以属于不同的段，甚至可能不属于任何段。碎片区直属于表空间，不属于任何一个段 为某个段分配存储空间的策略： 在刚向表中插入数据时，段是从某个碎片区以单个页面来分配存储空间的 当某个段已经占用了32个碎片区页面之后，就会以完整的区为单位来分配存储空间（原先碎片区中的页面不会复制到新申请的完整的区中）","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/tags/Mysql/"}]},{"title":"Springboot自动装配","slug":"Springboot自动装配","date":"2022-06-18T14:23:15.000Z","updated":"2022-06-19T11:14:26.761Z","comments":true,"path":"2022/06/18/Springboot自动装配/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/06/18/Springboot%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D/","excerpt":"","text":"​ 启动Springboot代码很简单，直接一行代码SpringApplication.run(class,args)搞定，其实这一步可以拆解成两步，SpringApplication.run方法里面，其实也是先new SpringApplication，然后调用它的run方法 12345678@SpringBootApplicationpublic class TestApplication &#123; public static void main(String[] args) &#123; // SpringApplication.run(TestApplication.class,args); SpringApplication springApplication = new SpringApplication(TestApplication.class); springApplication.run(args); &#125;&#125; new SpringApplication() 123public SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources);&#125; 1234567891011121314public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); // 1、将启动类存入primarySources中 this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); // 2、根据classpath下的类，推算当前web应用类型（webFlux,servlet) this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 3、去spring.factoryies中获取所有key为`org.springframework.context.ApplicationContextInitializer`的值 ,设置容器的初始化器 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 4、同3获取所有key为`org.springframework.context.ApplicationListener`的值,设置容器的监听器 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 5、根据调用栈推断出main方法所在类，获取其class对象 this.mainApplicationClass = deduceMainApplicationClass();&#125; setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); 123private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;);&#125; 调用重载方法 1234567private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 先看SpringFactoriesLoader.loadFactoryNames(type, classLoader)这个方法 1234public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; String factoryTypeName = factoryType.getName(); return (List)loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList());&#125; 这里又可以分为两步，先是loadSpringFactories(classLoader) 12345678910111213141516171819202122232425262728293031323334353637// 静态常量cache，用于缓存private static final Map&lt;ClassLoader, MultiValueMap&lt;String, String&gt;&gt; cache = new ConcurrentReferenceHashMap(); private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; // 先从缓存中取 MultiValueMap&lt;String, String&gt; result = cache.get(classLoader); if (result != null) &#123; return result; &#125; try &#123; // 获取资源定位 Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(&quot;META-INF/spring.factories&quot;) : ClassLoader.getSystemResources(&quot;META-INF/spring.factories&quot;)); result = new LinkedMultiValueMap&lt;&gt;(); // 遍历元素，添加到集合中 while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryTypeName = ((String) entry.getKey()).trim(); for (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryTypeName, factoryImplementationName.trim()); &#125; &#125; &#125; // 以classloader为key,放入cache cache.put(classLoader, result); return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(&quot;Unable to load factories from location [&quot; + FACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex); &#125; &#125; ​ ​ 就是加载类路径下中所有的spring.factories，把他们放入一个map中，然后getOrDefault(factoryTypeName, Collections.emptyList()); 获取以org.springframework.context.ApplicationContextInitializer为key的所有值.然后放入Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(..）中 ​ 紧接着是这一行 List instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); 12345678910111213141516private &lt;T&gt; List&lt;T&gt; createSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, ClassLoader classLoader, Object[] args, Set&lt;String&gt; names) &#123; List&lt;T&gt; instances = new ArrayList&lt;&gt;(names.size()); for (String name : names) &#123; try &#123; Class&lt;?&gt; instanceClass = ClassUtils.forName(name, classLoader); Constructor&lt;?&gt; constructor = instanceClass.getDeclaredConstructor(parameterTypes); T instance = (T) BeanUtils.instantiateClass(constructor, args); instances.add(instance); &#125; catch (Throwable ex) &#123; throw new IllegalArgumentException(&quot;Cannot instantiate &quot; + type + &quot; : &quot; + name, ex); &#125; &#125; return instances;&#125; 循环遍历刚刚拿到的集合，然后反射去创建实例 applcaiton.run(args)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public ConfigurableApplicationContext run(String... args) &#123; // stopwatch记录开始 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //1、 获取org.springframework.boot.SpringApplicationRunListener监听器 SpringApplicationRunListeners listeners = getRunListeners(args); // 事件ApplicationStartingEvent发布 listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 2、读取配置文件appcaiton.yml... ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); // 打印banner Banner printedBanner = printBanner(environment); // 3、创建spring上下文 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // 4、初始化上下文 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 5、refresh方法 refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; 1、 获取SpringApplicationRunListener监听器与事件发布*123456private SpringApplicationRunListeners getRunListeners(String[] args) &#123; // 有参构造方法所需参数 Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123; SpringApplication.class, String[].class &#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args));&#125; 1.1 getSpringFactoriesInstances getSpringFactoriesInstances就是new SpringApplication()里面所看到的，这次会从缓存cache中直接获取key为org.springframework.boot.SpringApplicationRunListeners所有的值，并反射创建其实例。 1234567private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 默认有一个 org.springframework.boot.context.event.EventPublishingRunListener；在Springboot的官方包里有配置 值得注意的是，在反射创建SpringApplicationRunListeners实例时，会调用其有参构造方法，将application，和args传入 12345678910111213public EventPublishingRunListener(SpringApplication application, String[] args) &#123; this.application = application; this.args = args; // 创建事件多播器 this.initialMulticaster = new SimpleApplicationEventMulticaster(); for (ApplicationListener&lt;?&gt; listener : application.getListeners()) &#123; // 将监听器添加到事件多播器中 this.initialMulticaster.addApplicationListener(listener); &#125;&#125;// 注意此处 application.getListeners()中，其值就是在new Applicaiton()中添加的；代码如下一行所示setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); 1.2 new SpringApplicationRunListeners() 再看看new SpringApplicationRunListeners()；构造器里只是做了赋值；将反射创建的实例EventPublishingRunListener赋值进去 1234SpringApplicationRunListeners(Log log, Collection&lt;? extends SpringApplicationRunListener&gt; listeners) &#123; this.log = log; this.listeners = new ArrayList&lt;&gt;(listeners);&#125; 1.3 listeners.starting() 调用SpringApplicationRunListeners的starting方法,里面就是循环listeners，然后调用其实现的starting()方法；此时此处的listeners里面就一个刚刚反射创建的EventPublishingRunListener。又会去调用它的starting方法 12345void starting() &#123; for (SpringApplicationRunListener listener : this.listeners) &#123; listener.starting(); &#125;&#125; EventPublishingRunListener.starting(); 123456@Overridepublic void starting() &#123; // initialMulticaster多播器里面，装的都是初始化SpringApplicaiton时，从Spring.factories中加载、并反射创建的实例 // 注意此处的是将类型为:ApplicationStartingEvent this.initialMulticaster.multicastEvent(new ApplicationStartingEvent(this.application, this.args));&#125; multicastEvent方法会去调用实现了ApplicationListener&lt;ApplicationStartingEvent&gt;的实现类；(一开始会发布一个ApplicationStartingEvent事件) 12345678910111213141516171819@Overridepublic void multicastEvent(ApplicationEvent event) &#123; multicastEvent(event, resolveDefaultEventType(event));&#125;@Overridepublic void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); Executor executor = getTaskExecutor(); // getApplicationListeners(event, type)获取对应事件类型的listeners for (ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; invokeListener(listener, event); &#125; &#125;&#125; 2、读取配置文件ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); 123456789101112131415private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); ConfigurationPropertySources.attach(environment); // 发布ApplicationEnvironmentPreparedEvent事件 listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment;&#125; springboot里面配置文件的加载，也是通过事件监听器完成的，此处会发布ApplicationEnvironmentPreparedEvent事件，在ConfigFileApplicationListener 类中。会去完成配置文件的加载 public class ConfigFileApplicationListener implements EnvironmentPostProcessor, SmartApplicationListener, Ordered 3、创建上下文context = createApplicationContext(); 1234567891011121314151617181920212223protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: // 根据web类型，如果是SERVLET，创建AnnotationConfigServletWebServerApplicationContext contextClass = Class.forName(&quot;org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext&quot;); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( &quot;Unable create a default ApplicationContext, please specify an ApplicationContextClass&quot;, ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);&#125; AnnotationConfigServletWebServerApplicationContext继承自ServletWebServerApplicationContext 4、初始化上下文 prepareContext(context, environment, listeners, applicationArguments, printedBanner); 123456789101112131415161718192021222324252627282930private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(&quot;springBootBanner&quot;, printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, &quot;Sources must not be empty&quot;); // 读取配置类 load(context, sources.toArray(new Object[0])); // 发布ConfigurableApplicationContext事件 listeners.contextLoaded(context);&#125; 123456789101112131415161718private int load(Class&lt;?&gt; source) &#123; if (isGroovyPresent() &amp;&amp; GroovyBeanDefinitionSource.class.isAssignableFrom(source)) &#123; // Any GroovyLoaders added in beans&#123;&#125; DSL can contribute beans here GroovyBeanDefinitionSource loader = BeanUtils.instantiateClass(source, GroovyBeanDefinitionSource.class); load(loader); &#125; if (isEligible(source)) &#123; this.annotatedReader.register(source); return 1; &#125; return 0;&#125;public void register(Class&lt;?&gt;... componentClasses) &#123; for (Class&lt;?&gt; componentClass : componentClasses) &#123; registerBean(componentClass); &#125;&#125; 5、refresh refreshContext(context); 123protected void refresh(ConfigurableApplicationContext applicationContext) &#123; applicationContext.refresh();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // 解析配置类，@Bean/@Import/@ImportSource/@ComponentScan等;将他们创建成beanDefinition invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // 这里会去创建内嵌tomcat onRefresh(); // Check for listener beans and register them. registerListeners(); // 初始化bean finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(&quot;Exception encountered during context initialization - &quot; + &quot;cancelling refresh attempt: &quot; + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &#x27;active&#x27; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring&#x27;s core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 相关注解@Import通过@Import( {类名.class,类名.classs…} )，直接导入某个类的方式，将类加入到spring的IOC容器中 ImportSelector @Import({类名.class})，其中类实现ImportSelector接口，重写selectImports方法，返回值就是要导入bean的全类名 参数AnnotationMetadata 就是被import注解的类的所有注解信息 1234567891011121314151617181920@Component@Import(User.class)public class Test &#123;&#125;public class User implements ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; Set&lt;String&gt; annotationTypes = annotationMetadata.getAnnotationTypes(); for (String annotationType : annotationTypes) &#123; System.out.println(&quot;---&gt;&quot;+ annotationType); &#125; // 打印内容 // ---&gt;org.springframework.stereotype.Component // ---&gt;org.springframework.context.annotation.Import return new String[]&#123;&quot;com.example.Colin&quot;&#125;; &#125;&#125; ImportBeanDefinitionRegistrar 自定义类实现ImportBeanDefinitionRegistrar接口，重写其registerBeanDefinitions方法；最后通过@Import将这个类导入进来 @EnableAutoConfigurationspringboot启动类上通常会加上@SpringBootApplicaiton注解，而在此注解上又有@EnableAutoConfiguration 1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration 可以看到里面有用到@Import导入了AutoConfigurationImportSelector类，其实现了DeferredImportSelector接口；继承该接口的 ImportSelector会在所有@Configuration配置类处理完后运行 DeferredImportSelector继承了ImportSelector，AutoConfigurationImportSelector重写了selectImports方法 并且！还重写了DeferredImportSelector中的getImportGroup方法.springboot加载的时候会去判断，如果重写了此方法，返回一个class，就会去调用class对饮的process方法，在这个方法里，会去分组，主要为了保证加载的顺序 1234@Overridepublic Class&lt;? extends Group&gt; getImportGroup() &#123; return AutoConfigurationGroup.class;&#125; 12345678910111213@Overridepublic void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) &#123; Assert.state(deferredImportSelector instanceof AutoConfigurationImportSelector, () -&gt; String.format(&quot;Only %s implementations are supported, got %s&quot;, AutoConfigurationImportSelector.class.getSimpleName(), deferredImportSelector.getClass().getName())); AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector) .getAutoConfigurationEntry(annotationMetadata); this.autoConfigurationEntries.add(autoConfigurationEntry); for (String importClassName : autoConfigurationEntry.getConfigurations()) &#123; this.entries.putIfAbsent(importClassName, annotationMetadata); &#125;&#125; 内嵌tomcat导入tomcat依赖，然后可以通过如下代码创建tomcat，并可以添加servlet 1234567891011121314151617181920212223public class TestTomcat &#123; private static final String contextPath = &quot;&quot;; public static void main(String[] args) &#123; Tomcat tomcat = new Tomcat(); tomcat.setPort(8099); String baseDir = Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;).getPath(); try &#123; Context context = tomcat.addContext(contextPath, baseDir); context.addServletContainerInitializer( (c,servletContext) -&gt; &#123; ServletRegistration.Dynamic testServlet = servletContext.addServlet(&quot;testServlet&quot;, new TestServlet()); testServlet.addMapping(&quot;/hello&quot;); &#125;,null); tomcat.start(); &#125; catch (LifecycleException e) &#123; e.printStackTrace(); &#125; tomcat.getServer().await(); &#125;&#125;","categories":[{"name":"springboot","slug":"springboot","permalink":"http://c89757.gitee.io/colinstar/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://c89757.gitee.io/colinstar/tags/springboot/"}]},{"title":"maven打包报错:Malformed \\uxxx encoding","slug":"maven打包报错-Malformed-uxxx-encoding","date":"2022-06-09T14:27:51.000Z","updated":"2023-08-09T15:00:59.662Z","comments":true,"path":"2022/06/09/maven打包报错-Malformed-uxxx-encoding/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/06/09/maven%E6%89%93%E5%8C%85%E6%8A%A5%E9%94%99-Malformed-uxxx-encoding/","excerpt":"","text":"​ 在最近一次项目构建中，执行mvn clean package却报出Malformed \\uxxx encoding的错误。查阅资料后，给出了以下几种解决方式： 删除~/.m2/repository/path-to-the-library的包 将项目中的/更改为\\ 对我来说都不得行，最后查阅到有人说是resolver-status.properties损坏，里面包含了\\u0000， 然后我就根据Maven提示，带上参数 -e - X 执行命令：Maven -e - X clean package，日志打印出是哪个包报错， 最后来到仓库中，删除对应的resolver-status.properties文件，再次构建成功！ 那resolver-status.properties文件是干嘛的呢？ Maven更新本地仓库的步骤是：先更新元文件，再根据元文件去更新本地仓库jar包 而元文件有三个maven-metadata-local.xml，maven-metadata-snapshot-nexus.xml，resolver-status.properties maven-metadata-local.xml 在本地install代码后会生成该文件，记录的是本地项目编译的时间戳 maven-metadata-snapshot-nexus.xml 从远程仓库拉取jar包后，会同时从仓库下载该元文件，该文件记录的是远程仓库上项目最新版本的时间 resolver-status.properties 从远程仓库拉取jar包的时候，也会生成该文件，并且每次拉取都会更新。该文件主要作用是记录maven-metadata–nexus.xml 文件的上次更新时间戳，并结合标签完成更新策略的一部分 更新本地jar包：依赖于 maven-metadata-local.xml 和 maven-metadata-snapshot-nexus.xml 两个文件 如果只有 maven-metadata-local.xml 文件，一般来说是配置有错，或者并没有从远程仓库中拉取过jar包 如果两个文件都有，每次都需要比较一下两个文件的时间戳，即标签上的时间戳。 如果local.xml的时间戳比snapshot.xml的时间戳要新，就不会从远程仓库下载； 如果local.xml的时间戳比snapshot.xml的时间戳要旧，就会去检查一下本地maven仓库的该项目文件夹路径下是否有snapshot.xml对应版本的jar包 如果没有该版本的jar包，就会从远程仓库拉取该版本的jar包 如果有该版本的jar包，就不会做任何行为 更新本地元文件：更新本地仓库jar包决定于本地元文件 maven-metadata-snapshot-nexus.xml，该文件的更新取决于resolver-status.properties文件 先去远程仓库获取maven-metadata-snapshot-nexus.xml文件，远程仓库中不存在此文件，那么会走下载流程 如果存在，读取resolver-status.properties中的lastUpdated参数，然后与当前的时间做比较，根据跟新策略是否需要下载（always/never/daily…) 附上stackOverflow上的回答：https://stackoverflow.com/questions/68003423/java-lang-illegalargumentexception-malformed-uxxxx-encoding-while-mvn-install","categories":[],"tags":[{"name":"maven","slug":"maven","permalink":"http://c89757.gitee.io/colinstar/tags/maven/"},{"name":"questions","slug":"questions","permalink":"http://c89757.gitee.io/colinstar/tags/questions/"}]},{"title":"restTemplate","slug":"restTemplate","date":"2022-06-01T12:26:08.000Z","updated":"2022-06-09T15:25:23.404Z","comments":true,"path":"2022/06/01/restTemplate/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/06/01/restTemplate/","excerpt":"","text":"概述 最近项目有个新需求，需要将原来的接口支持https，虽然之前也有用过restTemplate，但一直未对其进行过深入了解，今天便来看一看 官方文档：https://docs.spring.io/spring-framework/docs/current/reference/html/integration.html#rest-client-accessRestTemplate 有两种方法可以创建restTemplate实例，一种是直接new，另一种是通过构建者构建出来 new 12345678// 直接newRestTemplate restTemplate = new RestTemplate();// 也可以调用有参构造，传入一个ClientHttpRequestFactory的实现类SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory();factory.setConnectTimeout(3000);factory.setReadTimeout(3000);RestTemplate restTemplate = new RestTemplate(factory); build 123456RestTemplate restTemplate = new RestTemplateBuilder() .basicAuthentication(&quot;username&quot;, &quot;password&quot;) .setConnectTimeout(Duration.ofMillis(3000)) .setReadTimeout(Duration.ofMillis(3000)) .rootUri(&quot;http://example/base/&quot;) .build(); 常用API postForEntity 12345String url = &quot;http://www.baidu.com&quot;;HttpHeaders header = new HttpHeaders();header.add(&quot;auth&quot;,&quot;bearer ****&quot;);HttpEntity&lt;UserReqInfo&gt; httpEntity = new HttpEntity&lt;&gt;(new UserReqInfo(),header);ResponseEntity&lt;UserRespInfo&gt; orderResponseEntity = restTemplate.postForEntity(url, httpEntity, UserRespInfo.class); 对于基本类型和实体传参，必须使用MultiValueMap传参 ​ 什么是基本类型和实体传参呢？类似于form表单，如下 12@PostMapping(&quot;/test&quot;)public void test(UserDTO userDTO,Integer requestId)&#123;&#125; 而对于@Requestbody传参，需要使用HttpEntity传参 exhange exchange有以下几种重载方法 url：请求路径 method：请求方法 requestEntity：封装请求头和请求体 responseType：返回数据类型 uriVariables：支持PathVariable类型的数据 示例： 12345678910String url = &quot;http://www.baidu.com&quot;;// 创建http的headerHttpHeaders header = new HttpHeaders();header.add(&quot;auth&quot;,&quot;bearer ****&quot;);header.setContentType(MediaType.APPLICATION_JSON);Gson gson = new Gson();String json = gson.toJson(new UserReqInfo()); // UserReqInfo自定义实体类// 设置请求体和请求头HttpEntity&lt;String&gt; httpEntity = new HttpEntity&lt;&gt;(json,header);ResponseEntity&lt;UserRespInfo&gt; exchange = restTemplate.exchange(url, HttpMethod.POST, httpEntity, UserRespInfo.class); // UserRespInfo自定义实体类 execute restTemplate的所有get,post等等方法，最终都是调用的execute方法。 原理初始化 默认使用HttpUrlConnection，可以通过构造方法传入一个ClientHttpRequestFactory的实现类，以此来替换底层的执行引擎，常见的执行引擎包括HttpClient、Netty、OKHttp。 无参构造 调用RestTemplate无参构造初始化时，会去调用父类InterceptingHttpAccessor的无参构造，其又会去调用顶级父类HttpAccessor的无参构造，虽然无参构造啥也没做，但是可以看到，默认的ClientHttpRequestFactory在类加载时已经初始化为SimpleClientHttpRequestFactory了 有参构造 我们可以先创建一个HttpComponentsClientHttpRequestFactory的实例，该类的执行引擎用的是HttpClient exchange（）方法","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://c89757.gitee.io/colinstar/tags/spring/"}]},{"title":"堆排序","slug":"堆排序","date":"2022-03-24T11:44:57.000Z","updated":"2022-03-25T09:00:20.941Z","comments":true,"path":"2022/03/24/堆排序/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/03/24/%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"​ 堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序，它的最好，最坏，平均时间复杂度均为O（nlogn）,它也是不稳定的排序 堆是具有以下性质的完全二叉树： 每个结点的值都大于或等于其左右孩子节点的值，称为大顶堆 注意：没有要求结点的左孩子的值和右孩子的值的大小关系 每个结点的值都小于或等于其左右孩子的结点，称为小顶堆 大顶堆举例说明: 我们对堆中的结点按照层次进行编号，映射到数组中就是下面这个样子： [ 50 , 45 , 40 , 20 , 25 , 35 , 30 , 10 ,15] 大顶堆特点: arr[ i ] &gt;= arr [ 2 * i + 1 ] &amp;&amp; arr[ i ] &gt;= arr [ 2 * i + 2] // i对应第几个结点，i从0开始编号 小顶堆： 小顶堆：arr [ i ] &lt; = arr [ 2 * i + 1] &amp;&amp; arr [ i ] &lt;= arr [ 2 * i + 2] 一般升序采用大顶堆，降序采用小顶堆 堆排序基本思想： 1、将待排序序列构造成一个大顶堆 2、此时，整个序列的最大值就是顶堆的根节点 3、将其与末尾元素进行交换，此时末尾就为最大值 4、然后将剩余 n - 1个元素重新构造成一个堆，这样会得到 第n 个元素的次小值，如此反复执行，便能得到一个有序序列了 例题：给定一个数组 { 4， 6 ，8 ，5 ，9 }，要求使用堆排序法，将数组升序排序 图解： step1：构造初始堆。将给定无序序列构造成一个大顶堆 （ 一般升序采用大顶堆，降序采用小顶堆） 1、假设给定无序序列结构如下： 2、此时我们从最后一个非叶子结点开始（叶子结点不用调整，最后一个非叶子结点 arr.length / 2 -1 = 5 /2 - 1 = 1 , 也就是下面的6结点），从左至右，从下至上进行调整 arr.length / 2 -1 怎么来的？ 最后一个结点对应的数组下标为 arr.lenth - 1 ; 而 父结点 为 i 的左孩子下标为：2 * i + 1 ; 右结点为 2 * i + 2; 3、找到第二个非叶子节点4，先比较左右两边，9最大，4和9交换 4、这时，交换导致了子根 【 4， 5， 6】结构混乱，继续调整， 【 4，5 ，6 】中 6 最大 ，交换 4 和 6 此时，我们就将一个无序序列构造成了一个大顶堆 Step2：将堆顶元素与末尾元素进行交换，使末尾元素最大。然后继续调整堆，再将堆顶元素与末尾元素交换，得到第二大元素。如此反复进行 堆顶元素 9 和 末尾元素 4 进行交换 交换后重新调整结构，使其满足堆定义 再将堆顶元素8与末尾元素5进行交换，得到第二大元素8 （ 9 已经搞完了，相当于把它剔除了，所以这里末尾元素是5） 后续依次反复进行调整 总结： 将无序序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆 将堆顶元素与末尾元素交换，将最大元素“沉”到数组末端 重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class HeapSort &#123; public static void main(String[] args) &#123; // 将数组升序排列 int array[] = &#123; 4 ,6 ,8 ,5 ,9 &#125;; heapSort(array); System.out.println(Arrays.toString(array)); &#125; /** * 0 1 2 3 4 * [4 ,6 ,8 ,5 ,9 ] * 4 * / \\ * 6 8 * / \\ * 8 9 * @param array */ public static void heapSort(int[] array)&#123; /** * step1 : 构造初始堆。将给定无序序列构造成一个大顶堆 */ // 最后一个非叶子节点 的下标为 array.length / 2 - 1; // 最后第二个非叶子节点 的下标为 最后一个非叶子结点的下标 - 1 for (int i = array.length / 2 - 1; i &gt;= 0 ; i -- ) &#123; adjustBigHeap(array,i, array.length); &#125; /** * step2 : 将堆顶元素与末尾元素进行交换，使末尾元素最大。然后继续调整堆，再将堆顶元素与末尾元素交换，得到第二大元素。如此反复进行 */ int length = array.length; for (int i = 0; i &lt; array.length; i++) &#123; int root = array[0]; // 堆顶元素 // 交换位置 array[0] = array[length - 1]; array[length - 1] = root; length -- ; // 重新调整堆 adjustBigHeap(array,0,length); // 0 ——&gt; 从堆顶开始调整 &#125; &#125; /** * 将一个数组 (把数组当成二叉树的层次排序) 调整成一个大顶堆 * 【以 index 为对应的非叶子节点的树进行调整 成大顶堆】 * @param array 待调整的数组 * @param index 非叶子结点在数组中的索引 * @param length 表示对多少个元素进行调整 * @return */ public static void adjustBigHeap(int[] array,int index, int length)&#123; if (index &lt; 0)&#123; return; &#125; int temp = array[index]; // 先取出当前元素的值,存入临时变量 // 开始调整 // 【 index * 2 + 1 】 左孩子的下标 // 【 i = i * 2 + 1 】 继续往下调整，也就是左孩子的左孩子 for (int i = index * 2 + 1; i &lt; length; i = i * 2 + 1) &#123; if ( i + 1 &lt; length &amp;&amp; array [ i ] &lt; array [ i + 1 ])&#123; // 左子结点 小于 右子结点 i = i + 1; // i 指向右子节点 &#125; if ( array [ i ] &gt; temp)&#123; // 子节点 大于当前节点 // 进行调换 array[ index ] = array[i]; // 把较大得值赋给当前节点 // array[i] = temp; index = i; // index 指向 与之调换的下标 逻辑上交换，物理上不交换 // 继续循环比较 &#125;else &#123; break; &#125; &#125; // for 循环结束后，已经将 以index为顶点 的树调整为大顶堆 array[index] = temp; // 将temp放到调整后的位置 &#125;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://c89757.gitee.io/colinstar/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"堆","slug":"堆","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A0%86/"},{"name":"排序算法","slug":"排序算法","permalink":"http://c89757.gitee.io/colinstar/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"Synchronized详解","slug":"Synchronized详解","date":"2022-01-15T14:11:43.000Z","updated":"2022-03-25T08:58:33.756Z","comments":true,"path":"2022/01/15/Synchronized详解/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/01/15/Synchronized%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"设计同步器的意义 多线程编程中，有可能会出现多个线程同时访问同一个共享，可变资源的情况下，这个资源我们称之为临界资源；这种资源可能是：对象、变量、文件等 ​ 共享：资源可以由多个线程同时访问 ​ 可变：资源可以在其生命周期内被修改 由于线程执行的过程是不可控的，所以需要采用同步机制来协同对对象可变状态的访问 如何解决线程并发安全问题？ 实际上，所有的并发模式在执行线程安全问题时，采用的方案都是序列化访问临界资源。即在同一时刻，只能有一个线程访问临界资源，也称作同步互斥访问 Java中，提供了两种方式来实现同步互斥访问：synchronized和lock同步器的本质就是加锁目的：序列化访问临界资源，即同一时刻只能有一个线程访问临界资源（同步互斥访问） synchronized内置锁是一种对象锁（锁的是对象而非引用），作用粒度是对象，可以用来实现对临界资源的同步互斥访问，是可重入的 Synchronized底层原理​ synchronized是基于JVM内置锁实现，通过内部对象Monitor(监视器锁），基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖底层操作系统的Mutex lock(互斥锁）实现，它是一个重量级锁，性能较低。当然，JVM内置锁在1.5之后版本做了重大的优化，如锁粗化(Lock Coarsening),锁消除（Lock Elimination）,轻量级锁（Lightweight Locking)、偏向锁（Biased Locking)、适应性自旋（Adaptive Spinning)等技术来减少锁操作的开销，内置锁的并发性能已经基本与Lock持平。Synchronized关键字被编译成字节码后会被翻译成 monitorenter 和monitorexit 两条指令分别在同步块逻辑代码的起始位置与结束位置 每个对象都有一个自己的monitor(监视器锁)，加锁过程如下 Monitor监视器锁​ ​ 任何一个对象都有一个Monitor与之关联，当且一个Monitor被持有后，它将处于锁定状态。Synchronized在JVM里的实现都是 基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。 monitorenter：每个对象都是一个监视器锁（Monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下： 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者 如果该线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1 如果其他线程占有该monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权 monitorexit：执行monitorexit的线程必须是object ref对应的monitor的所有者。指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor,步再是这个monitor的所有者，其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权 ​ Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。 123public synchronized void method()&#123; System.out.println(&quot;hello world&quot;);&#125; 经过javap解析后如下 ​ 方法的同步并没有通过指令 monitorenter 和 monitorexit 来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了ACC_SYNCHRONIZED 标示符。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个 monitor对象。 什么是monitor?​ ​ 可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。与一切皆对象一样，所有的java对象是天生的Monitor，每一个Java对象都有称为Monitor的潜质，因为在java的设计中，每一个Java对象自生成就带了把看不见的锁，它叫做内置锁或者Monitor锁；也就是通常说的Synchronized的对象锁，MarkWord锁标识位为10，其中指针指向的是Monitor对象的起始位置；在Java虚拟机（HotSpot）中，Monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） ​ ​ 我们知道synchronized加锁加在对象上，对象是如何记录锁状态的呢？答案是锁状态是被记录在每个对象的对象头（Mark Word）中，下面我们一起认识一下对象的内存布局 对象的内存布局​ ​ HotSpot虚拟机中，对象在内存中存储的布局分为三块区域：对象头（Header)、示例数据（Instance Data）和对齐填充（Padding） 对象头：保存对象的Hash码，GC年龄，对象锁，锁状态标致，偏向锁（线程）ID，偏向时间等，如果是数组对象，还会保存数组的长度。Java对象头一般占有2个机器码（在32位虚拟机中，1个机器码等于4字节，也就是32bit，在64位虚拟机中，1个机器码是8个字节，也就是64bit)；但是如果对象是数组类型，则需要3个机器码，因为JVM虚拟机可以通过Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确定数组的大小，所以用一块来记录数组的长度 实例数据：存放类的属性数据信息，包括父类的属性信息 对齐填充：由于虚拟机要求对象起始地址必须是8字节的整数倍，填充数据不是必须存在的，仅仅是为了字节对齐 ​ HotSpot虚拟机的对象头包括两部分信息，第一部分是”Mark Word”，用于存储对象自身的运行时数据，如哈希码（HashCode），GC分代年龄、锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等等，它是实现轻量级锁和偏向锁的关键。这部分数据的长度在32位和64位的虚拟机（暂不考虑开启压缩指针的场景）中分别位32个和64个Bits，官方称它为“Mark Word”。对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如：在32位的HotSpot虚拟机 中对象未被锁定的状态下，Mark Word的32个Bits空间中的25Bits用于存储对象哈希码（HashCode），4Bits用于存储对象分代年龄，2Bits用于存储锁标志位，1Bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示 32位虚拟机 64位虚拟机 现在的虚拟机基本上是64位的，而64位的对象头有点浪费空间，JVM默认会开启指针压缩，所以基本上也是按32位的形式记录对象头的。 手动设置: -XX:+UseCompressedOops 哪些信息会被压缩？ 1.对象的全局静态变量(即类属性) 2.对象头信息：64位平台下，原生对象头大小为16字节，压缩后为12字节 3.对象的引用类型：64位平台下，引用类型本身大小为8字节，压缩后为4字节 4.对象数组类型：64位平台下，数组类型本身大小为24字节，压缩后16字节 对象头分析工具 OpenJDK开源工具包，JOL，maven坐标如下： 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.10&lt;/version&gt;&lt;/dependency&gt; 案例： 12345public static void main(String[] args) &#123; Object o = new Object(); // 打印markword System.out.println(ClassLayout.parseInstance(o).toPrintable());&#125; 打印出来的对象内存信息如下： 12345678java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1)//Mark Word 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 第一行为Mark Word 00000001 00000000 00000000 00000000 对象此时是无锁状态，前25位表示hashcode值，为什么hashcode是0？ 因为这个hashcode是jvm内置函数，类似于懒加载，此时还没有计算 此时将代码修改为如下： 1234567public static void main(String[] args) &#123; Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); synchronized (o)&#123; System.out.println(ClassLayout.parseInstance(o).toPrintable()); &#125;&#125; 打印的Mark Word为 00011000 11110111 00000010 00000010 即 00000010 00000010 11110111 00011000 发现对象头从无锁——&gt;轻量级锁 为什么不是偏向锁？ ​ 因为JVM会延迟去启动偏向锁，JVM启动时依赖大量的hashMap class对象等，这些对象里面也存在大量的同步块，JVM启动时内部也会去启动十几个线程，这些线程内部也会存在竞争，JVM为了避免造成 偏向锁 到 轻量级锁 到重量级锁 这种锁升级过程，减少锁升级的开销，所以把偏向锁推迟启动了 将代码睡眠几秒钟 12345678public static void main(String[] args) throws InterruptedException &#123; TimeUnit.SECONDS.sleep(10); Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); synchronized (o)&#123; System.out.println(ClassLayout.parseInstance(o).toPrintable()); &#125;&#125; 12345678910111213141516171819java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) a8 f7 06 03 (10101000 11110111 00000110 00000011) (50788264) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 第一次打印的：00000101 00000000 00000000 00000000 就已经是偏向锁状态了，但是偏向锁的前23bit位会记录线程ID，此处并没有，这种 称之为匿名偏向，可偏向状态 如果一直处于偏向状态，无法重偏向的话，那么MarkWord会一直记录最后一个偏向线程的状态 锁的膨胀升级过程​ ​ 锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级到重量级锁，但是锁的升级是单向的，也就是只能从低到高升级，不会出现锁的降级。从JDK1.6中默认是开启偏向锁和轻量级的，可以通过-XX:-UseBiasedLocking来禁用偏向锁 偏向锁：​ 偏向锁是Java6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁（会涉及到一些CAS操作，耗时）的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提高了程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。 默认开启偏向锁 开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0 关闭偏向锁：-XX:-UseBiasedLocking 轻量级锁：​ 倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时，Mark Word的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁 自旋锁： 轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程就可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环（这也是称为自旋的原因），一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。后没办法也就只能升级为重量级锁 锁消除: ​ 消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间。锁消除的依据是逃逸分析的数据支持 锁消除，前提是Java必须运行在server模式，（server模式会比client模式作更多的优化），同时必须开启逃逸分析 -XX:+DoEscapeAnalysis 开启逃逸分析 -XX:+EliminateLocks 表示开启锁消除 使用逃逸分析，编译器可以对代码做如下优化： 同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步 将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配 分离对象或标量替换。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中","categories":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/categories/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/tags/JUC/"},{"name":"多线程","slug":"多线程","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Netty","slug":"Netty","date":"2022-01-06T12:58:22.000Z","updated":"2022-03-25T08:55:54.425Z","comments":true,"path":"2022/01/06/Netty/","link":"","permalink":"http://c89757.gitee.io/colinstar/2022/01/06/Netty/","excerpt":"","text":"BIO&amp;NIO&amp;AIOBIO ​ blocking I/O , 即阻塞IO，同步阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时，服务端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，可以通过线程池机制改善（实现多个客户连接服务器） 先看单线程的版本 12345678910111213141516public static void main(String[] args) throws IOException &#123; final ServerSocket serverSocket = new ServerSocket(9000); while (true)&#123; log.info(&quot;等待连接....&quot;); final Socket socket = serverSocket.accept(); log.info(&quot;建立连接&quot;); InputStream inputStream = socket.getInputStream(); byte[] bytes = new byte[1024]; int read = inputStream.read(bytes); if (read != -1)&#123; log.info(&quot;收到消息：&#123;&#125;&quot;,new String(bytes,0,read)); &#125; socket.getOutputStream().write(&quot;已成功接收到消息&quot;.getBytes()); socket.getOutputStream().flush(); &#125; &#125; Debug启动程序，在serverSocket.accept()处打上断点，同时再下一行处也打上断点，然后我们点击idea调试的Resume Program按钮，让程序直接走完；我们会发现断点没有到达下一行，程序也没有停止，而是阻塞在了accept()里。 我们试着用telnet工具去连接程序 按下回车连接的同时，我们也会发现程序的断点跑到了下一行 我们再在 int read = inputStream.read(bytes);这一行及其下一行也打上断点； 程序来到inputStream.read(bytes)这一行，我们再次选择放掉这一个断点，发现此处程序也并没有来到下一行，也是在此处进行了阻塞 我们用telnet工具给服务端发送消息 回到程序，发现程序执行到了下一行 接下来我们重新开始，重新启动服务端，开启一个telnet（客户端1）去连接，但是不发送消息，让程序阻塞在int read = inputStream.read(bytes)这一行；与此同时，我们再另外开启一个telnet客户端（客户端2）去进行连接，然后发送消息给服务端 但是我们发现，控制台并没有任何消息打印； 我们此时在用客户端1去发送消息 发现客户端打印消息，但是打印hello2之前，输出了”建立连接“；说明此时我们其实客户端2并没有真正的连接上，而是阻塞在了serverSocket.accept()处 12final Socket socket = serverSocket.accept();log.info(&quot;建立连接&quot;); 在同一时刻，服务端只能响应一个客户端 解决方案我们可以在将代码改成多线程版本 12345678910111213141516171819202122232425262728293031323334353637383940414243@Slf4jpublic class TestBIO extends Thread&#123; private Socket socket; public TestBIO(Socket socket) &#123; this.socket = socket; &#125; public static void main(String[] args) throws IOException &#123; final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5, 10, 5000, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5)); log.info(&quot;等待连接....&quot;); final ServerSocket serverSocket = new ServerSocket(9000); while (true)&#123; Socket socket = serverSocket.accept(); log.info(&quot;建立连接&quot;); threadPoolExecutor.execute(new TestBIO(socket)); if (false)&#123; break;&#125; &#125; &#125; public static void handler(Socket socket) throws IOException &#123; InputStream inputStream = socket.getInputStream(); byte[] bytes = new byte[1024]; int read = inputStream.read(bytes); if (read != -1)&#123; log.info(&quot;收到消息：&#123;&#125;&quot;,new String(bytes,0,read)); &#125; socket.getOutputStream().write(&quot;已成功接收到消息&quot;.getBytes()); socket.getOutputStream().flush(); &#125; @Override public void run() &#123; try &#123; handler(this.socket); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 我们再实验以上步骤 先开启telnet客户端1去连接阻塞，但是不发送消息 再开启telnet客户端2去连接，并发送消息 结果此次控制台能正确接收到消息 存在的问题​ 如果开辟大量线程，比较消耗资源，且如果我们用了线程池，如果我们线程池数量是500，某一瞬间并发量有1w，那后面的请求就只能阻塞等待。又或者500线程池，其中400个线程只是和你建立连接，并不立马发送消息给服务端，那这个线程会一直被这个连接给占用，其他人无法获取; 又或者用完线程给别人用时，线程的切换也是比较消耗资源的 IO代码里read操作是阻塞操作，如果连接不做数据读写会导致线程阻塞，浪费资源 如果线程很多，会导致服务器线程太大，压力太大 应用场景：BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高 NIO​ Non Blocking IO,或者读为New IO,同步非阻塞，服务器实现模式为一个线程可以处理多个请求（连接），客户端发送的连接请求都会注册到多路复用器selector上，多路复用器轮询到连接有IO请求就进行处理，JDK1.4开始引入 123456789101112131415161718192021222324252627282930313233343536373839@Slf4jpublic class TestNIO &#123; private static List&lt;SocketChannel&gt; channelList = new ArrayList&lt;&gt;(); public static void main(String[] args) throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(9000)); // 设置ServerSocketChannel为非阻塞 serverSocketChannel.configureBlocking(false); while (true) &#123; // 非阻塞模式accept方法不会阻塞，否则会阻塞 // NIO的非阻塞是由操作系统内部实现的，底层调用了linux内核的accept函数 SocketChannel socketChannel = serverSocketChannel.accept(); if (socketChannel != null) &#123; // 如果有客户端进行连接 log.info(&quot;连接成功&quot;); // 设置SocketChannel为非阻塞 socketChannel.configureBlocking(false); // 保存客户端连接在list中 channelList.add(socketChannel); &#125; // 遍历连接进行数据读取 Iterator&lt;SocketChannel&gt; iterator = channelList.iterator(); while (iterator.hasNext()) &#123; SocketChannel next = iterator.next(); ByteBuffer byteBuffer = ByteBuffer.allocate(128); // 非阻塞模式read方法不会阻塞 int len = next.read(byteBuffer); if (len &gt; 0) &#123; log.info(&quot;接收到消息: &#123;&#125;&quot;, new String(byteBuffer.array())); &#125; else if (len == -1) &#123; // 如果客户端断开，把socket从集合中删调 iterator.remove(); log.info(&quot;与客户端断开连接&quot;); &#125; &#125; &#125; &#125;&#125; 我们先后开启两个telnet客户端去连接服务端，发送消息，服务端都能接收到; 会一直循环去判断是否有新的连接请求，是否有连接发送消息 上述代码存在的问题： 如果连接数太多的话，会有大量的无效遍历 比如如果我现在有10万个连接，但是经常给服务端发消息的就那个几百个，但是每次都要去遍历所有的连接 我们可以将那些有数据交互的连接，存储在另外一个数据结构中，每次遍历只需要遍历那些有数据交互的连接 NIO引入多路复用器代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Slf4jpublic class NioSelectorServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(9000)); // 设置ServerSocketChannel为非阻塞 serverSocketChannel.configureBlocking(false); // 打开selector处理Channel，即创建epoll Selector selector = Selector.open(); // 把ServerSocketChannel注册到selector上，并且selector监听客户端accept连接事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; // 阻塞等待需要处理的事件发生 selector.select(); // 获取selector中注册的全部事件的SelectionKey实例 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); // 遍历SelectionKey对事件进行处理 while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); // 如果是OP_ACCEPT事件，则进行连接获取和事件注册 if (key.isAcceptable())&#123; ServerSocketChannel channel =(ServerSocketChannel) key.channel(); final SocketChannel socketChannel = channel.accept(); socketChannel.configureBlocking(false); // 这里只注册了读事件，如果需要给客户端发送数据可以注册写事件 socketChannel.register(selector,SelectionKey.OP_READ); log.info(&quot;客户端连接成功&quot;); &#125;else if(key.isReadable())&#123; // 如果是OP_READ事件，则进行读取和打印 SocketChannel channel =(SocketChannel)key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int len = channel.read(byteBuffer); if (len &gt;0 )&#123; log.info(&quot;接收到消息:&#123;&#125;&quot;,new String(byteBuffer.array())); &#125;else if(len == -1)&#123; log.info(&quot;客户端断开连接&quot;); channel.close(); &#125; &#125; // 从事件集合里删除本次处理的key,防止下次select重复处理 iterator.remove(); &#125; &#125; &#125;&#125; NIO有三大核心组件：Channel(通道)，Buffer(缓冲区)，Selector(多路复用器) 1、channel类似于流，每个channel对应一个buffer缓冲区，buffer底层就是个数组 2、channel会注册到selector上，由selector根据channel独写事件的发生将其交由某个空闲的线程处理 3、NIO的Buffer和channe都是既可以读也可以写 先看一幅图 ​ 我们代码最开始处，创建了一个ServerSocketChannel，并绑定9000端口,并将ServerSocketChannel注册到selector上，并且selector监听客户端accept连接事件，注册上后会返回一个key,通过这个selectionKey可以找到与之绑定的ServerSocketChannel; ​ 我们在selector.select()处及其下一行打上断点，启动项目。 ​ 放掉断点让其走完，发现程序阻塞在了这一行； ​ 同样的，打开cmd，用telnet连接 1telnet localhost 9000 ​ ​ 连接上后，发现程序走到了下一行 ​ 继续往下走一行，获取到所有的selectionKey; 因为此时我们只有一个客户端进行连接，所以此处size是1 ​ 很显然我们此处是OP_ACCEPT事件 ​ 通过selectionKey可以拿到与之绑定的ServerSocketChannel，并让其与客户端建立连接,并把客户端对应的socketChannel也注册到selector上，并让其监听读事件（读是相当于服务端来的，也就是监听客户端发送过来的消息） ​ 我们一步一步调试，让程序走完，因为是死循环，在select处又会进行阻塞，因为此时既没有新的客户端连接进来，刚刚连接上的客户端也没有发送消息。 ​ 我们用telnet再给服务端发送一条消息 ​ 此时，程序停止了阻塞，走到了下一行 ​ 一步一步调试，很显然这次我们是OP_READ事件，通过key拿到与客户端对应的SocketChannel。也就是下图标识出来的部分，用它来读取客户端的数据 ​ 我们现在再另外开启一个telnet客户端，连接服务端 ​ 我们可以看到，现在有两个客户端，但是拿到的selectionKey只有一个，只针对那些发生的事件进行处理 ​ NIO底层在JDK1.4版本是用linux的内核函数select()或poll()来实现，跟上面最开始的代码类似，selector每次都会轮询所有的socketChannel看下哪个channel有读写事件，有的话就处理，没有就继续遍历，JDK1.5引入了epoll基于事件响应机制来优化NIO 几个核心APISelector.open();1Selector selector = Selector.open(); provider()方法里最终调用了下面的create()方法，发现其new 了一个WindowsSelectorProvider()。因为我们日常使用的是windows的jdk 123public static Selector open() throws IOException &#123; return SelectorProvider.provider().openSelector();&#125; 12345678public class DefaultSelectorProvider &#123; private DefaultSelectorProvider() &#123; &#125; public static SelectorProvider create() &#123; return new WindowsSelectorProvider(); &#125;&#125; 下载openJdk8u的源码，搜索DefaultSelectorProvider这个类，发现有三个，分别对应unix系统，mac系统，windows系统。我们接下来看unix系统对应的源码 unix系统create()方法的源码如下，发现和windows的有区别，如果是linux系统，会返回EPollSelectorProvider这个类 123456789public static SelectorProvider create() &#123; String osname = AccessController .doPrivileged(new GetPropertyAction(&quot;os.name&quot;)); if (osname.equals(&quot;SunOS&quot;)) return createProvider(&quot;sun.nio.ch.DevPollSelectorProvider&quot;); if (osname.equals(&quot;Linux&quot;)) return createProvider(&quot;sun.nio.ch.EPollSelectorProvider&quot;); return new sun.nio.ch.PollSelectorProvider();&#125; open()方法里会调用openSelector()这个方法，EPollSelectorProvider里的实现如下，直接new 了一个EPollSelectorImpl 1234567891011public class EPollSelectorProvider extends SelectorProviderImpl&#123; public AbstractSelector openSelector() throws IOException &#123; return new EPollSelectorImpl(this); &#125; public Channel inheritedChannel() throws IOException &#123; return InheritedChannel.getChannel(); &#125;&#125; 接着我们去看看EpollSelectorImpl这个类的构造函数，初始化的时候， new EPollArrayWrapper()创建了一个EPollArrayWrapper对象 123456789EPollSelectorImpl(SelectorProvider sp) throws IOException &#123; super(sp); long pipeFds = IOUtil.makePipe(false); fd0 = (int) (pipeFds &gt;&gt;&gt; 32); fd1 = (int) pipeFds; pollWrapper = new EPollArrayWrapper(); pollWrapper.initInterrupt(fd0, fd1); fdToKey = new HashMap&lt;&gt;();&#125; 紧接着我们看到EPollArrayWrapper的构造函数，里面调用了一个epollCreate（）方法 12345678910111213EPollArrayWrapper() throws IOException &#123; // creates the epoll file descriptor epfd = epollCreate(); // the epoll_event array passed to epoll_wait int allocationSize = NUM_EPOLLEVENTS * SIZE_EPOLLEVENT; pollArray = new AllocatedNativeObject(allocationSize, true); pollArrayAddress = pollArray.address(); // eventHigh needed when using file descriptors &gt; 64k if (OPEN_MAX &gt; MAX_UPDATE_ARRAY_SIZE) eventsHigh = new HashMap&lt;&gt;();&#125; ​ epollCreate是一个本地方法 （java的native方法是通过JNI，即java native interface来实现的，可以通过它来实现java与其他语言之间的交互） 1private native int epollCreate(); EPollArrayWrapper.c里找到这个epollCreate方法, epoll_create是linux的一个系统函数 12345678910111213JNIEXPORT jint JNICALLJava_sun_nio_ch_EPollArrayWrapper_epollCreate(JNIEnv *env, jobject this)&#123; /* * epoll_create expects a size as a hint to the kernel about how to * dimension internal structures. We can&#x27;t predict the size in advance. */ int epfd = epoll_create(256); if (epfd &lt; 0) &#123; JNU_ThrowIOExceptionWithLastError(env, &quot;epoll_create failed&quot;); &#125; return epfd;&#125; 我们在linux系统上执行 man epoll_create命令，查看这个函数的文档 -打开一个文件描述符，相当于创建了一个epoll对象，返回文件描述符的索引 int epfd = epoll_create(256) serverSocketChannel.register(…) 1serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); java.nio.channels.SelectableChannel#register(java.nio.channels.Selector, int) 12345public final SelectionKey register(Selector sel, int ops) throws ClosedChannelException&#123; return register(sel, ops, null);&#125; java.nio.channels.spi.AbstractSelectableChannel#register 这个方法里面最终又调用了一个register方法，我们再点进去 12345678910111213141516public final SelectionKey register(Selector sel, int ops, Object att) throws ClosedChannelException&#123; synchronized (regLock) &#123; ..... synchronized (keyLock) &#123; if (!isOpen()) throw new ClosedChannelException(); k = ((AbstractSelector)sel).register(this, ops, att); // 主要看这个register方法 addKey(k); &#125; &#125; ..... &#125;&#125; sun.nio.ch.SelectorImpl#register 这个里面又调用了一个implRegister（）方法，我们点进去是个抽象方法 protected abstract void implRegister(SelectionKeyImpl var1); 查看他的实现类，来到了WindowsSelectorImpl，这是windows系统的实现，我们去查看linux的implRegister的实现方法 123456789protected final SelectionKey register(AbstractSelectableChannel var1, int var2, Object var3) &#123; .... synchronized(this.publicKeys) &#123; this.implRegister(var4); &#125; .... &#125;&#125; sun.nio.ch.EPollSelectorImpl#implRegister pollWrapper.add(fd); fd是文件描述符，会根据这个索引找到这个文件（linux一切皆文件），在此处就是linux系统能够根据pd这个文件描述符找到这个创建好的serverSocketChannel； 这个pollWrapper就是上面Selector.open()里创建的pollWrapper 123456789protected void implRegister(SelectionKeyImpl ski) &#123; if (closed) throw new ClosedSelectorException(); SelChImpl ch = ski.channel; int fd = Integer.valueOf(ch.getFDVal()); fdToKey.put(fd, ski); pollWrapper.add(fd); keys.add(ski);&#125; selector.select(); 123Selector selector = Selector.open(); ....selector.select(); select是一个抽象方法 1public abstract int select() throws IOException; 点进实现类 sun.nio.ch.SelectorImpl#select() 123public int select() throws IOException &#123; return this.select(0L);&#125; lockAndDoSelect 1234567public int select(long var1) throws IOException &#123; if (var1 &lt; 0L) &#123; throw new IllegalArgumentException(&quot;Negative timeout&quot;); &#125; else &#123; return this.lockAndDoSelect(var1 == 0L ? -1L : var1); &#125;&#125; sun.nio.ch.SelectorImpl#lockAndDoSelect 123456789101112private int lockAndDoSelect(long var1) throws IOException &#123; ...... synchronized(this.publicKeys) &#123; synchronized(this.publicSelectedKeys) &#123; var10000 = this.doSelect(var1); &#125; &#125; ...... &#125; &#125;&#125; doSelect是一个抽象方法，点进实现类来到了WindowsSelectorImpl。同样的，我们需要看linux的实现EPollSelectorImpl 1protected abstract int doSelect(long var1) throws IOException; sun.nio.ch.EPollSelectorImpl#doSelect 1234567protected int doSelect(long timeout) throws IOException &#123; ....... pollWrapper.poll(timeout); ....... &#125; return numKeysUpdated;&#125; sun.nio.ch.EPollArrayWrapper#poll 123456789101112int poll(long timeout) throws IOException &#123; updateRegistrations(); updated = epollWait(pollArrayAddress, NUM_EPOLLEVENTS, timeout, epfd); for (int i=0; i&lt;updated; i++) &#123; if (getDescriptor(i) == incomingInterruptFD) &#123; interruptedIndex = i; interrupted = true; break; &#125; &#125; return updated;&#125; 先看updateRegistrations（）方法 updateRegistrations(); 此方法里又调用了一个epollCtl(epfd, opcode, fd, events) ，点进去，这是一个本地方法 private native void epollCtl(int epfd, int opcode, int fd, int events); 内部调用的就是linux函数epoll_ctl 123456789101112131415161718192021222324252627282930private void updateRegistrations() &#123; synchronized (updateLock) &#123; int j = 0; while (j &lt; updateCount) &#123; int fd = updateDescriptors[j]; short events = getUpdateEvents(fd); boolean isRegistered = registered.get(fd); int opcode = 0; if (events != KILLED) &#123; if (isRegistered) &#123; opcode = (events != 0) ? EPOLL_CTL_MOD : EPOLL_CTL_DEL; &#125; else &#123; opcode = (events != 0) ? EPOLL_CTL_ADD : 0; &#125; if (opcode != 0) &#123; epollCtl(epfd, opcode, fd, events); if (opcode == EPOLL_CTL_ADD) &#123; registered.set(fd); &#125; else if (opcode == EPOLL_CTL_DEL) &#123; registered.clear(fd); &#125; &#125; &#125; j++; &#125; updateCount = 0; &#125; &#125; 在linux系统上执行命令 1man epoll_ctl 查看此函数 epollCtl(epfd, opcode, fd, events); epfd epoll实例对应的文件描述符 fd socketChannel对应的文件描述符events 事件 参数opcode又以下几个值： 123EPOLL_CTL_ADD // 注册新的SocketChannel到epoll实例中，并关联事件eventEPOLL_CTL_DEL // 修改已经注册的SocketChannel的监听事件EPOLL_CTL_MOD // 从epoll中移除SocketChannel，并且忽略掉绑定的event epollCtl这个方法把SocketChannel和epoll关联起来 2.updated = epollWait(pollArrayAddress, NUM_EPOLLEVENTS, timeout, epfd); 再回到poll方法里，程序继续往下走，接着看epollWait这个方法，点进去也是一个本地方法，也是调用的操作系统内核函数 epoll_wait epoll_wait, epoll_pwait - wait for an I/O event on an epoll file descriptor epoll_wait的时候，会去查看sector里面的rdlist就绪列表里是否有数据，有数据就跳出阻塞，没有就阻塞住 利用操作系统回调函数，客户端有响应，把事件放进rdlist AIO（NIO 2.0） ​ 异步非阻塞，由操作系统完成后回调通知服务端程序启动线程去处理，一般适用于连接数较多并且连接时间较长的应用 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940public class TestAIO &#123; public static void main(String[] args) throws IOException &#123; AsynchronousServerSocketChannel serverSocketChannel = AsynchronousServerSocketChannel.open().bind(new InetSocketAddress(9000)); serverSocketChannel.accept(null, new CompletionHandler&lt;AsynchronousSocketChannel, Object&gt;() &#123; @Override public void completed(AsynchronousSocketChannel socketChannel, Object attachment) &#123; try &#123; System.out.println(&quot;2----&quot; + Thread.currentThread().getName()); // 再此接收客户端连接,如果不写这行代码后面的客户端连接不上服务端 serverSocketChannel.accept(attachment, this); System.out.println(socketChannel.getRemoteAddress()); ByteBuffer buffer = ByteBuffer.allocate(1024); socketChannel.read(buffer, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; System.out.println(&quot;3---&quot; + Thread.currentThread().getName()); buffer.flip(); System.out.println(new String(buffer.array(), 0, result)); socketChannel.write(ByteBuffer.wrap(&quot;HelloClient&quot;.getBytes())); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; exc.printStackTrace(); &#125; &#125;); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, Object attachment) &#123; exc.printStackTrace(); &#125; &#125;); System.out.println(&quot;1---&quot;+Thread.currentThread().getName()); System.in.read(); &#125;&#125; NettyRector响应式编程模型 所谓响应式，类似于GUI编程中，给一个Button绑定一个或多个事件，对于点击事件，点击后会触发对应方法 基础的Reactor设计，单线程版本; 用一个Reactor去处理客户端的连接，以及读写 存在的问题：类比上面的NioSelectorServer类代码。selector.select()处会阻塞，同一时间如果有大量的读写事件发生，那么循环处理的时候，会耗费大量时间，而此时新进来的连接就会阻塞在selector.select()处。 我们可以引入线程池，将读写工作交给其他线程去处理 存在的问题：还是类比上面的NioSelectorServer类的代码；我们现在while (iterator.hasNext()) {….}循环去处理的时候，引入线程池，将读写事件交给线程池去处理；这样分发完后，主线程能很快的回到selector.select()处，阻塞监听新的事件。但是如果一时间的事件很多，那么分发都需要花费大量的时间，同样新进来的事件也得不到处理 引入两个Reactor，一个mainReactor专门用来处理连接事件。subReactor用来处理独写事件，并且把这些读写事件分发给线程池去完成 Demo NettyServer.java 1234567891011121314151617181920212223242526272829303132333435363738public class NettyServer &#123; public static void main(String[] args) &#123; // 创建两个线程组boss和worker;含有的子线程NioEventLoop的个数默认为cpu核数的两倍 // boss组只是处理连接请求，真正的和客户端业务处理，会交给worker NioEventLoopGroup bossGroup = new NioEventLoopGroup(1); // 相当于主Reactor NioEventLoopGroup workerGroup = new NioEventLoopGroup(8); // 相当于从Reactor try&#123; // 创建服务端的启动对象 ServerBootstrap serverBootstrap = new ServerBootstrap(); // 使用链式编程来配置参数 serverBootstrap.group(bossGroup,workerGroup) // 设置两个线程组 // 使用NioServerSocketChannel作为服务器的通道实现 .channel(NioServerSocketChannel.class) // 初始化服务器连接队列大小，服务端处理客户端连接请求是顺序处理的，所以同一时间处理一个客户端 // 多个客户端同时来连接的时候，服务端将不能处理的客户端连接请求放在队列中等待处理 .option(ChannelOption.SO_BACKLOG,1024) .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new NettyServerHandler()); &#125; &#125;); log.info(&quot;------netty server start...------&quot;); // 绑定一个端口并且同步，生成了一个ChannelFuture异步对象，通过isDone()等方法可以判断异步事件的执行情况 // 启动服务器(并绑定端口),bind是异步操作，sync方法是等待异步操作执行完毕 ChannelFuture sync = serverBootstrap.bind(9000).sync(); // 等待服务端监听端口关闭，closeFuture是异步操作 // 通过sync方法同步等待通道关闭处理完毕，这里会阻塞等待通道关闭，内部调用的是object.wait()方法 sync.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125; NettyServerHandler.Java 123456789101112131415161718192021222324252627282930313233public class NettyServerHandler extends ChannelInboundHandlerAdapter &#123; /** * 读取客户端发送的消息 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf in = (ByteBuf) msg; System.out.println(in.toString(CharsetUtil.UTF_8)); &#125; /** * 数据读取完毕处理方法 */ @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; String msg = &quot;[来自服务端]:congratulations~连接成功&quot;; final ByteBuf byteBuf = Unpooled.copiedBuffer(msg.getBytes(CharsetUtil.UTF_8)); ctx.writeAndFlush(byteBuf); &#125; /** * 异常处理 */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // (4) // Close the connection when an exception is raised. cause.printStackTrace(); ctx.close(); &#125;&#125; NettyClient.java 123456789101112131415161718192021222324252627public class NettyClient &#123; public static void main(String[] args) throws InterruptedException &#123; // 客户端需要一个事件循环组 NioEventLoopGroup group = new NioEventLoopGroup(); try &#123; // 创建客户端启动对象 Bootstrap b = new Bootstrap(); // (1) b.group(group); // (2) b.channel(NioSocketChannel.class); // (3) b.option(ChannelOption.SO_KEEPALIVE, true); // (4) b.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new NettyClientChannel()); &#125; &#125;); System.out.println(&quot;netty client start....&quot;); // Start the client. ChannelFuture f = b.connect(&quot;127.0.0.1&quot;, 9000).sync(); // (5) // Wait until the connection is closed. f.channel().closeFuture().sync(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; NettyClientChannel.java 1234567891011121314151617181920212223242526272829public class NettyClientChannel extends ChannelInboundHandlerAdapter &#123; /** * 当通道有读取事件时，也就是服务端发送消息 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf m = (ByteBuf) msg; try &#123; System.out.println(m.toString(CharsetUtil.UTF_8)); &#125; finally &#123; m.release(); &#125; &#125; /** * 当客户端连接服务器完成就会触发该方法 */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; final ChannelFuture f = ctx.writeAndFlush(Unpooled.copiedBuffer((&quot;[来自客户端]:hello server&quot; ).getBytes(CharsetUtil.UTF_8))); // (3) &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; Netty模块组件 下面部分摘抄自官方文档https://netty.io/wiki/user-guide-for-4.x.html#wiki-h3-9 1、NioEventLoopGroup是一个处理 I/O 操作的多线程事件循环，Netty提供各种NioEventLoopGroup为不同类型的传输提供了各种实现；实现一个服务器端应用程序，因此NioEventLoopGroup将使用两个。第一个，通常称为“boss”，接受传入连接。第二个，通常称为“worker”，一旦boss接受连接并将接受的连接注册到worker;有多少线程使用和它们是如何映射到创建渠道取决于EventLoopGroup通过构造函数实现,甚至可能是可配置的 2、ServerBootstrap is a helper class that sets up a server；ServerBootstrap是一个设置服务器的辅助类。 Bootstrap与ServerBootstrap类似，除了它是非服务端通道，如客户端或无连接通道。 如果您只指定一个EventLoopGroup，它将同时用作boss组和worker组。但是，boss组不用于客户端。 NioSocketChannel被用来创建客户端Channel，而不是NioServerSocketChannel； 注意我们不像ServerBootstrap处，使用childOption(),因为客户端SocketChannel没有父级 我们应该调用connect()方法而不是bind()方法。 3、 Netty 抽象出两组线程池BossGroup和WorkerGroup，BossGroup专门负责接收客户端的连接, WorkerGroup专 门负责网络的 4 、BossGroup和WorkerGroup类型都是NioEventLoopGroup 5、NioEventLoopGroup 相当于一个事件循环线程组, 这个组中含有多个事件循环线程 ， 每一个事件循环线程是 NioEventLoop 6、每个NioEventLoop都有一个selector , 用于监听注册在其上的socketChannel的网络通讯 7、每个Boss NioEventLoop线程内部循环执行的步骤有 3 步 ​ 处理accept事件，与client建立连接，生成NioSocketChannle ​ 将NioSocketChannel注册到某个worker NIOEventLoop上的selector ​ 处理任务队列的任务，即runAllTasks 8、每个worker NIOEventLoop线程循环执行的步骤 ​ 轮询注册到自己selector上的所有NioSocketChannel 的read, write事件 ​ 处理 I/O 事件， 即read , write 事件， 在对应 NioSocketChannel 处理业务 ​ runAllTasks处理任务队列TaskQueue的任务 ，一些耗时的业务处理一般可以放入TaskQueue中慢慢处 理，这样不影响数据在 pipeline 中的流动处理 9、每个worker NIOEventLoop处理NioSocketChannel业务时，会使用 pipeline (管道)，管道中维护了很多 handler 处理器用来处理 channel 中的数据 Bootstrap、ServerBootstrap 一个 Netty 应用通常由一个 Bootstrap 开始，主要作用是配置整个 Netty 程序，串联各个组 件，Netty 中 Bootstrap 类是客户端程序的启动引导类，ServerBootstrap 是服务端启动引导类。 Future、ChannelFuture 在Netty中所有的IO操作都是异步的，不能立刻得知消息是否被正确处理 但是可以等他执行完成或者直接注册一个监听，具体的实现就是通过Future和CahnnelFutures,他们可以注 册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件 Channel Netty网络通信的组件，能够用于执行网络I/O操作。Channel为用户提供 1、当前网络连接的通道的状态（例如是否打开？是否已连接） 2、网络连接的配置参数（例如接收缓冲区大小） 3、提供异步的网络I/O操作（如建立连接，读写，绑定端口），异步调用意味着任何I/O调用都将立即返回，并且不保证在调用结束时所请求的I/O操作已完成 4、调用立即返回一个ChannelFuture实例，通过注册监听器到ChannelFuture上，可以I/O操作成功、失败或取消时回调通知调用方 5、支持关联I/O操作与对应的处理程序。 不同协议、不通的阻塞类型的连接都有不同的Channel类型与之对应 下面是一些常用的Channel类型： NioSocketChannel 异步的客户端TCP Socket连接 NioServerSocketChannel 异步的服务器端TCP Socket连接 NioDatagramChannel 异步的UDP连接 NioSctpChannel 异步的客户端Sctp连接 NioSctpServerChannel 异步的Sctp服务器端连接 这些通道涵盖了UDP和TCP网络IO以及文件IO Selector Netty基于Selector对象实现I/O多路复用，通过Selector一个线程可以监听多个连接的Channel事件。 当向一个Selector中注册Channel后，Selector内部的机制就可以自动不断地查询（Select）这些注册的Channel是否有已就绪的I/O事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多 个 Channel 。 NioEventLoop NioEventLoop中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用NioEventLoop 的 run 方 法，执行 I/O 任务和非 I/O 任务： I/O任务，即selectionKey中ready的事件，如accept、connect、read、write等，由 processSelectedKeys 方 法触发。 非 IO 任务，添加到 taskQueue 中的任务，如 register0、bind0 等任务，由 runAllTasks 方法触发。 NioEventLoopGroup NioEventLoopGroup，主要管理eventLoop的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程（NioEventLoop)负责处理多个Channel上的事件，而一个Channel只对应于一个线程 ChannelHandler ChannelHandler是一个接口，处理I/O事件或拦截I/O操作，并将其转发到其ChannelPipeline(业务处理链)中的下一个处理程序 ChannelHandler本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类： ChannelInboundHandler 用于处理入站I/O事件 ChannelOutboundHandler 用于处理出站I/O操作 或者使用以下适配器类 ChannelInboundHandlerAdapter 用于处理入站I/O事件 ChannlOutboundHandler 用于处理出站I/O操作 ChannelHandlerContext 保存Channel相关的上下文信息，同时关联一个ChannelHandler对象 ChannelPipline ​ 保存ChannelHandler的List,用于处理或拦截Channel的入站事件和出站操作 ChannelPipeline实现了一中高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，事件的处理方式 在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下： ​ 一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组 成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。 read事件(入站事件)和write事件(出站事件)在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰 Netty架构图 ByteBuf ​ 从结构上来说，ByteBuf 由一串字节数组构成。数组中每个字节用来存放信息。 ByteBuf 提供了两个索引，一个用于读取数据，一个用于写入数据。这两个索引通过在字节数组中移动，来定 位需要读或者写信息的位置。 当从 ByteBuf 读取时，它的 readerIndex（读索引）将会根据读取的字节数递增。 同样，当写 ByteBuf 时，它的 writerIndex 也会根据写入的字节数进行递增。 ​ 需要注意的是极限的情况是 readerIndex 刚好读到了 writerIndex 写入的地方。 如果 readerIndex 超过了 writerIndex 的时候，Netty 会抛出 IndexOutOf-BoundsException 异常 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041public class TestByteBuf &#123; public static void main(String[] args) &#123; // 创建byteBuf对象，该对象内部包含一个字符数组byte[10] // 通过readerindex和writeindex和capacity，将buffer分成三个区域， // 已经读取的区域: [0,readerindex) 注意开闭区间 // 可读取的区域: [readerindex,writeindex) // 可写的区域: [writerindex,capacity） ByteBuf buffer = Unpooled.buffer(10); System.out.println(buffer); for (int i = 0; i &lt; 7; i++) &#123; buffer.writeByte(i); &#125; System.out.println(buffer); for (int i = 0; i &lt; 5; i++) &#123; System.out.println(buffer.getByte(i)); &#125; System.out.println(buffer); for (int i = 0; i &lt; 5; i++) &#123; System.out.println(buffer.readByte()); &#125; System.out.println(buffer); System.out.println(&quot;----------------&quot;); ByteBuf byteBuf2 = Unpooled.copiedBuffer(&quot;hello world&quot;, CharsetUtil.UTF_8); if (byteBuf2.hasArray())&#123; byte[] array = byteBuf2.array(); // 转成字符串 System.out.println(new String(array, CharsetUtil.UTF_8)); System.out.println(byteBuf2); System.out.println(byteBuf2.readerIndex()); System.out.println(byteBuf2.writerIndex()); System.out.println(byteBuf2.capacity()); System.out.println(byteBuf2.getByte(0)); // 获取数组0这个位置的字符h的ascii码，h=104 int len = byteBuf2.readableBytes(); // 可读的字节数 System.out.println(&quot;len = &quot; + len); &#125; // 范围读取 CharSequence charSequence = byteBuf2.getCharSequence(0, 6, CharsetUtil.UTF_8); System.out.println(charSequence.toString()); &#125;&#125; Netty编解码 Netty涉及到编解码的组件有Channel、ChannelHandler、ChannelPipe等 ChannelHandler ChannelHandler充当了处理入站和出站数据的应用程序逻辑容器，例如，实现ChannelInboundHandler接口（或 ChannelInboundHandlerAdapter)，你就可以接收入站事件和数据，这些数据随后会被你的应用程序的业务逻辑处理。当你要给连接的客户端发送响应时，也可以从ChannelInboundHandler冲刷数据。你得业务逻辑通常写在一个或者多个ChannelInboundHandler中。ChannelOutboundHandler原理一样，只不过它用来处理出站数据的。 ChannelPipeline ChannelPipeline提供了ChannelHandler链的容器。以客户端应用程序为例，如果事件的运动方向时从客户端到服务端的，那么称为这些事件为出战的，即客户端发送给服务端的数据会通过pipeline中的一系列ChannelOutboundHandler(ChannelOutboundHandler)调用是从tail到head方向逐个调用每个handler的逻辑，并被这些handler处理，反之则称为入站的，入站只调用pipeline里的ChannelInboundHandler逻辑（ChannelInboundHandler调用是从head到tail方向逐个调用每个handler的逻辑 所谓的入站出站，是相当于客户端/服务端来说的，即收到消息为入站，消息发送为出站。入站会从head到tail经过一系列处理调用，但是入站只是会调用继承ChannelInboundHandler的逻辑，出站是从tail到尾进行处理调用，只会调用ChannelOutboundHandler 编码解码器 ​ 当你通过Netty发送或者接收一个消息时，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式（比如java对 象）；如果是出站消息，它会被编码成字节。 ​ Netty提供了一系列的编码解码器，他们都实现了ChannelInboundHadnler或者ChannelOutboundHandler接口。在这些类中，channelRead方法已经被重写了。 ​ 以入站为例，对于每个从入站Channel读取的消息，这个方法会被调用。随后，它将调用由已知解码器 所提供的decode()方法进行解码，并将已经解码的字节转发给ChannelPipeline中的下一个ChannelInboundHandler。Netty提供了很多编解码器，比如编解码字符串的StringEncoder和StringDecoder，编解码对象的ObjectEncoder和ObjectDecoder 等。 如果要实现高效的编解码可以用protobuf，但是protobuf需要维护大量的proto文件比较麻烦，现在一般可以使用protostuff。 protostuff是一个基于protobuf实现的序列化方法，它较于protobuf最明显的好处是，在几乎不损耗性能的情况下做到了不用我们 写.proto文件来实现序列化 maven坐标如下： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff‐api&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff‐core&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff‐runtime&lt;/artifactId&gt; &lt;version&gt;1.0.10&lt;/version&gt;&lt;/dependency&gt; Netty粘包拆包 TCP是一个流协议，就是没有界限的一长串二进制数据。TCP作为传输层协议并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行数据包的划分，所以在业务上认为是一个完整的包，可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。 ​ 面向流的通信是无消息保护边界的。 ​ 如下图：client发送两个数据包D1和D2，但是server端可能会收到如下几种情况的数据 解决方案 1、消息定长度，数据传输的大小固定长度，例如每段长度固定100字节，不够空位补齐 2、在数据包尾部添加特殊分隔符，比如下划线等。前提是消息本体不能带分隔符 3、发送长度：发送每条数据的时候，将数据的长度一并发送。比如可以选取每条数据的前四位去记录长度，接受处理时可以根据长度判定开始和结束 Netty提供了多个解码器，可以进行分包的操作 LineBasedFrameDecoder (回车换行分包) DelimiterBasedFrameDecoder (特殊分隔符分包) FixedLengthFrameDecoder (固定长度报文分包) Netty心跳检测机制​ 在Netty中，实现心跳机制的关键是IDleStateHandler。 123456789101112........childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel)&#123; socketChannel.pipeline().addLast(new StringDecoder()); socketChannel.pipeline().addLast(new StringEncoder()); // IdleStateEvent的readerIdleTime参数指定超过3秒还没收到客户端的连接，会触发 // IdleStateEvent事件并且交给下一个handler处理，下一个handler必须实现userEventTriggered方法处理对应事件 socketChannel.pipeline().addLast(new IdleStateHandler(3,0,0, TimeUnit.SECONDS)); socketChannel.pipeline().addLast(new HeartBeatServerHandler()); &#125;&#125;); 构造函数 12345678910111213141516171819202122232425262728293031323334353637383940// 读超时时间；写超时时间；所有的超时时间；时间单位public IdleStateHandler(long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit) &#123; this(false, readerIdleTime, writerIdleTime, allIdleTime, unit);&#125;public IdleStateHandler(boolean observeOutput, long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit) &#123; this.writeListener = new ChannelFutureListener() &#123; public void operationComplete(ChannelFuture future) throws Exception &#123; IdleStateHandler.this.lastWriteTime = IdleStateHandler.this.ticksInNanos(); IdleStateHandler.this.firstWriterIdleEvent = IdleStateHandler.this.firstAllIdleEvent=true; &#125; &#125;; this.firstReaderIdleEvent = true; this.firstWriterIdleEvent = true; this.firstAllIdleEvent = true; if (unit == null) &#123; throw new NullPointerException(&quot;unit&quot;); &#125; else &#123; this.observeOutput = observeOutput; if (readerIdleTime &lt;= 0L) &#123; this.readerIdleTimeNanos = 0L; &#125; else &#123; // 赋值 this.readerIdleTimeNanos = Math.max(unit.toNanos(readerIdleTime), MIN_TIMEOUT_NANOS); &#125; if (writerIdleTime &lt;= 0L) &#123; this.writerIdleTimeNanos = 0L; // 赋值 &#125; else &#123; this.writerIdleTimeNanos = Math.max(unit.toNanos(writerIdleTime), MIN_TIMEOUT_NANOS); &#125; if (allIdleTime &lt;= 0L) &#123; this.allIdleTimeNanos = 0L; // 赋值 &#125; else &#123; this.allIdleTimeNanos = Math.max(unit.toNanos(allIdleTime), MIN_TIMEOUT_NANOS); &#125; &#125;&#125; channelActive 1234public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; this.initialize(ctx); super.channelActive(ctx);&#125; initialize 1234567891011121314151617181920212223private void initialize(ChannelHandlerContext ctx) &#123; switch(this.state) &#123; case 1: case 2: return; default: this.state = 1; this.initOutputChanged(ctx); this.lastReadTime = this.lastWriteTime = this.ticksInNanos(); // lastReadTime,lastWriteTime赋初始值 if (this.readerIdleTimeNanos &gt; 0L) &#123; // readerIdleTimeNanos就是刚构造器里赋的值 this.readerIdleTimeout = this.schedule(ctx, new IdleStateHandler.ReaderIdleTimeoutTask(ctx), this.readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (this.writerIdleTimeNanos &gt; 0L) &#123; this.writerIdleTimeout = this.schedule(ctx, new IdleStateHandler.WriterIdleTimeoutTask(ctx), this.writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (this.allIdleTimeNanos &gt; 0L) &#123; this.allIdleTimeout = this.schedule(ctx, new IdleStateHandler.AllIdleTimeoutTask(ctx), this.allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; &#125;&#125; schedule 123ScheduledFuture&lt;?&gt; schedule(ChannelHandlerContext ctx, Runnable task, long delay, TimeUnit unit) &#123; return ctx.executor().schedule(task, delay, unit);&#125; ChannelHandlerContext ctx是io.netty.channel.DefaultChannelHandlerContext实例，DefaultChannleHandlerContext又继承了AbstractChannelHandlerContext，在AbstractChannelHandlerContext中找到executor()方法，如下 123public EventExecutor executor() &#123; return (EventExecutor)(this.executor == null ? this.channel().eventLoop() : this.executor);&#125; ​ ctx.executor()会返回一个EventExecutor，其类图如下，跟ScheduledThreadPollExecutor定时线程池一样，其都继承或实现自ScheduledExecutorService接口 接着我们去看new IdleStateHandler.ReaderIdleTimeoutTask(ctx)，这个任务里的run方法 123456789101112131415161718192021222324protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = IdleStateHandler.this.readerIdleTimeNanos; if (!IdleStateHandler.this.reading) &#123; // nextDelay = readerIdleTimeNanos - (当前时间 - lastReadTime) // channelReadComplete()方法里，会更新lastReadTime // 其实就是在计算 读的时间间隔是否超过设定的时间 nextDelay -= IdleStateHandler.this.ticksInNanos() - IdleStateHandler.this.lastReadTime; &#125; if (nextDelay &lt;= 0L) &#123; // 小于等于0，即超时了走这里 IdleStateHandler.this.readerIdleTimeout = IdleStateHandler.this.schedule(ctx, this, IdleStateHandler.this.readerIdleTimeNanos, TimeUnit.NANOSECONDS); // 还会提交任务，延迟时间为readerIdleTimeNanos boolean first = IdleStateHandler.this.firstReaderIdleEvent;// 构造函数赋初始值为true IdleStateHandler.this.firstReaderIdleEvent = false; try &#123; IdleStateEvent event = IdleStateHandler.this.newIdleStateEvent(IdleState.READER_IDLE, first); IdleStateHandler.this.channelIdle(ctx, event); &#125; catch (Throwable var6) &#123; ctx.fireExceptionCaught(var6); &#125; &#125; else &#123; IdleStateHandler.this.readerIdleTimeout = IdleStateHandler.this.schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125;&#125; 123protected void channelIdle(ChannelHandlerContext ctx, IdleStateEvent evt) throws Exception &#123; ctx.fireUserEventTriggered(evt); // 会调用到下一个handler&#125; 源码剖析NioEventLoopGroup12NioEventLoopGroup bossGroup = new NioEventLoopGroup(1);NioEventLoopGroup workerGroup = new NioEventLoopGroup(); 构造函数 1234567891011121314151617181920public NioEventLoopGroup() &#123; this(0);&#125;public NioEventLoopGroup(int nThreads) &#123; this(nThreads, (Executor)null);&#125;public NioEventLoopGroup(int nThreads, Executor executor) &#123; this(nThreads, executor, SelectorProvider.provider()); //SelectorProvider.provider()就是前面NIO所说的EPollSelectorProvider,详情看Selector.open()&#125;.......// 无参构造最终会调用这个有参构造 public NioEventLoopGroup(int nThreads, ThreadFactory threadFactory, SelectorProvider selectorProvider, SelectStrategyFactory selectStrategyFactory) &#123; super(nThreads, threadFactory, new Object[]&#123;selectorProvider, selectStrategyFactory, RejectedExecutionHandlers.reject()&#125;); //调用父类MultithreadEventLoopGroup的构造器 &#125; io.netty.channel.MultithreadEventLoopGroup 123456private static final int DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt(&quot;io.netty.eventLoopThreads&quot;, NettyRuntime.availableProcessors() * 2));protected MultithreadEventLoopGroup(int nThreads, ThreadFactory threadFactory, Object... args) &#123; super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, threadFactory, args); //继续调用父类构造器，nThreads = 0的话，会传入默认的线程数，cpu核数*2&#125; io.netty.util.concurrent.MultithreadEventExecutorGroup 123protected MultithreadEventExecutorGroup(int nThreads, Executor executor, Object... args) &#123; this(nThreads, executor, DefaultEventExecutorChooserFactory.INSTANCE, args);&#125; 最终会调用MultithreadEventExecutorGroup类的这个构造方法 123456789101112131415161718192021222324252627282930protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123; // nThreads = 16，executor = null this.terminatedChildren = new AtomicInteger(); this.terminationFuture = new DefaultPromise(GlobalEventExecutor.INSTANCE); if (nThreads &lt;= 0) &#123; throw new IllegalArgumentException(String.format(&quot;nThreads: %d (expected: &gt; 0)&quot;, nThreads)); &#125; else &#123; if (executor == null) &#123; // 创建一个线程池 executor = new ThreadPerTaskExecutor(this.newDefaultThreadFactory()); &#125; this.children = new EventExecutor[nThreads]; // 创建一个EventExecutor数组，长度为nThreads（16） int j; for(int i = 0; i &lt; nThreads; ++i) &#123; boolean success = false; boolean var18 = false; try &#123; var18 = true; // 循环遍历，对数组中的每个元素赋值；会去new NioEventLoop(...) this.children[i] = this.newChild((Executor)executor, args); success = true; var18 = false; &#125; catch (Exception var19) &#123; throw new IllegalStateException(&quot;failed to create a child event loop&quot;, var19); &#125; finally &#123; ....... &#125;&#125; newChild() io.netty.channel.nio.NioEventLoopGroup#newChild 123protected EventLoop newChild(Executor executor, Object... args) throws Exception &#123; return new NioEventLoop(this, executor, (SelectorProvider)args[0], ((SelectStrategyFactory)args[1]).newSelectStrategy(), (RejectedExecutionHandler)args[2]);&#125; io.netty.channel.nio.NioEventLoop 构造函数 public final class NioEventLoop extends SingleThreadEventLoop 1234567891011121314NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, false, DEFAULT_MAX_PENDING_TASKS, rejectedExecutionHandler); // 调用父类构造器,里面会创建一个阻塞队列taskQueue if (selectorProvider == null) &#123; throw new NullPointerException(&quot;selectorProvider&quot;); &#125; else if (strategy == null) &#123; throw new NullPointerException(&quot;selectStrategy&quot;); &#125; else &#123; this.provider = selectorProvider; NioEventLoop.SelectorTuple selectorTuple = this.openSelector(); // 类比前面NIO的代码，创建selector this.selector = selectorTuple.selector; this.unwrappedSelector = selectorTuple.unwrappedSelector; this.selectStrategy = strategy; &#125;&#125; io.netty.channel.SingleThreadEventLoop 构造函数 public abstract class SingleThreadEventLoop extends SingleThreadEventExecutor implements EventLoop 1234protected SingleThreadEventLoop(EventLoopGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedExecutionHandler) &#123; super(parent, executor, addTaskWakesUp, maxPendingTasks, rejectedExecutionHandler); this.tailTasks = this.newTaskQueue(maxPendingTasks);&#125; io.netty.util.concurrent.SingleThreadEventExecutor 构造函数 12345678910111213141516protected SingleThreadEventExecutor(EventExecutorGroup parent, Executor executor, boolean addTaskWakesUp, int maxPendingTasks, RejectedExecutionHandler rejectedHandler) &#123; super(parent); this.threadLock = new Semaphore(0); this.shutdownHooks = new LinkedHashSet(); this.state = 1; this.terminationFuture = new DefaultPromise(GlobalEventExecutor.INSTANCE); this.addTaskWakesUp = addTaskWakesUp; this.maxPendingTasks = Math.max(16, maxPendingTasks); this.executor = ThreadExecutorMap.apply(executor, this); this.taskQueue = this.newTaskQueue(this.maxPendingTasks); // 创建阻塞队列 this.rejectedExecutionHandler = (RejectedExecutionHandler)ObjectUtil.checkNotNull(rejectedHandler, &quot;rejectedHandler&quot;);&#125;protected Queue&lt;Runnable&gt; newTaskQueue(int maxPendingTasks) &#123; return new LinkedBlockingQueue(maxPendingTasks);&#125; ServerBootstrap 12ServerBootstrap serverBootstrap = new ServerBootstrap();serverBootstrap.group(bossGroup,workerGroup)..... ServerBootstrap构造器为空方法，没有做什么逻辑处理 group(bossGroup,workerGroup)1234567891011public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) &#123; super.group(parentGroup); if (childGroup == null) &#123; throw new NullPointerException(&quot;childGroup&quot;); &#125; else if (this.childGroup != null) &#123; throw new IllegalStateException(&quot;childGroup set already&quot;); &#125; else &#123; this.childGroup = childGroup; return this; &#125;&#125; io.netty.bootstrap.AbstractBootstrap#group public abstract class AbstractBootstrap&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; implements Cloneable {} 12345678910public B group(EventLoopGroup group) &#123; if (group == null) &#123; throw new NullPointerException(&quot;group&quot;); &#125; else if (this.group != null) &#123; throw new IllegalStateException(&quot;group set already&quot;); &#125; else &#123; this.group = group; // 赋值 return this.self(); &#125;&#125; channel(NioServerSocketChannel.class)1234567public B channel(Class&lt;? extends C&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException(&quot;channelClass&quot;); &#125; else &#123; return this.channelFactory((new ReflectiveChannelFactory(channelClass))); &#125;&#125; new ReflectiveChannelFactory(channelClass) 12345678910private final Constructor&lt;? extends T&gt; constructor; // 成员属性public ReflectiveChannelFactory(Class&lt;? extends T&gt; clazz) &#123; ObjectUtil.checkNotNull(clazz, &quot;clazz&quot;); try &#123; this.constructor = clazz.getConstructor(); // 获取传进来class的构造函数，并赋值给成员属性 &#125; catch (NoSuchMethodException var3) &#123; throw new IllegalArgumentException(&quot;Class &quot; + StringUtil.simpleClassName(clazz) + &quot; does not have a public non-arg constructor&quot;, var3); &#125; this.channelFactory((new ReflectiveChannelFactory(channelClass))); channelFactory()方法,就是将channelFactory赋值给成员属性 123456public B channelFactory(ChannelFactory&lt;? extends C&gt; channelFactory) &#123; ....... this.channelFactory = channelFactory; return this.self(); &#125;&#125; option(ChannelOption.SO_BACKLOG,1024)12345678910111213141516171819private final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = new LinkedHashMap(); // 成员属性public &lt;T&gt; B option(ChannelOption&lt;T&gt; option, T value) &#123; if (option == null) &#123; throw new NullPointerException(&quot;option&quot;); &#125; else &#123; if (value == null) &#123; synchronized(this.options) &#123; this.options.remove(option); &#125; &#125; else &#123; synchronized(this.options) &#123; this.options.put(option, value); // 就是把传进来的key,value放进map &#125; &#125; return this.self(); &#125;&#125; childHandler(new ChannelInitializer() {…}handler()是发生在初始化的时候，childHandler()是发生在客户端连接之后 .childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { socketChannel.pipeline().addLast(new ….); }}); 12345678910private volatile ChannelHandler childHandler; // 成员属性public ServerBootstrap childHandler(ChannelHandler childHandler) &#123; if (childHandler == null) &#123; throw new NullPointerException(&quot;childHandler&quot;); &#125; else &#123; this.childHandler = childHandler; return this; &#125;&#125; bind ChannelFuture cf = serverBootstrap.bind(ip,port); ServerBootstrap继承AbstractBootstrap，bind是父类AbstractBootstrap的方法 123public ChannelFuture bind(int inetPort) &#123; return this.bind(new InetSocketAddress(inetPort));&#125; 调用重载方法 12345678public ChannelFuture bind(SocketAddress localAddress) &#123; this.validate(); // 参数校验 if (localAddress == null) &#123; throw new NullPointerException(&quot;localAddress&quot;); &#125; else &#123; return this.doBind(localAddress); &#125;&#125; validate方法 校验成员属性是否有值,也就是group()，channel()配置的那些 123456789public B validate() &#123; if (this.group == null) &#123; throw new IllegalStateException(&quot;group not set&quot;); &#125; else if (this.channelFactory == null) &#123; throw new IllegalStateException(&quot;channel or channelFactory not set&quot;); &#125; else &#123; return this.self(); &#125;&#125; this.doBind(localAddress)方法 1234567891011121314151617181920212223242526private ChannelFuture doBind(final SocketAddress localAddress) &#123; final ChannelFuture regFuture = this.initAndRegister(); // ① final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &#123; return regFuture; &#125; else if (regFuture.isDone()) &#123; ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); // ② return promise; &#125; else &#123; final AbstractBootstrap.PendingRegistrationPromise promise = new AbstractBootstrap.PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &#123; public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; promise.setFailure(cause); &#125; else &#123; promise.registered(); AbstractBootstrap.doBind0(regFuture, channel, localAddress, promise); &#125; &#125; &#125;); return promise; &#125;&#125; this.initAndRegister()方法1234567891011121314151617181920212223final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; // channelFactory就是channel方法赋值的 ReflectiveChannelFactory // ReflectiveChannelFactory的newChannel()方法主要是: return (Channel)this.constructor.newInstance(); // 如前文所说，constructor也是channel方法赋值的，我们传进来的是NioServerSocketChannel.class channel = this.channelFactory.newChannel(); this.init(channel); &#125; catch (Throwable var3) &#123; ...... &#125; ChannelFuture regFuture = this.config().group().register(channel); // 将NioServerSocketChannel注册 if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; return regFuture;&#125; NioServerSocketChannel的无参构造：12345private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); // 成员属性public NioServerSocketChannel() &#123; this(newSocket(DEFAULT_SELECTOR_PROVIDER));&#125; 先看newSocket()方法 1234567private static java.nio.channels.ServerSocketChannel newSocket(SelectorProvider provider) &#123; try &#123; return provider.openServerSocketChannel(); // 类比文章开头的NIO代码，几乎一模一样 会去创建ServerSocketChannel对象 &#125; catch (IOException var2) &#123; throw new ChannelException(&quot;Failed to open a server socket.&quot;, var2); &#125;&#125; this(newSocket(DEFAULT_SELECTOR_PROVIDER));调用重载的构造器 1234public NioServerSocketChannel(java.nio.channels.ServerSocketChannel channel) &#123; super((Channel)null, channel, SelectionKey.OP_ACCEPT); // SelectionKey.OP_ACCEPT 连接事件 this.config = new NioServerSocketChannel.NioServerSocketChannelConfig(this, this.javaChannel().socket());&#125; 父类构造器 12345678910111213141516171819202122232425262728293031323334353637protected AbstractNioMessageChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent, ch, readInterestOp); // ① 继续调用父类构造器，如下&#125;protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); // ② 继续往上调用,代码如下 this.ch = ch; this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); // 设置ServerSocketChannel为非阻塞 &#125; catch (IOException var7) &#123; ...... &#125;&#125;protected AbstractChannel(Channel parent) &#123; // ③ this.parent = parent; this.id = this.newId(); this.unsafe = this.newUnsafe(); this.pipeline = this.newChannelPipeline(); // 创造pipeline&#125;protected DefaultChannelPipeline newChannelPipeline() &#123; // ④ return new DefaultChannelPipeline(this);&#125;protected DefaultChannelPipeline(Channel channel) &#123; // ⑤ this.channel = (Channel)ObjectUtil.checkNotNull(channel, &quot;channel&quot;); this.succeededFuture = new SucceededChannelFuture(channel, (EventExecutor)null); this.voidPromise = new VoidChannelPromise(channel, true); // 创建尾部节点，TailContext与HeadContext都间接实现了ChannelHandlerContext，AbstractChannelHandlerContext实现了它 // class TailContext extends AbstractChannelHandlerContext implements ChannelInboundHandler this.tail = new DefaultChannelPipeline.TailContext(this); this.head = new DefaultChannelPipeline.HeadContext(this); // 创建头部节点 this.head.next = this.tail; // 首尾互指 this.tail.prev = this.head;&#125; ch.configureBlocking(false); 即前面NIO代码的如下地方： this.init(channel); this.init()是一个抽象方法，ServerBootstrap中对应实现如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = new LinkedHashMap(); // AbstractBootstrap中的成员属性void init(Channel channel) throws Exception &#123; //channel ——&gt; NioServerSocketChannel实例 // options0（）是父类AbstractBootstrap方法，具体逻辑就是 return this.options; // this.options是前文所说的option()方法赋的值 Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = this.options0(); synchronized(options) &#123; // 会去遍历options,给nioServerSocketChannel里的成员属性ServerSocketChannelConfig赋值 setChannelOptions(channel, options, logger); ， &#125; Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = this.attrs0(); synchronized(attrs) &#123; Iterator var5 = attrs.entrySet().iterator(); while(true) &#123; if (!var5.hasNext()) &#123; break; &#125; Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e = (Entry)var5.next(); AttributeKey&lt;Object&gt; key = (AttributeKey)e.getKey(); channel.attr(key).set(e.getValue()); &#125; &#125; ChannelPipeline p = channel.pipeline(); // 拿到NioServerSocketChannel中的pipeline final EventLoopGroup currentChildGroup = this.childGroup; final ChannelHandler currentChildHandler = this.childHandler; final Entry[] currentChildOptions; synchronized(this.childOptions) &#123; currentChildOptions = (Entry[])this.childOptions.entrySet().toArray(newOptionArray(0)); &#125; final Entry[] currentChildAttrs; synchronized(this.childAttrs) &#123; currentChildAttrs = (Entry[])this.childAttrs.entrySet().toArray(newAttrArray(0)); &#125; p.addLast(new ChannelHandler[]&#123;new ChannelInitializer&lt;Channel&gt;() &#123; // 往pipeline里添加一个handler public void initChannel(final Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = ServerBootstrap.this.config.handler(); if (handler != null) &#123; pipeline.addLast(new ChannelHandler[]&#123;handler&#125;); &#125; ch.eventLoop().execute(new Runnable() &#123; public void run() &#123; pipeline.addLast(new ChannelHandler[]&#123;new ServerBootstrap.ServerBootstrapAcceptor(ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)&#125;); &#125; &#125;); &#125; &#125;&#125;);&#125; this.config().group().register(channel); this.config()返回一个ServerBootstrapConfig对象 1public abstract AbstractBootstrapConfig&lt;B, C&gt; config(); //抽象方法 ServerBootstarp中的实现如下 12345private final ServerBootstrapConfig config = new ServerBootstrapConfig(this); // 成员属性public final ServerBootstrapConfig config() &#123; return this.config;&#125; ServerBootstrapConfig的构造方法如下： 123456789101112ServerBootstrapConfig(ServerBootstrap bootstrap) &#123; super(bootstrap); // 往上调用&#125;public abstract class AbstractBootstrapConfig&lt;B extends AbstractBootstrap&lt;B, C&gt;, C extends Channel&gt; &#123; protected final B bootstrap; protected AbstractBootstrapConfig(B bootstrap) &#123; // 将ServerBootstarp赋值给成员属性 this.bootstrap = (AbstractBootstrap)ObjectUtil.checkNotNull(bootstrap, &quot;bootstrap&quot;); &#125;&#125; group()方法 123public final EventLoopGroup group() &#123; return this.bootstrap.group(); // this.bootstrap就是ServerBootstrap实例&#125; 12345volatile EventLoopGroup group; // 成员属性；具体在前文所说的ServerBootstrap里的group方法里赋的值public final EventLoopGroup group() &#123; return this.group; // 就是NioEventLoopGroup，准确来说是boss线程组。&#125; register(channel)方法 ​ 前面的this.config().group()会返回NioEventLoopGroup，register是抽象方法；而NioEventLoopGroup继承MultithreadEventLoopGroup，我们看MultithreadEventLoopGroup里的实现 1234567public ChannelFuture register(Channel channel) &#123; // channel ——&gt; NioServerSocketChannel return this.next().register(channel);&#125;public EventLoop next() &#123; return (EventLoop)super.next(); // 拿一个NioEventLoop线程，前面所说会创建(默认长度为16的)children数组，并循环遍历对每一个赋值&#125; ​ 接着继续跟进返回的nioEventLoop的register方法，NioEventLoop继承SingleThreadEventLoop，所以我们看它里面的实现 io.netty.channel.SingleThreadEventLoop#register(io.netty.channel.Channel) 123public ChannelFuture register(Channel channel) &#123; return this.register((ChannelPromise)(new DefaultChannelPromise(channel, this)));&#125; 调用重载方法 12345public ChannelFuture register(ChannelPromise promise) &#123; ObjectUtil.checkNotNull(promise, &quot;promise&quot;); promise.channel().unsafe().register(this, promise); // this ————&gt; NioEventLoop return promise;&#125; io.netty.channel.AbstractChannel.AbstractUnsafe#register 123456789101112131415161718192021public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; if (eventLoop == null) &#123; ...... &#125; else &#123; AbstractChannel.this.eventLoop = eventLoop; // 将传进来的NioEventLoop赋值给成员属性 if (eventLoop.inEventLoop()) &#123; // 判断当前线程是否是NioEventLoop中的线程 this.register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; public void run() &#123; AbstractUnsafe.this.register0(promise); &#125; &#125;); &#125; catch (Throwable var4) &#123; ...... &#125; &#125; &#125;&#125; 先看excute方法做了什么 io.netty.util.concurrent.SingleThreadEventExecutor#execute 123456789101112131415161718192021222324252627282930public void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; else &#123; boolean inEventLoop = this.inEventLoop(); this.addTask(task); // 将任务添加到taskQueue队列 if (!inEventLoop) &#123; this.startThread(); if (this.isShutdown()) &#123; boolean reject = false; try &#123; if (this.removeTask(task)) &#123; reject = true; &#125; &#125; catch (UnsupportedOperationException var5) &#123; &#125; if (reject) &#123; reject(); &#125; &#125; &#125; if (!this.addTaskWakesUp &amp;&amp; this.wakesUpForTask(task)) &#123; this.wakeup(inEventLoop); &#125; &#125;&#125; 123456789101112131415private void doStartThread() &#123; this.executor.execute(new Runnable() &#123; public void run() &#123; .... label1907: &#123; try &#123; var112 = true; SingleThreadEventExecutor.this.run(); // 调用NioEventLoop的run方法 success = true; var112 = false; break label1907; &#125; catch (Throwable var119) &#123; ....... &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected void run() &#123; while(true) &#123; while(true) &#123; while(true) &#123; try &#123; try &#123; switch(this.selectStrategy.calculateStrategy(this.selectNowSupplier, this.hasTasks())) &#123; case -3: case -1: // select()，类比NIO代码 // 方法里面会去调用 selector.select(timeoutMillis);超时等待 this.select(this.wakenUp.getAndSet(false)); if (this.wakenUp.get()) &#123; this.selector.wakeup(); &#125; break; case -2: continue; &#125; &#125; catch (IOException var23) &#123; this.rebuildSelector0(); handleLoopException(var23); continue; &#125; this.cancelledKeys = 0; this.needsToSelectAgain = false; int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; this.processSelectedKeys(); // 类比NIO代码,拿到SelectionKey &#125; finally &#123; this.runAllTasks(); // 执行任务 &#125; &#125; else &#123; long ioStartTime = System.nanoTime(); boolean var14 = false; try &#123; var14 = true; this.processSelectedKeys(); var14 = false; &#125; finally &#123; if (var14) &#123; long ioTime = System.nanoTime() - ioStartTime; this.runAllTasks(ioTime * (long)(100 - ioRatio) / (long)ioRatio); &#125; &#125; long ioTime = System.nanoTime() - ioStartTime; this.runAllTasks(ioTime * (long)(100 - ioRatio) / (long)ioRatio); &#125; &#125; catch (Throwable var24) &#123; handleLoopException(var24); &#125; break; &#125; ....... &#125; &#125;&#125; 1234567891011121314151617181920protected boolean runAllTasks() &#123; assert this.inEventLoop(); boolean ranAtLeastOne = false; boolean fetchedAll; do &#123; fetchedAll = this.fetchFromScheduledTaskQueue(); if (this.runAllTasksFrom(this.taskQueue)) &#123; // 从队列中获取任务并执行 ranAtLeastOne = true; &#125; &#125; while(!fetchedAll); if (ranAtLeastOne) &#123; this.lastExecutionTime = ScheduledFutureTask.nanoTime(); &#125; this.afterRunningAllTasks(); return ranAtLeastOne;&#125; 回过头来看，执行任务的逻辑，即刚刚提交任务的run方法 eventLoop.execute(new Runnable() { public void run() { AbstractUnsafe.this.register0(promise); }}); 123456789101112131415161718192021222324252627private void register0(ChannelPromise promise) &#123; try &#123; if (!promise.setUncancellable() || !this.ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = this.neverRegistered; AbstractChannel.this.doRegister(); // 注册 this.neverRegistered = false; AbstractChannel.this.registered = true; AbstractChannel.this.pipeline.invokeHandlerAddedIfNeeded(); this.safeSetSuccess(promise); AbstractChannel.this.pipeline.fireChannelRegistered(); // 责任链调用pipeline中的handler if (AbstractChannel.this.isActive()) &#123; if (firstRegistration) &#123; AbstractChannel.this.pipeline.fireChannelActive(); &#125; else if (AbstractChannel.this.config().isAutoRead()) &#123; this.beginRead(); &#125; &#125; &#125; catch (Throwable var3) &#123; this.closeForcibly(); AbstractChannel.this.closeFuture.setClosed(); this.safeSetFailure(promise, var3); &#125;&#125; 12345678910111213141516protected void doRegister() throws Exception &#123; boolean selected = false; while(true) &#123; try &#123; this.selectionKey = this.javaChannel().register(this.eventLoop().unwrappedSelector(), 0, this); // 将serverSocketChannel注册到selector上，并让其对 return; &#125; catch (CancelledKeyException var3) &#123; if (selected) &#123; throw var3; &#125; this.eventLoop().selectNow(); selected = true; &#125; &#125; &#125; 1234public final ChannelPipeline fireChannelRegistered() &#123; AbstractChannelHandlerContext.invokeChannelRegistered(this.head); // 将pipeline中的头节点传进去 return this;&#125; 12345678910111213static void invokeChannelRegistered(final AbstractChannelHandlerContext next) &#123; EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeChannelRegistered(); &#125; else &#123; executor.execute(new Runnable() &#123; // 接着执行 public void run() &#123; next.invokeChannelRegistered(); &#125; &#125;); &#125;&#125; 流程图 无锁串行化​ 大多数场景下，并行多线程处理可以提升系统的并发能力。但是，如果对于共享资源的并发访问处理不当，会带来严重的锁竞争，这最终会导致性能的下降。为了尽可能的避免锁竞争带来的性能损耗，可以通过串行化设计，即消息的处理尽可能在同一个线程内完成，期间不进行线程的切换，这样就避免了多线程竞争和同步锁。NIO的多路复用就是一种无锁串行化的设计思想。为了尽可能提升性能，Netty采用了串行无锁化设计，在IO线程内部进行串行操作，避免多线程竞争导致的性能下降。表面上来看，串行化的设计似乎CPU利用率不高，并发成都不够，但是，通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优 Netty的NioEventLoop读到消息之后，直接调用ChannelPipeline的fireChannelRead(Object msg)，只要用户不主动切换线程，一直会由NioEventLoop调到用户的handler,期间不进行线程切换 零拷贝（直接内存的使用） 直接内存 直接内存Direct Memory,并不是虚拟机运行时数据区的一部分，某些情况下这部分内存也会被频繁地使用，而且也可能导致OOM,Java里用DirectByteBuffer可以分配一块直接内存(堆外内存) ​ 直接内存申请较慢，但访问效率高。在java虚拟机实现上，本地IO一般会直接操作直接内存（直接内存-&gt;系统调用 -&gt;硬盘/网卡），而非直接内存则需要二次拷贝（堆内存-&gt;直接内存-&gt;系统调用-&gt;硬盘/网卡）。 ​ Netty的接收和发送ByteBuf采用DIRECT BUFFERS ， 使用堆外内存进行Scoket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的JVM堆内存（HEAP BUFFERS)进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才能写入Socket中，Jvm堆内存的数据是不能写入Socket中的。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 优点： 不占用堆内存空间，减少GC发生的频率 java虚拟机实现上，本地IO会直接操作直接内存（直接内存——&gt;系统调用——&gt;硬盘/网卡），而非直接内存则需要二次拷贝（堆内存——&gt;直接内存——&gt;系统调用——&gt;硬盘/网卡） 缺点： 初始分配较慢 没有JVM直接帮助管理内存，容易发生内存溢出，为了避免一直没有FULL GC，最终导致直接内存把物理内存耗完。我们可以指定直接内存的最大值，通过-XX:MaxDirectMemorySize来指定，当达到阈值的时候，调用system.gc来进行一次FULL GC，间接把那些没有被使用的直接内存回收掉 ByteBuf内存池设计 ​ 随着JVM虚拟机和JIT即时编译技术的发展，对象的分配和回收是个非常轻量级的工作。但是对于缓冲区Buffer(相当于一个内存块)，情况却稍有不同，特别是对于堆外直接内存的分配和回收，是一件耗时的操作，为了尽量重用缓冲区，Netty提供了基于ByteBuffer内存池的缓冲区重用机制。需要的时候直接从池子里获取ByteBuf使用即可，使用完毕之后就重新放回池子里去。 灵活的TCP参数配置能力​ 合理设置TCP参数在某些场景下对于性能的提升可以起到显著的效果，例如接收缓冲区SO_RCVBUF和发送缓冲区SO_SNDBUF。如果设置不当，对性能的影响是非常大的。通常建议值为128k或者256k Netty在启动辅助类ChannelOption中可以灵活的配置TCP参数，满足不同的用户场景 ByteBuf扩容机制 minNewCapacity：表示用户需要写入的值大小 threshold：阈值，为bytebuf内部设定容量的最大值 maxCapacity：Netty最大能接受的容量大小，一般为int的最大值","categories":[{"name":"netty","slug":"netty","permalink":"http://c89757.gitee.io/colinstar/categories/netty/"}],"tags":[{"name":"nio","slug":"nio","permalink":"http://c89757.gitee.io/colinstar/tags/nio/"},{"name":"netty","slug":"netty","permalink":"http://c89757.gitee.io/colinstar/tags/netty/"}]},{"title":"关于count(*)","slug":"关于count()","date":"2021-12-22T12:09:37.000Z","updated":"2021-12-22T13:01:32.776Z","comments":true,"path":"2021/12/22/关于count()/","link":"","permalink":"http://c89757.gitee.io/colinstar/2021/12/22/%E5%85%B3%E4%BA%8Ecount()/","excerpt":"","text":"count(*)的不同实现方式 在 msyql 引擎中，count（*）有不同的实现方式 MyISAM引擎把一个表的总行数存在了磁盘上,因此执行count(*)的时候会直接返回这个数，效率很高 而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累计计数 当然，这里说的是不加where条件的count(*)，如果加了条件，MyISAM表也不能返回这么快的。 为什么InnoDB不像MyISAM一样，也把数字存起来呢？ ​ 因为即使在同一个时刻的多个子查询，由于多版本并发控制（MVCC）的原因，而InnoDB表 应该返回多少行 也是不确定的。 比如现在某表中有1000条数据 会话A去执行select(*) 会话B开启事务，新增一条数据，再执行select * 会话A和会话B在同一时刻执行，那么他们返回的总行数是不一样的，A返回1000，而B返回1001 这和InnoDB的事务有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是MVCC来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB会把数据一行一行的读出来依次判断，可见的行才能够计算“基于这个查询”的表的总行数 ​ MySQL在执行 count(*)操作的时候还是做了优化的。 InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是 主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树 得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑 正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一 解决方案 如果一个页面需要经常查询显示某表的总数，应该如何去做呢？ 我们应该自己去计数 用缓存系统保存计数​ 可以用Redis去记录这个表的总行数。每插入一行Redis计数就加1，每删除一行Redis计数就减1。 可能存在的问题： 1、Redis可能会丢失数据，如果我们刚在表里插入了一行数据，Redis中的值也进行了自增，然后Redis宕机了，还没来得及进行持久化，导致数据的丢失； （我们可以在Redis宕机后，手动select(*)查询总行数写回Redis) 2、Redis和MySql存在分布式事务问题； 比如某个场景下，我们需要查询显示总数，并且还要显示最近操作的100条记录。那我们就需要先从Redis里面取出计数，再去表里取数据记录 可能存在的问题，查到的100行里面没有新增的数据，但Redis的计数已经加1 另一种是，查到的100行有新增的数，但是Redis的计数还没加1 产生的原因就是，无法保证提交数据库事务的同时写入Redis， 在数据库保存计数​ 用一张表去记录总数，可以避免上述问题，因此事务的可见性，我们插入数据和修改表中记录的行数都是在方法执行完后统一提交的事务，事务还未提交时，对其他线程是不可见的 从并发系统性能的角度看，应该先插数据表，还是先更新计数表呢？ 更新计数表会涉及到行锁的竞争，先插入再更新能最大程度的减少了事务之间的锁等待，提高并发度（事务开启后，更新操作放到最后，减少锁等待时间的影响） 不同count的用法count(*)、count(id)、count(字段)、count(1)的用法的性能，有哪些差别呢。 基于InnoDB引擎 count（）是一个聚合函数，对于返回的结果集，一行一行的判断，如果count函数的参数不是null,就会累计值加1，否则不加。 所以count(*),count(id),count(字段),count(1)都返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里，参数“字段”不为null的总个数 对于count(id)来说。InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层，server层拿到id后，判断是不可能为空的，就按行累加 对于count(1)来说。InnoDB引擎遍历整张表，但是不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加 count(*)执行的要比count(id)快，因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作 对于count(字段)来说。 如果这个字段是定义为not null的话，一行行的从记录里面读取出这个字段，判断不能为null,按行累加； 如果这个字段允许为空，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加 对于count(*)来说。并不会把全部字段取出来，而是专门做了优化，不取值，count(*)肯定不是null,按行累加 按照效率排序的话，count(字段) &lt; count(id) &lt; count(1) ≈ count(*)","categories":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"}]},{"title":"Sychronized关键字-monitorenter与monitorexit","slug":"Sychronized关键字-monitorenter与monitorexit","date":"2021-12-17T11:19:25.000Z","updated":"2022-01-15T15:13:50.736Z","comments":true,"path":"2021/12/17/Sychronized关键字-monitorenter与monitorexit/","link":"","permalink":"http://c89757.gitee.io/colinstar/2021/12/17/Sychronized%E5%85%B3%E9%94%AE%E5%AD%97-monitorenter%E4%B8%8Emonitorexit/","excerpt":"","text":"每个对象都有一个Monitor与之关联，当Monitor被持有后，它将处于锁定状态。Synchronized在JVM里的实现都是 基于进入和退出Monitor对象来实现方法同步和代码块同步，都可以通过成对的MonitorEnter和MonitorExit指令来实现。 12345public void method() &#123; synchronized(this) &#123; System.out.println(&quot;hello world&quot;); &#125; &#125; 经过javap解析后 1234567891011121314151617181920212223public void method(); Code: 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String hello world 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit 14: goto 22 17: astore_2 18: aload_1 19: monitorexit 20: aload_2 21: athrow 22: return Exception table: from to target type 4 14 17 any 17 20 17 any 此处会发现有一个monitorenter，却有两个monitorexit；这是JVM的补偿机制，保证你的同步代码块中出现异常，能正常释放锁 如字节码行号4-13可能会出现异常，则会走17进行异常处理，在此处进行锁的释放","categories":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/categories/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/tags/JUC/"},{"name":"多线程","slug":"多线程","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]}],"categories":[{"name":"网络","slug":"网络","permalink":"http://c89757.gitee.io/colinstar/categories/%E7%BD%91%E7%BB%9C/"},{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/categories/MySql/"},{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/categories/mysql/"},{"name":"java","slug":"java","permalink":"http://c89757.gitee.io/colinstar/categories/java/"},{"name":"jvm","slug":"jvm","permalink":"http://c89757.gitee.io/colinstar/categories/jvm/"},{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/categories/JUC/"},{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/categories/Mysql/"},{"name":"springboot","slug":"springboot","permalink":"http://c89757.gitee.io/colinstar/categories/springboot/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://c89757.gitee.io/colinstar/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"netty","slug":"netty","permalink":"http://c89757.gitee.io/colinstar/categories/netty/"}],"tags":[{"name":"other","slug":"other","permalink":"http://c89757.gitee.io/colinstar/tags/other/"},{"name":"MySql","slug":"MySql","permalink":"http://c89757.gitee.io/colinstar/tags/MySql/"},{"name":"mysql","slug":"mysql","permalink":"http://c89757.gitee.io/colinstar/tags/mysql/"},{"name":"java","slug":"java","permalink":"http://c89757.gitee.io/colinstar/tags/java/"},{"name":"GC","slug":"GC","permalink":"http://c89757.gitee.io/colinstar/tags/GC/"},{"name":"jvm","slug":"jvm","permalink":"http://c89757.gitee.io/colinstar/tags/jvm/"},{"name":"questions","slug":"questions","permalink":"http://c89757.gitee.io/colinstar/tags/questions/"},{"name":"JUC","slug":"JUC","permalink":"http://c89757.gitee.io/colinstar/tags/JUC/"},{"name":"多线程","slug":"多线程","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Mysql","slug":"Mysql","permalink":"http://c89757.gitee.io/colinstar/tags/Mysql/"},{"name":"springboot","slug":"springboot","permalink":"http://c89757.gitee.io/colinstar/tags/springboot/"},{"name":"maven","slug":"maven","permalink":"http://c89757.gitee.io/colinstar/tags/maven/"},{"name":"spring","slug":"spring","permalink":"http://c89757.gitee.io/colinstar/tags/spring/"},{"name":"堆","slug":"堆","permalink":"http://c89757.gitee.io/colinstar/tags/%E5%A0%86/"},{"name":"排序算法","slug":"排序算法","permalink":"http://c89757.gitee.io/colinstar/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"nio","slug":"nio","permalink":"http://c89757.gitee.io/colinstar/tags/nio/"},{"name":"netty","slug":"netty","permalink":"http://c89757.gitee.io/colinstar/tags/netty/"}]}